 1/1:
from phi.torch.flow import *
from tqdm.notebook import trange
import torch
import matplotlib.pyplot as plt
 2/1:
from phi.torch.flow import *
from tqdm.notebook import trange
import torch
import matplotlib.pyplot as plt
 3/1:
from phi.torch.flow import *
from tqdm.notebook import trange
import torch
import matplotlib.pyplot as plt
 3/2: import warp
 3/3:
# fluid specification & initialization
RES = 128
BOUND = 100
NUM_TIME_STEPS = 200
DT = 0.5
domain = Box(x=BOUND, y=BOUND)
INFLOW_RATE = 0.5
BUOYANCY = 0.1
inflow = Sphere(x=50, y=9.5, radius=8)

v0 = StaggeredGrid(0, 0, domain, x=RES, y=RES)
smoke0 = CenteredGrid(0, math.extrapolation.BOUNDARY, domain, x=RES, y=RES)
 3/4:
# noise specification & initialization
batch_size = 2
num_channel = 2
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
up_level = 2 # noise upsampling level
res_up = RES * (2 ** up_level)
 3/5:
# conditional noise upsampling & visualization
x = math.random_normal(batch(b=batch_size),math.channel(vec=num_channel),spatial(x=RES, y=RES))
x_up = warp.upsample_noise_cond(x, up_level)
vis.plot({'noise':x.b[0].vec[0],'conditional upsampled noise':x_up.b[0].vec[0]})
 3/6:
# fluid step function with smoke inflow
@jit_compile
def step(v, s, p, dt):
    s = advect.mac_cormack(s, v, dt) + INFLOW_RATE * resample(inflow, to=s, soft=True)
    buoyancy = resample(s * (0, BUOYANCY), to=v)
    v = advect.semi_lagrangian(v, v, dt) + buoyancy * dt
    v, p = fluid.make_incompressible(v, (), Solve('CG', 1e-3, x0=p))
    return v, s, p
 3/7: v_trj, s_trj, p_trj = iterate(step, batch(time=NUM_TIME_STEPS), v0, smoke0, None, dt=DT, range=trange, substeps=3)
 4/1:
from phi.torch.flow import *
from tqdm.notebook import trange
import torch
import matplotlib.pyplot as plt
 4/2:
# fluid specification & initialization
RES = 128
BOUND = 100
NUM_TIME_STEPS = 200
DT = 0.5
domain = Box(x=BOUND, y=BOUND)
INFLOW_RATE = 0.5
BUOYANCY = 0.1
inflow = Sphere(x=50, y=9.5, radius=8)

v0 = StaggeredGrid(0, 0, domain, x=RES, y=RES)
smoke0 = CenteredGrid(0, math.extrapolation.BOUNDARY, domain, x=RES, y=RES)
 4/3:
# noise specification & initialization
batch_size = 2
num_channel = 2
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
up_level = 2 # noise upsampling level
res_up = RES * (2 ** up_level)
 4/4:
# conditional noise upsampling & visualization
x = math.random_normal(batch(b=batch_size),math.channel(vec=num_channel),spatial(x=RES, y=RES))
x_up = warp.upsample_noise_cond(x, up_level)
vis.plot({'noise':x.b[0].vec[0],'conditional upsampled noise':x_up.b[0].vec[0]})
 4/5: import warp
 4/6:
# fluid specification & initialization
RES = 128
BOUND = 100
NUM_TIME_STEPS = 200
DT = 0.5
domain = Box(x=BOUND, y=BOUND)
INFLOW_RATE = 0.5
BUOYANCY = 0.1
inflow = Sphere(x=50, y=9.5, radius=8)

v0 = StaggeredGrid(0, 0, domain, x=RES, y=RES)
smoke0 = CenteredGrid(0, math.extrapolation.BOUNDARY, domain, x=RES, y=RES)
 4/7:
# noise specification & initialization
batch_size = 2
num_channel = 2
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
up_level = 2 # noise upsampling level
res_up = RES * (2 ** up_level)
 4/8:
# conditional noise upsampling & visualization
x = math.random_normal(batch(b=batch_size),math.channel(vec=num_channel),spatial(x=RES, y=RES))
x_up = warp.upsample_noise_cond(x, up_level)
vis.plot({'noise':x.b[0].vec[0],'conditional upsampled noise':x_up.b[0].vec[0]})
 4/9:
# fluid step function with smoke inflow
@jit_compile
def step(v, s, p, dt):
    s = advect.mac_cormack(s, v, dt) + INFLOW_RATE * resample(inflow, to=s, soft=True)
    buoyancy = resample(s * (0, BUOYANCY), to=v)
    v = advect.semi_lagrangian(v, v, dt) + buoyancy * dt
    v, p = fluid.make_incompressible(v, (), Solve('CG', 1e-3, x0=p))
    return v, s, p
4/10: v_trj, s_trj, p_trj = iterate(step, batch(time=NUM_TIME_STEPS), v0, smoke0, None, dt=DT, range=trange, substeps=3)
4/11:
# resampling the grid to a finer grid for noise transport
part_level = 2 # partition level for triangulation
tris_per_pix_dim = 2 ** (part_level-1) # triangles per pixel per dimension
tris_per_dim = tris_per_pix_dim * RES # triangles per dimension
vtx_per_dim = tris_per_pix_dim * RES + 1 # vertices per dimention
domain1=Box(x=(-BOUND/RES/tris_per_pix_dim/2, BOUND+BOUND/RES/tris_per_pix_dim/2),y=(-BOUND/RES/tris_per_pix_dim/2,BOUND+BOUND/RES/tris_per_pix_dim/2))
grid1 = CenteredGrid(0, math.extrapolation.BOUNDARY, domain1, x=vtx_per_dim, y=vtx_per_dim)
v_trj_rs = field.resample(value=v_trj, to=grid1)

vis.plot({'velocity': v_trj.time[-1], 'velocity resampled': v_trj_rs.time[-1]})
4/12:
# vertices & triangles (represented by vertex indices) generation
_, vertices = warp.vertices_gen(RES, RES, part_level)
reshaped_mesh_idxs = warp.mesh_idx_gen(RES, RES, part_level)
4/13:
# complete noise warping step function
def noise_step(vtx_pos, noise, up_level,mesh_idxs,vertices):
    res, _ = math.spatial(noise).sizes

    part_level = up_level
    resolution = res * (2 ** up_level)
    tris_per_row = 2 ** (part_level-1)

    noise_up = warp.upsample_noise_cond(noise, up_level)

    idx_y = mesh_idxs[:,0].int()
    idx_x = mesh_idxs[:,1].int()
    warped_coords = vtx_pos.native(['x','y','vector'])[idx_y, idx_x].fliplr()
    rast_out = warp.rasterize(warped_coords, vertices, res * tris_per_row, resolution, device)

    noise_warped = warp.transport_noise(noise_up, res, rast_out, part_level)

    return noise_warped
4/14:
# normalize the grid and corresponding vertex velocities for warping
grid_nmlzd = grid1.center * tris_per_dim / BOUND
v_trj_nmlzd = v_trj_rs * tris_per_dim / BOUND
4/15:
def calc_grid_pos(grid, vel, dt):
    grid_warp = grid - vel.values*dt
    return grid_warp

def gen_grids_warped(grid, vels, dt):
    # maps = []
    maps = [grid]
    for i in range(vels.time.size-1):
        grid_warp = calc_grid_pos(grid,vels.time[i+1],dt)
        maps.append(grid_warp)
    maps = math.stack(maps, batch('time'))
    return maps
4/16:
# generate the warped grid positions
grids_warped = gen_grids_warped(grid_nmlzd,v_trj_nmlzd,.5)
4/17:
# noise warping by the proposed method, no disclusion fix
noise_trj = [x]
x_in = x
for i in range(NUM_TIME_STEPS):
    x_warped = noise_step(grids_warped.time[i+1], x_in, up_level, reshaped_mesh_idxs, vertices)
    noise_trj.append(x_warped)
    x_in = x_warped
noise_trj = math.stack(noise_trj, batch('time'))
 5/1:
from phi.torch.flow import *
from tqdm.notebook import trange
import torch
import matplotlib.pyplot as plt
 5/2: import warp
 5/3:
# fluid specification & initialization
RES = 128
BOUND = 100
NUM_TIME_STEPS = 200
DT = 0.5
domain = Box(x=BOUND, y=BOUND)
INFLOW_RATE = 0.5
BUOYANCY = 0.1
inflow = Sphere(x=50, y=9.5, radius=8)

v0 = StaggeredGrid(0, 0, domain, x=RES, y=RES)
smoke0 = CenteredGrid(0, math.extrapolation.BOUNDARY, domain, x=RES, y=RES)
 5/4:
# noise specification & initialization
batch_size = 2
num_channel = 2
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
up_level = 2 # noise upsampling level
res_up = RES * (2 ** up_level)
 5/5:
# conditional noise upsampling & visualization
x = math.random_normal(batch(b=batch_size),math.channel(vec=num_channel),spatial(x=RES, y=RES))
x_up = warp.upsample_noise_cond(x, up_level)
vis.plot({'noise':x.b[0].vec[0],'conditional upsampled noise':x_up.b[0].vec[0]})
 5/6:
# fluid step function with smoke inflow
@jit_compile
def step(v, s, p, dt):
    s = advect.mac_cormack(s, v, dt) + INFLOW_RATE * resample(inflow, to=s, soft=True)
    buoyancy = resample(s * (0, BUOYANCY), to=v)
    v = advect.semi_lagrangian(v, v, dt) + buoyancy * dt
    v, p = fluid.make_incompressible(v, (), Solve('CG', 1e-3, x0=p))
    return v, s, p
 5/7: v_trj, s_trj, p_trj = iterate(step, batch(time=NUM_TIME_STEPS), v0, smoke0, None, dt=DT, range=trange, substeps=3)
 5/8:
# resampling the grid to a finer grid for noise transport
part_level = 2 # partition level for triangulation
tris_per_pix_dim = 2 ** (part_level-1) # triangles per pixel per dimension
tris_per_dim = tris_per_pix_dim * RES # triangles per dimension
vtx_per_dim = tris_per_pix_dim * RES + 1 # vertices per dimention
domain1=Box(x=(-BOUND/RES/tris_per_pix_dim/2, BOUND+BOUND/RES/tris_per_pix_dim/2),y=(-BOUND/RES/tris_per_pix_dim/2,BOUND+BOUND/RES/tris_per_pix_dim/2))
grid1 = CenteredGrid(0, math.extrapolation.BOUNDARY, domain1, x=vtx_per_dim, y=vtx_per_dim)
v_trj_rs = field.resample(value=v_trj, to=grid1)

vis.plot({'velocity': v_trj.time[-1], 'velocity resampled': v_trj_rs.time[-1]})
 5/9:
# vertices & triangles (represented by vertex indices) generation
_, vertices = warp.vertices_gen(RES, RES, part_level)
reshaped_mesh_idxs = warp.mesh_idx_gen(RES, RES, part_level)
5/10:
# complete noise warping step function
def noise_step(vtx_pos, noise, up_level,mesh_idxs,vertices):
    res, _ = math.spatial(noise).sizes

    part_level = up_level
    resolution = res * (2 ** up_level)
    tris_per_row = 2 ** (part_level-1)

    noise_up = warp.upsample_noise_cond(noise, up_level)

    idx_y = mesh_idxs[:,0].int()
    idx_x = mesh_idxs[:,1].int()
    warped_coords = vtx_pos.native(['x','y','vector'])[idx_y, idx_x].fliplr()
    rast_out = warp.rasterize(warped_coords, vertices, res * tris_per_row, resolution, device)

    noise_warped = warp.transport_noise(noise_up, res, rast_out, part_level)

    return noise_warped
5/11:
# normalize the grid and corresponding vertex velocities for warping
grid_nmlzd = grid1.center * tris_per_dim / BOUND
v_trj_nmlzd = v_trj_rs * tris_per_dim / BOUND
5/12:
def calc_grid_pos(grid, vel, dt):
    grid_warp = grid - vel.values*dt
    return grid_warp

def gen_grids_warped(grid, vels, dt):
    # maps = []
    maps = [grid]
    for i in range(vels.time.size-1):
        grid_warp = calc_grid_pos(grid,vels.time[i+1],dt)
        maps.append(grid_warp)
    maps = math.stack(maps, batch('time'))
    return maps
5/13:
# generate the warped grid positions
grids_warped = gen_grids_warped(grid_nmlzd,v_trj_nmlzd,.5)
5/14:
# noise warping by the proposed method, no disclusion fix
noise_trj = [x]
x_in = x
for i in range(NUM_TIME_STEPS):
    x_warped = noise_step(grids_warped.time[i+1], x_in, up_level, reshaped_mesh_idxs, vertices)
    noise_trj.append(x_warped)
    x_in = x_warped
noise_trj = math.stack(noise_trj, batch('time'))
 6/1:
from phi.torch.flow import *
from tqdm.notebook import trange
import torch
import matplotlib.pyplot as plt
 6/2: import warp
 6/3:
# fluid specification & initialization
RES = 128
BOUND = 100
NUM_TIME_STEPS = 200
DT = 0.5
domain = Box(x=BOUND, y=BOUND)
INFLOW_RATE = 0.5
BUOYANCY = 0.1
inflow = Sphere(x=50, y=9.5, radius=8)

v0 = StaggeredGrid(0, 0, domain, x=RES, y=RES)
smoke0 = CenteredGrid(0, math.extrapolation.BOUNDARY, domain, x=RES, y=RES)
 6/4:
# noise specification & initialization
batch_size = 2
num_channel = 2
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
up_level = 2 # noise upsampling level
res_up = RES * (2 ** up_level)
 6/5:
# conditional noise upsampling & visualization
x = math.random_normal(batch(b=batch_size),math.channel(vec=num_channel),spatial(x=RES, y=RES))
x_up = warp.upsample_noise_cond(x, up_level)
vis.plot({'noise':x.b[0].vec[0],'conditional upsampled noise':x_up.b[0].vec[0]})
 6/6:
# fluid step function with smoke inflow
@jit_compile
def step(v, s, p, dt):
    s = advect.mac_cormack(s, v, dt) + INFLOW_RATE * resample(inflow, to=s, soft=True)
    buoyancy = resample(s * (0, BUOYANCY), to=v)
    v = advect.semi_lagrangian(v, v, dt) + buoyancy * dt
    v, p = fluid.make_incompressible(v, (), Solve('CG', 1e-3, x0=p))
    return v, s, p
 6/7: v_trj, s_trj, p_trj = iterate(step, batch(time=NUM_TIME_STEPS), v0, smoke0, None, dt=DT, range=trange, substeps=3)
 6/8:
# resampling the grid to a finer grid for noise transport
part_level = 2 # partition level for triangulation
tris_per_pix_dim = 2 ** (part_level-1) # triangles per pixel per dimension
tris_per_dim = tris_per_pix_dim * RES # triangles per dimension
vtx_per_dim = tris_per_pix_dim * RES + 1 # vertices per dimention
domain1=Box(x=(-BOUND/RES/tris_per_pix_dim/2, BOUND+BOUND/RES/tris_per_pix_dim/2),y=(-BOUND/RES/tris_per_pix_dim/2,BOUND+BOUND/RES/tris_per_pix_dim/2))
grid1 = CenteredGrid(0, math.extrapolation.BOUNDARY, domain1, x=vtx_per_dim, y=vtx_per_dim)
v_trj_rs = field.resample(value=v_trj, to=grid1)

vis.plot({'velocity': v_trj.time[-1], 'velocity resampled': v_trj_rs.time[-1]})
 6/9:
# vertices & triangles (represented by vertex indices) generation
_, vertices = warp.vertices_gen(RES, RES, part_level)
reshaped_mesh_idxs = warp.mesh_idx_gen(RES, RES, part_level)
6/10:
# complete noise warping step function
def noise_step(vtx_pos, noise, up_level,mesh_idxs,vertices):
    res, _ = math.spatial(noise).sizes

    part_level = up_level
    resolution = res * (2 ** up_level)
    tris_per_row = 2 ** (part_level-1)

    noise_up = warp.upsample_noise_cond(noise, up_level)

    idx_y = mesh_idxs[:,0].int()
    idx_x = mesh_idxs[:,1].int()
    warped_coords = vtx_pos.native(['x','y','vector'])[idx_y, idx_x].fliplr()
    rast_out = warp.rasterize(warped_coords, vertices, res * tris_per_row, resolution, device)

    noise_warped = warp.transport_noise(noise_up, res, rast_out, part_level)

    return noise_warped
6/11:
# normalize the grid and corresponding vertex velocities for warping
grid_nmlzd = grid1.center * tris_per_dim / BOUND
v_trj_nmlzd = v_trj_rs * tris_per_dim / BOUND
6/12:
def calc_grid_pos(grid, vel, dt):
    grid_warp = grid - vel.values*dt
    return grid_warp

def gen_grids_warped(grid, vels, dt):
    # maps = []
    maps = [grid]
    for i in range(vels.time.size-1):
        grid_warp = calc_grid_pos(grid,vels.time[i+1],dt)
        maps.append(grid_warp)
    maps = math.stack(maps, batch('time'))
    return maps
6/13:
# generate the warped grid positions
grids_warped = gen_grids_warped(grid_nmlzd,v_trj_nmlzd,.5)
6/14:
# noise warping by the proposed method, no disclusion fix
noise_trj = [x]
x_in = x
for i in range(NUM_TIME_STEPS):
    x_warped = noise_step(grids_warped.time[i+1], x_in, up_level, reshaped_mesh_idxs, vertices)
    noise_trj.append(x_warped)
    x_in = x_warped
noise_trj = math.stack(noise_trj, batch('time'))
6/15:
# noise warping by the proposed method, filling empty cell with warping from previous frame
noise_trj_prev = [x]
x_in = x
for i in range(NUM_TIME_STEPS):
    x_warped = noise_step(grids_warped.time[i+1], x_in, up_level, reshaped_mesh_idxs, vertices)
    x_warped_prev = noise_step(grids_warped.time[i], x_in, up_level, reshaped_mesh_idxs, vertices)
    x_warped = math.where(math.is_nan(x_warped),x_warped_prev,x_warped)
    noise_trj_prev.append(x_warped)
    x_in = x_warped
noise_trj_prev = math.stack(noise_trj_prev, batch('time'))
6/16:
# noise warping by the proposed method, filling empty cell with warping from last frame + random noise
noise_trj_prev_rand = [x]
x_in = x
for i in range(NUM_TIME_STEPS):
    x_warped = noise_step(grids_warped.time[i+1], x_in, up_level, reshaped_mesh_idxs, vertices)
    x_warped_prev = noise_step(grids_warped.time[i], x_in, up_level, reshaped_mesh_idxs, vertices)
    x_warped = math.where(math.is_nan(x_warped),x_warped_prev,x_warped)
    x_warped = math.where(math.is_nan(x_warped), math.random_normal(x_warped.shape), x_warped)
    noise_trj_prev_rand.append(x_warped)
    x_in = x_warped
noise_trj_prev_rand = math.stack(noise_trj_prev_rand, batch('time'))
6/17:
# noise warping comparison
row1 = math.stack([noise_trj.b[0].vec[0],noise_trj_prev.b[0].vec[0]],batch('row'))
row2 = math.stack([noise_trj_prev_rand.b[0].vec[0],s_trj.values / s_trj.values.max],batch('row'))
ani = math.stack([row1,row2],batch('col'))
t1 = math.stack(['original dubbed noise','with previous frame'],batch('row'))
t2 = math.stack(['with previous frame + random noise', 'density'],batch('row'))
ttl = math.stack([t1,t2],batch('col'))

vis.plot(ani,row_dims='row',col_dims='col', frame_time=40,animate='time',size=(10,6),title=ttl)
6/18:
# noise warping comparison
row1 = math.stack([noise_trj.b[0].vec[0],noise_trj_prev.b[0].vec[0]],batch('row'))
row2 = math.stack([noise_trj_prev_rand.b[0].vec[0],s_trj.values / s_trj.values.max],batch('row'))
ani = math.stack([row1,row2],batch('col'))
t1 = math.stack(['original dubbed noise','with previous frame'],batch('row'))
t2 = math.stack(['with previous frame + random noise', 'density'],batch('row'))
ttl = math.stack([t1,t2],batch('col'))

vis.plot(ani,row_dims='row',col_dims='col', frame_time=40,animate='time',size=(10,6),title=ttl)
 7/1:
from phi.torch.flow import *
from tqdm.notebook import trange
import torch
import matplotlib.pyplot as plt
 7/2: import warp
 7/3:
# fluid specification & initialization
RES = 128
BOUND = 100
NUM_TIME_STEPS = 200
DT = 0.5
domain = Box(x=BOUND, y=BOUND)
INFLOW_RATE = 0.5
BUOYANCY = 0.1
inflow = Sphere(x=50, y=9.5, radius=8)

v0 = StaggeredGrid(0, 0, domain, x=RES, y=RES)
smoke0 = CenteredGrid(0, math.extrapolation.BOUNDARY, domain, x=RES, y=RES)
 7/4:
# noise specification & initialization
batch_size = 2
num_channel = 2
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
up_level = 2 # noise upsampling level
res_up = RES * (2 ** up_level)
 7/5:
# conditional noise upsampling & visualization
x = math.random_normal(batch(b=batch_size),math.channel(vec=num_channel),spatial(x=RES, y=RES))
x_up = warp.upsample_noise_cond(x, up_level)
vis.plot({'noise':x.b[0].vec[0],'conditional upsampled noise':x_up.b[0].vec[0]})
 7/6:
# fluid step function with smoke inflow
@jit_compile
def step(v, s, p, dt):
    s = advect.mac_cormack(s, v, dt) + INFLOW_RATE * resample(inflow, to=s, soft=True)
    buoyancy = resample(s * (0, BUOYANCY), to=v)
    v = advect.semi_lagrangian(v, v, dt) + buoyancy * dt
    v, p = fluid.make_incompressible(v, (), Solve('CG', 1e-3, x0=p))
    return v, s, p
 7/7: v_trj, s_trj, p_trj = iterate(step, batch(time=NUM_TIME_STEPS), v0, smoke0, None, dt=DT, range=trange, substeps=3)
 7/8:
# resampling the grid to a finer grid for noise transport
part_level = 2 # partition level for triangulation
tris_per_pix_dim = 2 ** (part_level-1) # triangles per pixel per dimension
tris_per_dim = tris_per_pix_dim * RES # triangles per dimension
vtx_per_dim = tris_per_pix_dim * RES + 1 # vertices per dimention
domain1=Box(x=(-BOUND/RES/tris_per_pix_dim/2, BOUND+BOUND/RES/tris_per_pix_dim/2),y=(-BOUND/RES/tris_per_pix_dim/2,BOUND+BOUND/RES/tris_per_pix_dim/2))
grid1 = CenteredGrid(0, math.extrapolation.BOUNDARY, domain1, x=vtx_per_dim, y=vtx_per_dim)
v_trj_rs = field.resample(value=v_trj, to=grid1)

vis.plot({'velocity': v_trj.time[-1], 'velocity resampled': v_trj_rs.time[-1]})
 7/9:
# vertices & triangles (represented by vertex indices) generation
_, vertices = warp.vertices_gen(RES, RES, part_level)
reshaped_mesh_idxs = warp.mesh_idx_gen(RES, RES, part_level)
7/10:
# complete noise warping step function
def noise_step(vtx_pos, noise, up_level,mesh_idxs,vertices):
    res, _ = math.spatial(noise).sizes

    part_level = up_level
    resolution = res * (2 ** up_level)
    tris_per_row = 2 ** (part_level-1)

    noise_up = warp.upsample_noise_cond(noise, up_level)

    idx_y = mesh_idxs[:,0].int()
    idx_x = mesh_idxs[:,1].int()
    warped_coords = vtx_pos.native(['x','y','vector'])[idx_y, idx_x].fliplr()
    rast_out = warp.rasterize(warped_coords, vertices, res * tris_per_row, resolution, device)

    noise_warped = warp.transport_noise(noise_up, res, rast_out, part_level)

    return noise_warped
7/11:
# normalize the grid and corresponding vertex velocities for warping
grid_nmlzd = grid1.center * tris_per_dim / BOUND
v_trj_nmlzd = v_trj_rs * tris_per_dim / BOUND
7/12:
def calc_grid_pos(grid, vel, dt):
    grid_warp = grid - vel.values*dt
    return grid_warp

def gen_grids_warped(grid, vels, dt):
    # maps = []
    maps = [grid]
    for i in range(vels.time.size-1):
        grid_warp = calc_grid_pos(grid,vels.time[i+1],dt)
        maps.append(grid_warp)
    maps = math.stack(maps, batch('time'))
    return maps
7/13:
# generate the warped grid positions
grids_warped = gen_grids_warped(grid_nmlzd,v_trj_nmlzd,.5)
7/14:
# noise warping by the proposed method, no disclusion fix
noise_trj = [x]
x_in = x
for i in range(NUM_TIME_STEPS):
    x_warped = noise_step(grids_warped.time[i+1], x_in, up_level, reshaped_mesh_idxs, vertices)
    noise_trj.append(x_warped)
    x_in = x_warped
noise_trj = math.stack(noise_trj, batch('time'))
7/15:
# noise warping by the proposed method, filling empty cell with warping from previous frame
noise_trj_prev = [x]
x_in = x
for i in range(NUM_TIME_STEPS):
    x_warped = noise_step(grids_warped.time[i+1], x_in, up_level, reshaped_mesh_idxs, vertices)
    x_warped_prev = noise_step(grids_warped.time[i], x_in, up_level, reshaped_mesh_idxs, vertices)
    x_warped = math.where(math.is_nan(x_warped),x_warped_prev,x_warped)
    noise_trj_prev.append(x_warped)
    x_in = x_warped
noise_trj_prev = math.stack(noise_trj_prev, batch('time'))
7/16:
# noise warping by the proposed method, filling empty cell with warping from last frame + random noise
noise_trj_prev_rand = [x]
x_in = x
for i in range(NUM_TIME_STEPS):
    x_warped = noise_step(grids_warped.time[i+1], x_in, up_level, reshaped_mesh_idxs, vertices)
    x_warped_prev = noise_step(grids_warped.time[i], x_in, up_level, reshaped_mesh_idxs, vertices)
    x_warped = math.where(math.is_nan(x_warped),x_warped_prev,x_warped)
    x_warped = math.where(math.is_nan(x_warped), math.random_normal(x_warped.shape), x_warped)
    noise_trj_prev_rand.append(x_warped)
    x_in = x_warped
noise_trj_prev_rand = math.stack(noise_trj_prev_rand, batch('time'))
7/17:
# noise warping comparison
row1 = math.stack([noise_trj.b[0].vec[0],noise_trj_prev.b[0].vec[0]],batch('row'))
row2 = math.stack([noise_trj_prev_rand.b[0].vec[0],s_trj.values / s_trj.values.max],batch('row'))
ani = math.stack([row1,row2],batch('col'))
t1 = math.stack(['original dubbed noise','with previous frame'],batch('row'))
t2 = math.stack(['with previous frame + random noise', 'density'],batch('row'))
ttl = math.stack([t1,t2],batch('col'))

vis.plot(ani,row_dims='row',col_dims='col', frame_time=40,animate='time',size=(10,6),title=ttl)
 8/1:
from phi.torch.flow import *
from tqdm.notebook import trange
import torch
import matplotlib.pyplot as plt
 8/2: import warp
 8/3:
# fluid specification & initialization
RES = 128
BOUND = 100
NUM_TIME_STEPS = 200
DT = 0.5
domain = Box(x=BOUND, y=BOUND)
INFLOW_RATE = 0.5
BUOYANCY = 0.1
inflow = Sphere(x=50, y=9.5, radius=8)

v0 = StaggeredGrid(0, 0, domain, x=RES, y=RES)
smoke0 = CenteredGrid(0, math.extrapolation.BOUNDARY, domain, x=RES, y=RES)
 8/4:
# noise specification & initialization
batch_size = 2
num_channel = 2
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
up_level = 2 # noise upsampling level
res_up = RES * (2 ** up_level)
 8/5:
# conditional noise upsampling & visualization
x = math.random_normal(batch(b=batch_size),math.channel(vec=num_channel),spatial(x=RES, y=RES))
x_up = warp.upsample_noise_cond(x, up_level)
vis.plot({'noise':x.b[0].vec[0],'conditional upsampled noise':x_up.b[0].vec[0]})
 8/6:
# fluid step function with smoke inflow
@jit_compile
def step(v, s, p, dt):
    s = advect.mac_cormack(s, v, dt) + INFLOW_RATE * resample(inflow, to=s, soft=True)
    buoyancy = resample(s * (0, BUOYANCY), to=v)
    v = advect.semi_lagrangian(v, v, dt) + buoyancy * dt
    v, p = fluid.make_incompressible(v, (), Solve('CG', 1e-3, x0=p))
    return v, s, p
 8/7: v_trj, s_trj, p_trj = iterate(step, batch(time=NUM_TIME_STEPS), v0, smoke0, None, dt=DT, range=trange, substeps=3)
 8/8:
# resampling the grid to a finer grid for noise transport
part_level = 2 # partition level for triangulation
tris_per_pix_dim = 2 ** (part_level-1) # triangles per pixel per dimension
tris_per_dim = tris_per_pix_dim * RES # triangles per dimension
vtx_per_dim = tris_per_pix_dim * RES + 1 # vertices per dimention
domain1=Box(x=(-BOUND/RES/tris_per_pix_dim/2, BOUND+BOUND/RES/tris_per_pix_dim/2),y=(-BOUND/RES/tris_per_pix_dim/2,BOUND+BOUND/RES/tris_per_pix_dim/2))
grid1 = CenteredGrid(0, math.extrapolation.BOUNDARY, domain1, x=vtx_per_dim, y=vtx_per_dim)
v_trj_rs = field.resample(value=v_trj, to=grid1)

vis.plot({'velocity': v_trj.time[-1], 'velocity resampled': v_trj_rs.time[-1]})
 8/9:
# vertices & triangles (represented by vertex indices) generation
_, vertices = warp.vertices_gen(RES, RES, part_level)
reshaped_mesh_idxs = warp.mesh_idx_gen(RES, RES, part_level)
8/10:
# complete noise warping step function
def noise_step(vtx_pos, noise, up_level,mesh_idxs,vertices):
    res, _ = math.spatial(noise).sizes

    part_level = up_level
    resolution = res * (2 ** up_level)
    tris_per_row = 2 ** (part_level-1)

    noise_up = warp.upsample_noise_cond(noise, up_level)

    idx_y = mesh_idxs[:,0].int()
    idx_x = mesh_idxs[:,1].int()
    warped_coords = vtx_pos.native(['x','y','vector'])[idx_y, idx_x].fliplr()
    rast_out = warp.rasterize(warped_coords, vertices, res * tris_per_row, resolution, device)

    noise_warped = warp.transport_noise(noise_up, res, rast_out, part_level)

    return noise_warped
8/11:
# normalize the grid and corresponding vertex velocities for warping
grid_nmlzd = grid1.center * tris_per_dim / BOUND
v_trj_nmlzd = v_trj_rs * tris_per_dim / BOUND
8/12:
def calc_grid_pos(grid, vel, dt):
    grid_warp = grid - vel.values*dt
    return grid_warp

def gen_grids_warped(grid, vels, dt):
    # maps = []
    maps = [grid]
    for i in range(vels.time.size-1):
        grid_warp = calc_grid_pos(grid,vels.time[i+1],dt)
        maps.append(grid_warp)
    maps = math.stack(maps, batch('time'))
    return maps
8/13:
# generate the warped grid positions
grids_warped = gen_grids_warped(grid_nmlzd,v_trj_nmlzd,.5)
8/14:
# noise warping by the proposed method, no disclusion fix
noise_trj = [x]
x_in = x
for i in range(NUM_TIME_STEPS):
    x_warped = noise_step(grids_warped.time[i+1], x_in, up_level, reshaped_mesh_idxs, vertices)
    noise_trj.append(x_warped)
    x_in = x_warped
noise_trj = math.stack(noise_trj, batch('time'))
8/15:
# noise warping by the proposed method, filling empty cell with warping from previous frame
noise_trj_prev = [x]
x_in = x
for i in range(NUM_TIME_STEPS):
    x_warped = noise_step(grids_warped.time[i+1], x_in, up_level, reshaped_mesh_idxs, vertices)
    x_warped_prev = noise_step(grids_warped.time[i], x_in, up_level, reshaped_mesh_idxs, vertices)
    x_warped = math.where(math.is_nan(x_warped),x_warped_prev,x_warped)
    noise_trj_prev.append(x_warped)
    x_in = x_warped
noise_trj_prev = math.stack(noise_trj_prev, batch('time'))
8/16:
# noise warping by the proposed method, filling empty cell with warping from last frame + random noise
noise_trj_prev_rand = [x]
x_in = x
for i in range(NUM_TIME_STEPS):
    x_warped = noise_step(grids_warped.time[i+1], x_in, up_level, reshaped_mesh_idxs, vertices)
    x_warped_prev = noise_step(grids_warped.time[i], x_in, up_level, reshaped_mesh_idxs, vertices)
    x_warped = math.where(math.is_nan(x_warped),x_warped_prev,x_warped)
    x_warped = math.where(math.is_nan(x_warped), math.random_normal(x_warped.shape), x_warped)
    noise_trj_prev_rand.append(x_warped)
    x_in = x_warped
noise_trj_prev_rand = math.stack(noise_trj_prev_rand, batch('time'))
8/17:
# noise warping comparison
row1 = math.stack([noise_trj.b[0].vec[0],noise_trj_prev.b[0].vec[0]],batch('row'))
row2 = math.stack([noise_trj_prev_rand.b[0].vec[0],s_trj.values / s_trj.values.max],batch('row'))
ani = math.stack([row1,row2],batch('col'))
t1 = math.stack(['original dubbed noise','with previous frame'],batch('row'))
t2 = math.stack(['with previous frame + random noise', 'density'],batch('row'))
ttl = math.stack([t1,t2],batch('col'))

vis.plot(ani,row_dims='row',col_dims='col', frame_time=40,animate='time',size=(10,6),title=ttl)
 9/1:
!wget -nc "https://dataserv.ub.tum.de/s/m1734798.001/download?path=/&files=128_tra_small.zip" -O data/128_tra_small.zip --no-check-certificate 
!unzip -nq data/128_tra_small.zip -d data
!wget -nc "https://dataserv.ub.tum.de/s/m1734798.001/download?path=/&files=checkpoints_acdm_tra.zip" -O models/checkpoints_acdm_tra.zip --no-check-certificate 
!unzip -nq models/checkpoints_acdm_tra.zip -d models
10/1:
!wget -nc "https://dataserv.ub.tum.de/s/m1734798.001/download?path=/&files=128_tra_small.zip" -O data/128_tra_small.zip --no-check-certificate 
!unzip -nq data/128_tra_small.zip -d data
!wget -nc "https://dataserv.ub.tum.de/s/m1734798.001/download?path=/&files=checkpoints_acdm_tra.zip" -O models/checkpoints_acdm_tra.zip --no-check-certificate 
!unzip -nq models/checkpoints_acdm_tra.zip -d models
10/2:
try:
    import google.colab  # only to ensure that we are inside colab
    !pip install einops
except ImportError:
    print("This notebook is running locally, please follow the ACDM installation instructions first, then continue with the cell below.")
    pass
10/3:
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader, SequentialSampler, RandomSampler

from einops import rearrange
from functools import partial

import matplotlib.pyplot as plt
import numpy as np

import math
import os, json
from typing import List,Tuple,Dict
11/1:
!wget -nc "https://dataserv.ub.tum.de/s/m1734798.001/download?path=/&files=128_tra_small.zip" -O data/128_tra_small.zip --no-check-certificate 
!unzip -nq data/128_tra_small.zip -d data
!wget -nc "https://dataserv.ub.tum.de/s/m1734798.001/download?path=/&files=checkpoints_acdm_tra.zip" -O models/checkpoints_acdm_tra.zip --no-check-certificate 
!unzip -nq models/checkpoints_acdm_tra.zip -d models
11/2:
try:
    import google.colab  # only to ensure that we are inside colab
    !pip install einops
except ImportError:
    print("This notebook is running locally, please follow the ACDM installation instructions first, then continue with the cell below.")
    pass
11/3:
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader, SequentialSampler, RandomSampler

from einops import rearrange
from functools import partial

import matplotlib.pyplot as plt
import numpy as np

import math
import os, json
from typing import List,Tuple,Dict
11/4:
class TurbulenceDataset(Dataset):
    """Data set for turbulence and wavelet noise data

    Args:
        name: name of the dataset
        dataDirs: list of paths to data directories
        filterTop: filter for top level folder names (e.g. different types of data)
        excludeFilterTop: mode for filterTop (exclude or include)
        filterSim: filter simulations by min and max (min inclusive, max exclusive)
        excludefilterSim: mode for filterSim (exclude or include)
        filterFrame: mandatory filter for simulation frames by min and max (min inclusive, max exclusive)
        sequenceLength: number of frames to group into a sequence and number of frames to omit in between
        randSeqOffset: randomizes the starting frame of each sequence
        simFields: list of simulation fields to include (vel is always included) ["dens", "pres"]
        simParams: list of simulation parameters to include ["rey", "mach"]
        printLevel: print mode for contents of the dataset ["none", "top", "sim", "full"]
    """

    def __init__(self, name:str, dataDirs:List[str], filterTop:List[str], excludeFilterTop:bool=False, filterSim:List[Tuple[int, int]]=[],
                excludefilterSim:bool=False, filterFrame:List[Tuple[int, int]]=[], sequenceLength:List[Tuple[int, int]]=[],
                randSeqOffset:bool=False, simFields:List[str]=[], simParams:List[str]=[], printLevel:str="none"):

        self.transform = None
        self.name = name
        self.dataDirs = dataDirs
        self.filterTop = filterTop
        self.excludeFilterTop = excludeFilterTop
        self.filterSim = filterSim
        self.excludefilterSim = excludefilterSim
        self.filterFrame = filterFrame
        self.sequenceLength = sequenceLength
        self.randSeqOffset = randSeqOffset
        self.simFields = ["velocity"]
        if "dens" in simFields:
            self.simFields += ["density"]
        if "pres" in simFields:
            self.simFields += ["pressure"]

        self.simParams = simParams
        self.printLevel = printLevel

        self.summaryPrint = []
        self.summaryPrint += ["Dataset " + name + " at " + str(dataDirs)]
        self.summaryPrint += [self.getFilterInfoString()]

        # BUILD FULL FILE LIST
        self.dataPaths = []
        self.dataPathModes = []

        for dataDir in dataDirs:
            topDirs = os.listdir(dataDir)
            topDirs.sort()

            # top level folders
            for topDir in topDirs:
                if filterTop:
                    # continue when excluding or including according to filter
                    if excludeFilterTop == any( item in topDir for item in filterTop ):
                        continue

                match = -1
                # compute matching top filter for according sim or frame filtering
                if len(filterSim) > 1 or len(filterFrame) > 1:
                    for i in range(len(filterTop)):
                        if filterTop[i] in topDir:
                            match = i
                            break
                    assert (match >= 0), "Match computation error"

                simDir = os.path.join(dataDir, topDir)
                sims = os.listdir(simDir)
                sims.sort()

                if printLevel == "top":
                    self.summaryPrint += ["Top folder loaded: " + simDir.replace(dataDir + "/", "")]

                # sim_000001 folders
                for sim in sims:
                    currentDir = os.path.join(simDir, sim)
                    if not os.path.isdir(currentDir):
                        continue

                    if len(filterSim) > 0:
                        simNum = int(sim.split("_")[1])
                        if len(filterSim) == 1:
                            if type(filterSim[0]) is tuple:
                                inside = simNum >= filterSim[0][0] and simNum < filterSim[0][1]
                            elif type(filterSim[0]) is list:
                                inside = simNum in filterSim[0]
                        else:
                            if type(filterSim[match]) is tuple:
                                inside = simNum >= filterSim[match][0] and simNum < filterSim[match][1]
                            elif type(filterSim[match]) is list:
                                inside = simNum in filterSim[match]
                        # continue when excluding or including according to filter
                        if inside == excludefilterSim:
                            continue

                    if printLevel == "sim":
                        self.summaryPrint += ["Sim loaded: " + currentDir.replace(dataDir + "/", "")]

                    # individual simulation frames
                    minFrame = filterFrame[0][0] if len(filterFrame) == 1 else filterFrame[match][0]
                    maxFrame = filterFrame[0][1] if len(filterFrame) == 1 else filterFrame[match][1]
                    seqLength = sequenceLength[0][0] if len(sequenceLength) == 1 else sequenceLength[match][0]
                    seqSkip   = sequenceLength[0][1] if len(sequenceLength) == 1 else sequenceLength[match][1]
                    for seqStart in range(minFrame, maxFrame, seqLength*seqSkip):
                        validSeq = True
                        for frame in range(seqStart, seqStart+seqLength*seqSkip, seqSkip):
                            # discard incomplete sequences at simulation end
                            if seqStart+seqLength*seqSkip > maxFrame:
                                validSeq = False
                                break

                            for field in self.simFields:
                                currentField = os.path.join(currentDir, "%s_%06d.npz" % (field, frame))
                                if not os.path.isfile(currentField):
                                    raise FileNotFoundError("Could not load %s file: %s" % (field, currentField))

                        # imcomplete sequence means there are no more frames left
                        if not validSeq:
                            break

                        if printLevel == "full":
                            self.summaryPrint += ["Frames %s loaded: %s/%s_%06d-%06d(%03d).npz" % ("-".join(self.simFields),
                                        currentDir.replace(dataDir + "/", ""), "-".join(self.simFields), seqStart, seqStart + seqLength*(seqSkip-1), seqSkip)]

                        self.dataPaths.append((currentDir, seqStart, seqStart + seqLength*seqSkip, seqSkip))

        self.summaryPrint += ["Dataset Length: %d\n" % len(self.dataPaths)]


    def __len__(self) -> int:
        return len(self.dataPaths)


    def __getitem__(self, idx:int) -> dict:
        # sequence indexing
        basePath, seqStart, seqEnd, seqSkip = self.dataPaths[idx]
        seqLen = int((seqEnd - seqStart) / seqSkip)
        if self.randSeqOffset:
            halfSeq = int((seqEnd-seqStart) / 2)
            offset = torch.randint(-halfSeq, halfSeq+1, (1,)).item()
            if seqStart + offset >= self.filterFrame[0][0] and seqEnd + offset < self.filterFrame[0][1]:
                seqStart = seqStart + offset
                seqEnd = seqEnd + offset

        # loading simulation parameters
        with open(os.path.join(basePath, "src", "description.json")) as f:
            loadedJSON = json.load(f)

            loadNames = ["Reynolds Number", "Mach Number", "Drag Coefficient", "Lift Coefficient", "Z Slice"]
            loadedParams = {}
            for loadName in loadNames:
                loadedParam = np.zeros(seqLen, dtype=np.float32)
                if loadName in loadedJSON:
                    temp = loadedJSON[loadName]
                    if isinstance(temp, int) or isinstance(temp, float):
                        temp = np.array(temp, dtype=np.float32)
                        loadedParam[0:] = np.repeat(temp, seqLen)
                    elif isinstance(temp, list):
                        loadedParam[0:] = temp[seqStart:seqEnd:seqSkip]
                    else:
                        raise ValueError("Invalid simulation parameter data type")
                loadedParams[loadName] = loadedParam

            if "rey" in self.simParams and "mach" in self.simParams:
                simParameters = np.stack([loadedParams["Reynolds Number"], loadedParams["Mach Number"]], axis=1)
            elif "rey" in self.simParams:
                simParameters = np.reshape(loadedParams["Reynolds Number"], (-1,1))
            elif "mach" in self.simParams:
                simParameters = np.reshape(loadedParams["Mach Number"], (-1,1))
            elif "zslice" in self.simParams:
                simParameters = np.reshape(loadedParams["Z Slice"], (-1,1))
            elif not self.simParams:
                simParameters ={}
            else:
                raise ValueError("Invalid specification of simulation parameters")

        # loading obstacle mask
        if os.path.isfile(os.path.join(basePath, "obstacle_mask.npz")):
            obsMask = np.load(os.path.join(basePath, "obstacle_mask.npz"))['arr_0']
        else:
            obsMask = None

        # loading fields and combining them with simulation parameters
        loaded = {}
        for field in self.simFields:
            loaded[field] = []

        for frame in range(seqStart, seqEnd, seqSkip):
            for field in self.simFields:
                loadedArr = np.load(os.path.join(basePath, "%s_%06d.npz" % (field,frame)))['arr_0']
                loaded[field] += [loadedArr.astype(np.float32)]

        loadedFields = []
        for field in self.simFields:
            loadedFields += [np.stack(loaded[field], axis=0)]

        if type(simParameters) is not dict:
            vel = loadedFields[0]
            if vel.ndim == 4:
                simParExpanded = simParameters[:,:,np.newaxis,np.newaxis]
                simParExpanded = np.repeat(np.repeat(simParExpanded, vel.shape[2], axis=2), vel.shape[3], axis=3)
            elif vel.ndim == 5:
                simParExpanded = simParameters[:,:,np.newaxis,np.newaxis,np.newaxis]
                simParExpanded = np.repeat(np.repeat(np.repeat(simParExpanded, vel.shape[2], axis=2), vel.shape[3], axis=3), vel.shape[4], axis=4)
            else:
                raise ValueError("Invalid input shape when loading samples!")
            loadedFields += [simParExpanded]

        data = np.concatenate(loadedFields, axis=1) # ORDER (fields): velocity (x,y), velocity z / density, pressure, ORDER (params): rey, mach, zslice

        # output
        dataPath = "%s/%s_%06d-%06d(%03d).npz" % (basePath, "-".join(self.simFields), seqStart, seqEnd - seqSkip, seqSkip)
        sample = {"data" : data, "simParameters" : simParameters, "allParameters" : loadedParams, "path" : dataPath}
        if obsMask is not None:
            sample["obsMask"] = obsMask

        if self.transform:
            sample = self.transform(sample)
        else:
            print("WARNING: no data transformations are employed!")

        return sample


    def printDatasetInfo(self):
        if self.transform:
            s  = "%s - Data Normalization Transformation: ACTIVE\n" % (self.name)
            self.summaryPrint += [s]
        print('\n'.join(self.summaryPrint))

    def getFilterInfoString(self) -> str:
        s  = "%s - Data Filter Setup: \n" % (self.name)
        s += "\tdataDirs: %s\n" % (str(self.dataDirs))
        s += "\tfilterTop: %s  exlude: %s\n" % (str(self.filterTop), self.excludeFilterTop)
        s += "\tfilterSim: %s  exlude: %s\n" % (str(self.filterSim), self.excludefilterSim)
        s += "\tfilterFrame: %s\n" % (str(self.filterFrame))
        s += "\tsequenceLength: %s\n" % (str(self.sequenceLength))
        return s
11/5:
class Residual(nn.Module):
    def __init__(self, fn):
        super().__init__()
        self.fn = fn

    def forward(self, x, *args, **kwargs):
        return self.fn(x, *args, **kwargs) + x

def Upsample(dim):
    return nn.ConvTranspose2d(dim, dim, 4, 2, 1)

def Downsample(dim):
    return nn.Conv2d(dim, dim, 4, 2, 1)


class SinusoidalPositionEmbeddings(nn.Module):
    def __init__(self, dim):
        super().__init__()
        self.dim = dim

    def forward(self, time):
        device = time.device
        half_dim = self.dim // 2
        embeddings = math.log(10000) / (half_dim - 1)
        embeddings = torch.exp(torch.arange(half_dim, device=device) * -embeddings)
        embeddings = time[:, None] * embeddings[None, :]
        embeddings = torch.cat((embeddings.sin(), embeddings.cos()), dim=-1)
        return embeddings
11/6:
class ConvNextBlock(nn.Module):

    def __init__(self, dim, dim_out, *, time_emb_dim=None, mult=2, norm=True):
        super().__init__()
        self.mlp = (
            nn.Sequential(nn.GELU(), nn.Linear(time_emb_dim, dim))
            if time_emb_dim is not None else None
        )

        self.ds_conv = nn.Conv2d(dim, dim, 7, padding=3, groups=dim)

        self.net = nn.Sequential(
            nn.GroupNorm(1, dim) if norm else nn.Identity(),
            nn.Conv2d(dim, dim_out * mult, 3, padding=1),
            nn.GELU(),
            nn.GroupNorm(1, dim_out * mult),
            nn.Conv2d(dim_out * mult, dim_out, 3, padding=1),
        )

        self.res_conv = nn.Conv2d(dim, dim_out, 1) if dim != dim_out else nn.Identity()

    def forward(self, x, time_emb=None):
        h = self.ds_conv(x)

        if self.mlp is not None and time_emb is not None:
            assert time_emb is not None, "time embedding must be passed in"
            condition = self.mlp(time_emb)
            h = h + rearrange(condition, "b c -> b c 1 1")

        h = self.net(h)
        return h + self.res_conv(x)
11/7:
class ConvNextBlock(nn.Module):

    def __init__(self, dim, dim_out, *, time_emb_dim=None, mult=2, norm=True):
        super().__init__()
        self.mlp = (
            nn.Sequential(nn.GELU(), nn.Linear(time_emb_dim, dim))
            if time_emb_dim is not None else None
        )

        self.ds_conv = nn.Conv2d(dim, dim, 7, padding=3, groups=dim)

        self.net = nn.Sequential(
            nn.GroupNorm(1, dim) if norm else nn.Identity(),
            nn.Conv2d(dim, dim_out * mult, 3, padding=1),
            nn.GELU(),
            nn.GroupNorm(1, dim_out * mult),
            nn.Conv2d(dim_out * mult, dim_out, 3, padding=1),
        )

        self.res_conv = nn.Conv2d(dim, dim_out, 1) if dim != dim_out else nn.Identity()

    def forward(self, x, time_emb=None):
        h = self.ds_conv(x)

        if self.mlp is not None and time_emb is not None:
            assert time_emb is not None, "time embedding must be passed in"
            condition = self.mlp(time_emb)
            h = h + rearrange(condition, "b c -> b c 1 1")

        h = self.net(h)
        return h + self.res_conv(x)
11/8:
class Attention(nn.Module):
    def __init__(self, dim, heads=4, dim_head=32):
        super().__init__()
        self.scale = dim_head**-0.5
        self.heads = heads
        hidden_dim = dim_head * heads
        self.to_qkv = nn.Conv2d(dim, hidden_dim * 3, 1, bias=False)
        self.to_out = nn.Conv2d(hidden_dim, dim, 1)

    def forward(self, x):
        b, c, h, w = x.shape
        qkv = self.to_qkv(x).chunk(3, dim=1)
        q, k, v = map(
            lambda t: rearrange(t, "b (h c) x y -> b h c (x y)", h=self.heads), qkv
        )
        q = q * self.scale

        sim = torch.einsum("b h d i, b h d j -> b h i j", q, k)
        sim = sim - sim.amax(dim=-1, keepdim=True).detach()
        attn = sim.softmax(dim=-1)

        out = torch.einsum("b h i j, b h d j -> b h i d", attn, v)
        out = rearrange(out, "b h (x y) d -> b (h d) x y", x=h, y=w)
        return self.to_out(out)


class LinearAttention(nn.Module):
    def __init__(self, dim, heads=4, dim_head=32):
        super().__init__()
        self.scale = dim_head**-0.5
        self.heads = heads
        hidden_dim = dim_head * heads
        self.to_qkv = nn.Conv2d(dim, hidden_dim * 3, 1, bias=False)

        self.to_out = nn.Sequential(nn.Conv2d(hidden_dim, dim, 1),
                                    nn.GroupNorm(1, dim))

    def forward(self, x):
        b, c, h, w = x.shape
        qkv = self.to_qkv(x).chunk(3, dim=1)
        q, k, v = map(
            lambda t: rearrange(t, "b (h c) x y -> b h c (x y)", h=self.heads), qkv
        )

        q = q.softmax(dim=-2)
        k = k.softmax(dim=-1)

        q = q * self.scale
        context = torch.einsum("b h d n, b h e n -> b h d e", k, v)

        out = torch.einsum("b h d e, b h d n -> b h e n", context, q)
        out = rearrange(out, "b h c (x y) -> b (h c) x y", h=self.heads, x=h, y=w)
        return self.to_out(out)
11/9:
class PreNorm(nn.Module):
    def __init__(self, dim, fn):
        super().__init__()
        self.fn = fn
        self.norm = nn.GroupNorm(1, dim)

    def forward(self, x):
        x = self.norm(x)
        return self.fn(x)


class Unet(nn.Module):
    def __init__(
        self,
        dim,
        init_dim=None,
        out_dim=None,
        dim_mults=(1, 2, 4, 8),
        channels=3,
        with_time_emb=True,
        resnet_block_groups=8,
        use_convnext=True,
        convnext_mult=2,
    ):
        super().__init__()

        # determine dimensions
        self.channels = channels

        init_dim = init_dim if init_dim is not None else dim // 3 * 2
        self.init_conv = nn.Conv2d(channels, init_dim, 7, padding=3)

        dims = [init_dim, *map(lambda m: dim * m, dim_mults)]
        in_out = list(zip(dims[:-1], dims[1:]))

        if use_convnext:
            block_klass = partial(ConvNextBlock, mult=convnext_mult)
        else:
            raise NotImplementedError()

        # time embeddings
        if with_time_emb:
            time_dim = dim * 4
            self.time_mlp = nn.Sequential(
                SinusoidalPositionEmbeddings(dim),
                nn.Linear(dim, time_dim),
                nn.GELU(),
                nn.Linear(time_dim, time_dim),
            )

        else:
            time_dim = None
            self.time_mlp = None
            self.cond_mlp = None
            self.sim_mlp = None

        # layers
        self.downs = nn.ModuleList([])
        self.ups = nn.ModuleList([])
        num_resolutions = len(in_out)

        for ind, (dim_in, dim_out) in enumerate(in_out):
            is_last = ind >= (num_resolutions - 1)

            self.downs.append(
                nn.ModuleList(
                    [
                        block_klass(dim_in, dim_out, time_emb_dim=time_dim),
                        block_klass(dim_out, dim_out, time_emb_dim=time_dim),
                        Residual(PreNorm(dim_out, LinearAttention(dim_out))),
                        Downsample(dim_out) if not is_last else nn.Identity(),
                    ]
                )
            )

        mid_dim = dims[-1]
        self.mid_block1 = block_klass(mid_dim, mid_dim, time_emb_dim=time_dim)
        self.mid_attn = Residual(PreNorm(mid_dim, Attention(mid_dim)))
        self.mid_block2 = block_klass(mid_dim, mid_dim, time_emb_dim=time_dim)

        for ind, (dim_in, dim_out) in enumerate(reversed(in_out[1:])):
            is_last = ind >= (num_resolutions - 1)

            self.ups.append(
                nn.ModuleList(
                    [
                        block_klass(dim_out * 2, dim_in, time_emb_dim=time_dim),
                        block_klass(dim_in, dim_in, time_emb_dim=time_dim),
                        Residual(PreNorm(dim_in, LinearAttention(dim_in))),
                        Upsample(dim_in) if not is_last else nn.Identity(),
                    ]
                )
            )

        out_dim = out_dim if out_dim is not None else channels
        self.final_conv = nn.Sequential(
            block_klass(dim, dim), nn.Conv2d(dim, out_dim, 1)
        )

    def forward(self, x, time):
        x = self.init_conv(x)

        t = self.time_mlp(time) if self.time_mlp is not None else None

        h = []

        # downsample
        for block1, block2, attn, downsample in self.downs:
            x = block1(x, t)
            x = block2(x, t)
            x = attn(x)
            h.append(x)
            x = downsample(x)

        # bottleneck
        x = self.mid_block1(x, t)
        x = self.mid_attn(x)
        x = self.mid_block2(x, t)

        # upsample
        for block1, block2, attn, upsample in self.ups:
            x = torch.cat((x, h.pop()), dim=1)
            x = block1(x, t)
            x = block2(x, t)
            x = attn(x)
            x = upsample(x)

        return self.final_conv(x)
11/10:
def linear_beta_schedule(timesteps):
    if timesteps < 10:
        raise ValueError("Warning: Less than 10 timesteps require adjustments to this schedule!")

    beta_start = 0.0001 * (500/timesteps) # adjust reference values determined for 500 steps
    beta_end = 0.02 * (500/timesteps)
    betas = torch.linspace(beta_start, beta_end, timesteps)
    return torch.clip(betas, 0.0001, 0.9999)
11/11:
class DiffusionModel(nn.Module):
    def __init__(self, diffusionSteps:int, condChannels:int, dataChannels:int):
        super(DiffusionModel, self).__init__()

        self.timesteps = diffusionSteps
        betas = linear_beta_schedule(timesteps=self.timesteps)

        betas = betas.unsqueeze(1).unsqueeze(2).unsqueeze(3)
        alphas = 1.0 - betas
        alphasCumprod = torch.cumprod(alphas, axis=0)
        alphasCumprodPrev = F.pad(alphasCumprod[:-1], (0,0,0,0,0,0,1,0), value=1.0)
        sqrtRecipAlphas = torch.sqrt(1.0 / alphas)

        # calculations for diffusion q(x_t | x_{t-1}) and others
        sqrtAlphasCumprod = torch.sqrt(alphasCumprod)
        sqrtOneMinusAlphasCumprod = torch.sqrt(1. - alphasCumprod)

        # calculations for posterior q(x_{t-1} | x_t, x_0)
        posteriorVariance = betas * (1. - alphasCumprodPrev) / (1. - alphasCumprod)
        sqrtPosteriorVariance = torch.sqrt(posteriorVariance)

        self.register_buffer("betas", betas)
        self.register_buffer("sqrtRecipAlphas", sqrtRecipAlphas)
        self.register_buffer("sqrtAlphasCumprod", sqrtAlphasCumprod)
        self.register_buffer("sqrtOneMinusAlphasCumprod", sqrtOneMinusAlphasCumprod)
        self.register_buffer("sqrtPosteriorVariance", sqrtPosteriorVariance)

        # backbone model
        self.unet = Unet(
            dim=128,
            channels= condChannels + dataChannels,
            dim_mults=(1,1,1),
            use_convnext=True,
            convnext_mult=1,
        )


    # input shape (both inputs): B S C W H (D) -> output shape (both outputs): B S nC W H (D)
    def forward(self, conditioning:torch.Tensor, data:torch.Tensor) -> torch.Tensor:
        device = "cuda" if data.is_cuda else "cpu"
        seqLen = data.shape[1]

        # combine batch and sequence dimension for decoder processing
        d = torch.reshape(data, (-1, data.shape[2], data.shape[3], data.shape[4]))
        cond = torch.reshape(conditioning, (-1, conditioning.shape[2], conditioning.shape[3], conditioning.shape[4]))

        # TRAINING
        if self.training:

            # forward diffusion process that adds noise to data
            d = torch.concat((cond, d), dim=1)
            noise = torch.randn_like(d, device=device)
            t = torch.randint(0, self.timesteps, (d.shape[0],), device=device).long()
            dNoisy = self.sqrtAlphasCumprod[t] * d + self.sqrtOneMinusAlphasCumprod[t] * noise

            # noise prediction with network
            predictedNoise = self.unet(dNoisy, t)

            # unstack batch and sequence dimension again
            noise = torch.reshape(noise, (-1, seqLen, conditioning.shape[2] + data.shape[2], data.shape[3], data.shape[4]))
            predictedNoise = torch.reshape(predictedNoise, (-1, seqLen, conditioning.shape[2] + data.shape[2], data.shape[3], data.shape[4]))

            return noise, predictedNoise


        # INFERENCE
        else:
            # conditioned reverse diffusion process
            dNoise = torch.randn_like(d, device=device)
            cNoise = torch.randn_like(cond, device=device)

            for i in reversed(range(0, self.timesteps)):
                t = i * torch.ones(cond.shape[0], device=device).long()

                # compute conditioned part with normal forward diffusion
                condNoisy = self.sqrtAlphasCumprod[t] * cond + self.sqrtOneMinusAlphasCumprod[t] * cNoise

                dNoiseCond = torch.concat((condNoisy, dNoise), dim=1)

                # backward diffusion process that removes noise to create data
                predictedNoiseCond = self.unet(dNoiseCond, t)

                # use model (noise predictor) to predict mean
                modelMean = self.sqrtRecipAlphas[t] * (dNoiseCond - self.betas[t] * predictedNoiseCond / self.sqrtOneMinusAlphasCumprod[t])

                dNoise = modelMean[:, cond.shape[1]:modelMean.shape[1]] # discard prediction of conditioning
                if i != 0:
                    # sample randomly (only for non-final prediction), use mean directly for final prediction
                    dNoise = dNoise + self.sqrtPosteriorVariance[t] * torch.randn_like(dNoise)

            # unstack batch and sequence dimension again
            dNoise = torch.reshape(dNoise, (-1, seqLen, data.shape[2], data.shape[3], data.shape[4]))

            return dNoise
11/12:
device = "cuda" if torch.cuda.is_available() else "cpu"
print("Training device: %s" % device)

startFromCheckpoint = True

batch = 32 # training batch size
if startFromCheckpoint:
    epochs = 10 # finetune only for a small number of epochs
    lr = 0.00001 # since the model is already trained, a conservatively low learning rate
else:
    epochs = 10000 # train from scratch for large number of epochs
    lr = 0.0001 # larger learning rate for training from scratch

sequenceLength = [3,2] # three timesteps (two input steps and one target step) with a temporal stride of 2
simFields = ["dens", "pres"] # the provided data set contains velocity (implict), as well as density and pressure values
simParams = ["mach"] # scalar simulation parameters on which the model is conditioned only contain the Mach number here
diffusionSteps = 20 # the provided model checkpoint was pretrained on 20 diffusion steps

# data set and data loading
trainSet = TurbulenceDataset("Training", ["data"], filterTop=["128_small_tra"], filterSim=[[0]], excludefilterSim=False, filterFrame=[(250,1000)],
                sequenceLength=[sequenceLength], randSeqOffset=True, simFields=simFields, simParams=simParams, printLevel="sim")
trainSet.transform = DataTransforms(normalizeMode="traMixed", simFields=simFields, simParams=simParams)
trainSet.printDatasetInfo()
trainSampler = RandomSampler(trainSet)
#trainSampler = SequentialSampler(trainSet)
trainLoader = DataLoader(trainSet, sampler=trainSampler, batch_size=batch, drop_last=True, num_workers=2)

# model definition
condChannels = 2 * (2 + len(simFields) + len(simParams))
dataChannels = 2 + len(simFields) + len(simParams)
model = DiffusionModel(diffusionSteps, condChannels, dataChannels)

if startFromCheckpoint:
    # load weights from checkpoint
    loaded = torch.load("models/models_tra/128_acdm-r20_02/Model.pth", map_location=torch.device('cpu'))
    model.load_state_dict(loaded["stateDictDecoder"])
model.train()
model.to(device)

# print model info and trainable weigths
paramsTrainable = sum([np.prod(p.size()) for p in filter(lambda p: p.requires_grad, model.parameters())])
params = sum([np.prod(p.size()) for p in model.parameters()])
#print(model)
print("Trainable Weights (All Weights): %d (%d)" % (paramsTrainable, params))

# training loop
print("\nStarting training...")
optimizer = torch.optim.Adam(model.parameters(), lr=lr)
for epoch in range(epochs):
    losses = []
    for s, sample in enumerate(trainLoader, 0):
        optimizer.zero_grad()

        d = sample["data"].to(device)

        inputSteps = 2
        cond = []
        for i in range(inputSteps):
            cond += [d[:,i:i+1]] # collect input steps
        conditioning = torch.concat(cond, dim=2) # combine along channel dimension
        data = d[:, inputSteps:inputSteps+1]

        noise, predictedNoise = model(conditioning=conditioning, data=data)

        loss = F.smooth_l1_loss(noise, predictedNoise)
        print("    [Epoch %2d, Batch %4d]: %1.7f" % (epoch, s, loss.detach().cpu().item()))
        loss.backward()

        losses += [loss.detach().cpu().item()]

        optimizer.step()
    print("[Epoch %2d, FULL]: %1.7f" % (epoch, sum(losses)/len(losses)))

print("Training complete!")
12/1:
!wget -nc "https://dataserv.ub.tum.de/s/m1734798.001/download?path=/&files=128_tra_small.zip" -O data/128_tra_small.zip --no-check-certificate 
!unzip -nq data/128_tra_small.zip -d data
!wget -nc "https://dataserv.ub.tum.de/s/m1734798.001/download?path=/&files=checkpoints_acdm_tra.zip" -O models/checkpoints_acdm_tra.zip --no-check-certificate 
!unzip -nq models/checkpoints_acdm_tra.zip -d models
12/2:
try:
    import google.colab  # only to ensure that we are inside colab
    !pip install einops
except ImportError:
    print("This notebook is running locally, please follow the ACDM installation instructions first, then continue with the cell below.")
    pass
12/3:
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader, SequentialSampler, RandomSampler

from einops import rearrange
from functools import partial

import matplotlib.pyplot as plt
import numpy as np

import math
import os, json
from typing import List,Tuple,Dict
12/4:
class TurbulenceDataset(Dataset):
    """Data set for turbulence and wavelet noise data

    Args:
        name: name of the dataset
        dataDirs: list of paths to data directories
        filterTop: filter for top level folder names (e.g. different types of data)
        excludeFilterTop: mode for filterTop (exclude or include)
        filterSim: filter simulations by min and max (min inclusive, max exclusive)
        excludefilterSim: mode for filterSim (exclude or include)
        filterFrame: mandatory filter for simulation frames by min and max (min inclusive, max exclusive)
        sequenceLength: number of frames to group into a sequence and number of frames to omit in between
        randSeqOffset: randomizes the starting frame of each sequence
        simFields: list of simulation fields to include (vel is always included) ["dens", "pres"]
        simParams: list of simulation parameters to include ["rey", "mach"]
        printLevel: print mode for contents of the dataset ["none", "top", "sim", "full"]
    """

    def __init__(self, name:str, dataDirs:List[str], filterTop:List[str], excludeFilterTop:bool=False, filterSim:List[Tuple[int, int]]=[],
                excludefilterSim:bool=False, filterFrame:List[Tuple[int, int]]=[], sequenceLength:List[Tuple[int, int]]=[],
                randSeqOffset:bool=False, simFields:List[str]=[], simParams:List[str]=[], printLevel:str="none"):

        self.transform = None
        self.name = name
        self.dataDirs = dataDirs
        self.filterTop = filterTop
        self.excludeFilterTop = excludeFilterTop
        self.filterSim = filterSim
        self.excludefilterSim = excludefilterSim
        self.filterFrame = filterFrame
        self.sequenceLength = sequenceLength
        self.randSeqOffset = randSeqOffset
        self.simFields = ["velocity"]
        if "dens" in simFields:
            self.simFields += ["density"]
        if "pres" in simFields:
            self.simFields += ["pressure"]

        self.simParams = simParams
        self.printLevel = printLevel

        self.summaryPrint = []
        self.summaryPrint += ["Dataset " + name + " at " + str(dataDirs)]
        self.summaryPrint += [self.getFilterInfoString()]

        # BUILD FULL FILE LIST
        self.dataPaths = []
        self.dataPathModes = []

        for dataDir in dataDirs:
            topDirs = os.listdir(dataDir)
            topDirs.sort()

            # top level folders
            for topDir in topDirs:
                if filterTop:
                    # continue when excluding or including according to filter
                    if excludeFilterTop == any( item in topDir for item in filterTop ):
                        continue

                match = -1
                # compute matching top filter for according sim or frame filtering
                if len(filterSim) > 1 or len(filterFrame) > 1:
                    for i in range(len(filterTop)):
                        if filterTop[i] in topDir:
                            match = i
                            break
                    assert (match >= 0), "Match computation error"

                simDir = os.path.join(dataDir, topDir)
                sims = os.listdir(simDir)
                sims.sort()

                if printLevel == "top":
                    self.summaryPrint += ["Top folder loaded: " + simDir.replace(dataDir + "/", "")]

                # sim_000001 folders
                for sim in sims:
                    currentDir = os.path.join(simDir, sim)
                    if not os.path.isdir(currentDir):
                        continue

                    if len(filterSim) > 0:
                        simNum = int(sim.split("_")[1])
                        if len(filterSim) == 1:
                            if type(filterSim[0]) is tuple:
                                inside = simNum >= filterSim[0][0] and simNum < filterSim[0][1]
                            elif type(filterSim[0]) is list:
                                inside = simNum in filterSim[0]
                        else:
                            if type(filterSim[match]) is tuple:
                                inside = simNum >= filterSim[match][0] and simNum < filterSim[match][1]
                            elif type(filterSim[match]) is list:
                                inside = simNum in filterSim[match]
                        # continue when excluding or including according to filter
                        if inside == excludefilterSim:
                            continue

                    if printLevel == "sim":
                        self.summaryPrint += ["Sim loaded: " + currentDir.replace(dataDir + "/", "")]

                    # individual simulation frames
                    minFrame = filterFrame[0][0] if len(filterFrame) == 1 else filterFrame[match][0]
                    maxFrame = filterFrame[0][1] if len(filterFrame) == 1 else filterFrame[match][1]
                    seqLength = sequenceLength[0][0] if len(sequenceLength) == 1 else sequenceLength[match][0]
                    seqSkip   = sequenceLength[0][1] if len(sequenceLength) == 1 else sequenceLength[match][1]
                    for seqStart in range(minFrame, maxFrame, seqLength*seqSkip):
                        validSeq = True
                        for frame in range(seqStart, seqStart+seqLength*seqSkip, seqSkip):
                            # discard incomplete sequences at simulation end
                            if seqStart+seqLength*seqSkip > maxFrame:
                                validSeq = False
                                break

                            for field in self.simFields:
                                currentField = os.path.join(currentDir, "%s_%06d.npz" % (field, frame))
                                if not os.path.isfile(currentField):
                                    raise FileNotFoundError("Could not load %s file: %s" % (field, currentField))

                        # imcomplete sequence means there are no more frames left
                        if not validSeq:
                            break

                        if printLevel == "full":
                            self.summaryPrint += ["Frames %s loaded: %s/%s_%06d-%06d(%03d).npz" % ("-".join(self.simFields),
                                        currentDir.replace(dataDir + "/", ""), "-".join(self.simFields), seqStart, seqStart + seqLength*(seqSkip-1), seqSkip)]

                        self.dataPaths.append((currentDir, seqStart, seqStart + seqLength*seqSkip, seqSkip))

        self.summaryPrint += ["Dataset Length: %d\n" % len(self.dataPaths)]


    def __len__(self) -> int:
        return len(self.dataPaths)


    def __getitem__(self, idx:int) -> dict:
        # sequence indexing
        basePath, seqStart, seqEnd, seqSkip = self.dataPaths[idx]
        seqLen = int((seqEnd - seqStart) / seqSkip)
        if self.randSeqOffset:
            halfSeq = int((seqEnd-seqStart) / 2)
            offset = torch.randint(-halfSeq, halfSeq+1, (1,)).item()
            if seqStart + offset >= self.filterFrame[0][0] and seqEnd + offset < self.filterFrame[0][1]:
                seqStart = seqStart + offset
                seqEnd = seqEnd + offset

        # loading simulation parameters
        with open(os.path.join(basePath, "src", "description.json")) as f:
            loadedJSON = json.load(f)

            loadNames = ["Reynolds Number", "Mach Number", "Drag Coefficient", "Lift Coefficient", "Z Slice"]
            loadedParams = {}
            for loadName in loadNames:
                loadedParam = np.zeros(seqLen, dtype=np.float32)
                if loadName in loadedJSON:
                    temp = loadedJSON[loadName]
                    if isinstance(temp, int) or isinstance(temp, float):
                        temp = np.array(temp, dtype=np.float32)
                        loadedParam[0:] = np.repeat(temp, seqLen)
                    elif isinstance(temp, list):
                        loadedParam[0:] = temp[seqStart:seqEnd:seqSkip]
                    else:
                        raise ValueError("Invalid simulation parameter data type")
                loadedParams[loadName] = loadedParam

            if "rey" in self.simParams and "mach" in self.simParams:
                simParameters = np.stack([loadedParams["Reynolds Number"], loadedParams["Mach Number"]], axis=1)
            elif "rey" in self.simParams:
                simParameters = np.reshape(loadedParams["Reynolds Number"], (-1,1))
            elif "mach" in self.simParams:
                simParameters = np.reshape(loadedParams["Mach Number"], (-1,1))
            elif "zslice" in self.simParams:
                simParameters = np.reshape(loadedParams["Z Slice"], (-1,1))
            elif not self.simParams:
                simParameters ={}
            else:
                raise ValueError("Invalid specification of simulation parameters")

        # loading obstacle mask
        if os.path.isfile(os.path.join(basePath, "obstacle_mask.npz")):
            obsMask = np.load(os.path.join(basePath, "obstacle_mask.npz"))['arr_0']
        else:
            obsMask = None

        # loading fields and combining them with simulation parameters
        loaded = {}
        for field in self.simFields:
            loaded[field] = []

        for frame in range(seqStart, seqEnd, seqSkip):
            for field in self.simFields:
                loadedArr = np.load(os.path.join(basePath, "%s_%06d.npz" % (field,frame)))['arr_0']
                loaded[field] += [loadedArr.astype(np.float32)]

        loadedFields = []
        for field in self.simFields:
            loadedFields += [np.stack(loaded[field], axis=0)]

        if type(simParameters) is not dict:
            vel = loadedFields[0]
            if vel.ndim == 4:
                simParExpanded = simParameters[:,:,np.newaxis,np.newaxis]
                simParExpanded = np.repeat(np.repeat(simParExpanded, vel.shape[2], axis=2), vel.shape[3], axis=3)
            elif vel.ndim == 5:
                simParExpanded = simParameters[:,:,np.newaxis,np.newaxis,np.newaxis]
                simParExpanded = np.repeat(np.repeat(np.repeat(simParExpanded, vel.shape[2], axis=2), vel.shape[3], axis=3), vel.shape[4], axis=4)
            else:
                raise ValueError("Invalid input shape when loading samples!")
            loadedFields += [simParExpanded]

        data = np.concatenate(loadedFields, axis=1) # ORDER (fields): velocity (x,y), velocity z / density, pressure, ORDER (params): rey, mach, zslice

        # output
        dataPath = "%s/%s_%06d-%06d(%03d).npz" % (basePath, "-".join(self.simFields), seqStart, seqEnd - seqSkip, seqSkip)
        sample = {"data" : data, "simParameters" : simParameters, "allParameters" : loadedParams, "path" : dataPath}
        if obsMask is not None:
            sample["obsMask"] = obsMask

        if self.transform:
            sample = self.transform(sample)
        else:
            print("WARNING: no data transformations are employed!")

        return sample


    def printDatasetInfo(self):
        if self.transform:
            s  = "%s - Data Normalization Transformation: ACTIVE\n" % (self.name)
            self.summaryPrint += [s]
        print('\n'.join(self.summaryPrint))

    def getFilterInfoString(self) -> str:
        s  = "%s - Data Filter Setup: \n" % (self.name)
        s += "\tdataDirs: %s\n" % (str(self.dataDirs))
        s += "\tfilterTop: %s  exlude: %s\n" % (str(self.filterTop), self.excludeFilterTop)
        s += "\tfilterSim: %s  exlude: %s\n" % (str(self.filterSim), self.excludefilterSim)
        s += "\tfilterFrame: %s\n" % (str(self.filterFrame))
        s += "\tsequenceLength: %s\n" % (str(self.sequenceLength))
        return s
12/5:
class DataTransforms(object):

    def __init__(self, normalizeMode="traMixed", simFields=["dens","pres"], simParams=["mach"]):
        self.simFields = simFields
        self.simParams = simParams

        # mean and std statistics from whole dataset for normalization
        if "tra" in normalizeMode.lower() and "mixed" in normalizeMode.lower():
            # ORDER (fields): velocity (x,y), density, pressure, ORDER (params): rey, mach
            self.normMean = np.array([0.560642, -0.000129, 0.903352, 0.637941, 10000.000000, 0.700000], dtype=np.float32)
            self.normStd =  np.array([0.216987, 0.216987, 0.145391, 0.119944, 1, 0.118322], dtype=np.float32)


    def __call__(self, sample:dict):
        data = sample["data"]
        simParameters = sample["simParameters"]
        allParameters = sample["allParameters"]
        obsMask = sample.get("obsMask", None)
        path = sample["path"]

        # normalization to std. normal distr. with zero mean and unit std via statistics from whole dataset
        # ORDER (fields): velocity (x,y), velocity z / density, pressure, ORDER (params): rey, mach
        filterList = [0, 1]
        if "dens" in self.simFields:
            filterList += [2]
        if "pres" in self.simFields:
            filterList += [3]
        if "rey" in self.simParams:
            filterList += [4]
        if "mach" in self.simParams:
            filterList += [5]
        filterArr = np.array(filterList)
        filterArrParam = filterArr[-len(self.simParams):]

        if self.simParams:
            meanParam = self.normMean[filterArrParam].reshape((1,-1))
            stdParam = self.normStd[filterArrParam].reshape((1,-1))
            simParameters = (simParameters - meanParam) / stdParam

        meanData = self.normMean[filterArr].reshape((1,-1,1,1))
        stdData = self.normStd[filterArr].reshape((1,-1,1,1))
        data = (data - meanData) / stdData

        # toTensor
        result = torch.from_numpy(data)
        if obsMask is not None:
            obsMask = torch.from_numpy(obsMask)

        outDict = {"data": result, "simParameters": simParameters, "allParameters": allParameters, "path": path}
        if obsMask is not None:
            outDict["obsMask"] = obsMask
        return outDict
12/6:
class Residual(nn.Module):
    def __init__(self, fn):
        super().__init__()
        self.fn = fn

    def forward(self, x, *args, **kwargs):
        return self.fn(x, *args, **kwargs) + x

def Upsample(dim):
    return nn.ConvTranspose2d(dim, dim, 4, 2, 1)

def Downsample(dim):
    return nn.Conv2d(dim, dim, 4, 2, 1)


class SinusoidalPositionEmbeddings(nn.Module):
    def __init__(self, dim):
        super().__init__()
        self.dim = dim

    def forward(self, time):
        device = time.device
        half_dim = self.dim // 2
        embeddings = math.log(10000) / (half_dim - 1)
        embeddings = torch.exp(torch.arange(half_dim, device=device) * -embeddings)
        embeddings = time[:, None] * embeddings[None, :]
        embeddings = torch.cat((embeddings.sin(), embeddings.cos()), dim=-1)
        return embeddings
12/7:
class ConvNextBlock(nn.Module):

    def __init__(self, dim, dim_out, *, time_emb_dim=None, mult=2, norm=True):
        super().__init__()
        self.mlp = (
            nn.Sequential(nn.GELU(), nn.Linear(time_emb_dim, dim))
            if time_emb_dim is not None else None
        )

        self.ds_conv = nn.Conv2d(dim, dim, 7, padding=3, groups=dim)

        self.net = nn.Sequential(
            nn.GroupNorm(1, dim) if norm else nn.Identity(),
            nn.Conv2d(dim, dim_out * mult, 3, padding=1),
            nn.GELU(),
            nn.GroupNorm(1, dim_out * mult),
            nn.Conv2d(dim_out * mult, dim_out, 3, padding=1),
        )

        self.res_conv = nn.Conv2d(dim, dim_out, 1) if dim != dim_out else nn.Identity()

    def forward(self, x, time_emb=None):
        h = self.ds_conv(x)

        if self.mlp is not None and time_emb is not None:
            assert time_emb is not None, "time embedding must be passed in"
            condition = self.mlp(time_emb)
            h = h + rearrange(condition, "b c -> b c 1 1")

        h = self.net(h)
        return h + self.res_conv(x)
12/8:
class Attention(nn.Module):
    def __init__(self, dim, heads=4, dim_head=32):
        super().__init__()
        self.scale = dim_head**-0.5
        self.heads = heads
        hidden_dim = dim_head * heads
        self.to_qkv = nn.Conv2d(dim, hidden_dim * 3, 1, bias=False)
        self.to_out = nn.Conv2d(hidden_dim, dim, 1)

    def forward(self, x):
        b, c, h, w = x.shape
        qkv = self.to_qkv(x).chunk(3, dim=1)
        q, k, v = map(
            lambda t: rearrange(t, "b (h c) x y -> b h c (x y)", h=self.heads), qkv
        )
        q = q * self.scale

        sim = torch.einsum("b h d i, b h d j -> b h i j", q, k)
        sim = sim - sim.amax(dim=-1, keepdim=True).detach()
        attn = sim.softmax(dim=-1)

        out = torch.einsum("b h i j, b h d j -> b h i d", attn, v)
        out = rearrange(out, "b h (x y) d -> b (h d) x y", x=h, y=w)
        return self.to_out(out)


class LinearAttention(nn.Module):
    def __init__(self, dim, heads=4, dim_head=32):
        super().__init__()
        self.scale = dim_head**-0.5
        self.heads = heads
        hidden_dim = dim_head * heads
        self.to_qkv = nn.Conv2d(dim, hidden_dim * 3, 1, bias=False)

        self.to_out = nn.Sequential(nn.Conv2d(hidden_dim, dim, 1),
                                    nn.GroupNorm(1, dim))

    def forward(self, x):
        b, c, h, w = x.shape
        qkv = self.to_qkv(x).chunk(3, dim=1)
        q, k, v = map(
            lambda t: rearrange(t, "b (h c) x y -> b h c (x y)", h=self.heads), qkv
        )

        q = q.softmax(dim=-2)
        k = k.softmax(dim=-1)

        q = q * self.scale
        context = torch.einsum("b h d n, b h e n -> b h d e", k, v)

        out = torch.einsum("b h d e, b h d n -> b h e n", context, q)
        out = rearrange(out, "b h c (x y) -> b (h c) x y", h=self.heads, x=h, y=w)
        return self.to_out(out)
12/9:
class PreNorm(nn.Module):
    def __init__(self, dim, fn):
        super().__init__()
        self.fn = fn
        self.norm = nn.GroupNorm(1, dim)

    def forward(self, x):
        x = self.norm(x)
        return self.fn(x)


class Unet(nn.Module):
    def __init__(
        self,
        dim,
        init_dim=None,
        out_dim=None,
        dim_mults=(1, 2, 4, 8),
        channels=3,
        with_time_emb=True,
        resnet_block_groups=8,
        use_convnext=True,
        convnext_mult=2,
    ):
        super().__init__()

        # determine dimensions
        self.channels = channels

        init_dim = init_dim if init_dim is not None else dim // 3 * 2
        self.init_conv = nn.Conv2d(channels, init_dim, 7, padding=3)

        dims = [init_dim, *map(lambda m: dim * m, dim_mults)]
        in_out = list(zip(dims[:-1], dims[1:]))

        if use_convnext:
            block_klass = partial(ConvNextBlock, mult=convnext_mult)
        else:
            raise NotImplementedError()

        # time embeddings
        if with_time_emb:
            time_dim = dim * 4
            self.time_mlp = nn.Sequential(
                SinusoidalPositionEmbeddings(dim),
                nn.Linear(dim, time_dim),
                nn.GELU(),
                nn.Linear(time_dim, time_dim),
            )

        else:
            time_dim = None
            self.time_mlp = None
            self.cond_mlp = None
            self.sim_mlp = None

        # layers
        self.downs = nn.ModuleList([])
        self.ups = nn.ModuleList([])
        num_resolutions = len(in_out)

        for ind, (dim_in, dim_out) in enumerate(in_out):
            is_last = ind >= (num_resolutions - 1)

            self.downs.append(
                nn.ModuleList(
                    [
                        block_klass(dim_in, dim_out, time_emb_dim=time_dim),
                        block_klass(dim_out, dim_out, time_emb_dim=time_dim),
                        Residual(PreNorm(dim_out, LinearAttention(dim_out))),
                        Downsample(dim_out) if not is_last else nn.Identity(),
                    ]
                )
            )

        mid_dim = dims[-1]
        self.mid_block1 = block_klass(mid_dim, mid_dim, time_emb_dim=time_dim)
        self.mid_attn = Residual(PreNorm(mid_dim, Attention(mid_dim)))
        self.mid_block2 = block_klass(mid_dim, mid_dim, time_emb_dim=time_dim)

        for ind, (dim_in, dim_out) in enumerate(reversed(in_out[1:])):
            is_last = ind >= (num_resolutions - 1)

            self.ups.append(
                nn.ModuleList(
                    [
                        block_klass(dim_out * 2, dim_in, time_emb_dim=time_dim),
                        block_klass(dim_in, dim_in, time_emb_dim=time_dim),
                        Residual(PreNorm(dim_in, LinearAttention(dim_in))),
                        Upsample(dim_in) if not is_last else nn.Identity(),
                    ]
                )
            )

        out_dim = out_dim if out_dim is not None else channels
        self.final_conv = nn.Sequential(
            block_klass(dim, dim), nn.Conv2d(dim, out_dim, 1)
        )

    def forward(self, x, time):
        x = self.init_conv(x)

        t = self.time_mlp(time) if self.time_mlp is not None else None

        h = []

        # downsample
        for block1, block2, attn, downsample in self.downs:
            x = block1(x, t)
            x = block2(x, t)
            x = attn(x)
            h.append(x)
            x = downsample(x)

        # bottleneck
        x = self.mid_block1(x, t)
        x = self.mid_attn(x)
        x = self.mid_block2(x, t)

        # upsample
        for block1, block2, attn, upsample in self.ups:
            x = torch.cat((x, h.pop()), dim=1)
            x = block1(x, t)
            x = block2(x, t)
            x = attn(x)
            x = upsample(x)

        return self.final_conv(x)
12/10:
def linear_beta_schedule(timesteps):
    if timesteps < 10:
        raise ValueError("Warning: Less than 10 timesteps require adjustments to this schedule!")

    beta_start = 0.0001 * (500/timesteps) # adjust reference values determined for 500 steps
    beta_end = 0.02 * (500/timesteps)
    betas = torch.linspace(beta_start, beta_end, timesteps)
    return torch.clip(betas, 0.0001, 0.9999)
12/11:
class DiffusionModel(nn.Module):
    def __init__(self, diffusionSteps:int, condChannels:int, dataChannels:int):
        super(DiffusionModel, self).__init__()

        self.timesteps = diffusionSteps
        betas = linear_beta_schedule(timesteps=self.timesteps)

        betas = betas.unsqueeze(1).unsqueeze(2).unsqueeze(3)
        alphas = 1.0 - betas
        alphasCumprod = torch.cumprod(alphas, axis=0)
        alphasCumprodPrev = F.pad(alphasCumprod[:-1], (0,0,0,0,0,0,1,0), value=1.0)
        sqrtRecipAlphas = torch.sqrt(1.0 / alphas)

        # calculations for diffusion q(x_t | x_{t-1}) and others
        sqrtAlphasCumprod = torch.sqrt(alphasCumprod)
        sqrtOneMinusAlphasCumprod = torch.sqrt(1. - alphasCumprod)

        # calculations for posterior q(x_{t-1} | x_t, x_0)
        posteriorVariance = betas * (1. - alphasCumprodPrev) / (1. - alphasCumprod)
        sqrtPosteriorVariance = torch.sqrt(posteriorVariance)

        self.register_buffer("betas", betas)
        self.register_buffer("sqrtRecipAlphas", sqrtRecipAlphas)
        self.register_buffer("sqrtAlphasCumprod", sqrtAlphasCumprod)
        self.register_buffer("sqrtOneMinusAlphasCumprod", sqrtOneMinusAlphasCumprod)
        self.register_buffer("sqrtPosteriorVariance", sqrtPosteriorVariance)

        # backbone model
        self.unet = Unet(
            dim=128,
            channels= condChannels + dataChannels,
            dim_mults=(1,1,1),
            use_convnext=True,
            convnext_mult=1,
        )


    # input shape (both inputs): B S C W H (D) -> output shape (both outputs): B S nC W H (D)
    def forward(self, conditioning:torch.Tensor, data:torch.Tensor) -> torch.Tensor:
        device = "cuda" if data.is_cuda else "cpu"
        seqLen = data.shape[1]

        # combine batch and sequence dimension for decoder processing
        d = torch.reshape(data, (-1, data.shape[2], data.shape[3], data.shape[4]))
        cond = torch.reshape(conditioning, (-1, conditioning.shape[2], conditioning.shape[3], conditioning.shape[4]))

        # TRAINING
        if self.training:

            # forward diffusion process that adds noise to data
            d = torch.concat((cond, d), dim=1)
            noise = torch.randn_like(d, device=device)
            t = torch.randint(0, self.timesteps, (d.shape[0],), device=device).long()
            dNoisy = self.sqrtAlphasCumprod[t] * d + self.sqrtOneMinusAlphasCumprod[t] * noise

            # noise prediction with network
            predictedNoise = self.unet(dNoisy, t)

            # unstack batch and sequence dimension again
            noise = torch.reshape(noise, (-1, seqLen, conditioning.shape[2] + data.shape[2], data.shape[3], data.shape[4]))
            predictedNoise = torch.reshape(predictedNoise, (-1, seqLen, conditioning.shape[2] + data.shape[2], data.shape[3], data.shape[4]))

            return noise, predictedNoise


        # INFERENCE
        else:
            # conditioned reverse diffusion process
            dNoise = torch.randn_like(d, device=device)
            cNoise = torch.randn_like(cond, device=device)

            for i in reversed(range(0, self.timesteps)):
                t = i * torch.ones(cond.shape[0], device=device).long()

                # compute conditioned part with normal forward diffusion
                condNoisy = self.sqrtAlphasCumprod[t] * cond + self.sqrtOneMinusAlphasCumprod[t] * cNoise

                dNoiseCond = torch.concat((condNoisy, dNoise), dim=1)

                # backward diffusion process that removes noise to create data
                predictedNoiseCond = self.unet(dNoiseCond, t)

                # use model (noise predictor) to predict mean
                modelMean = self.sqrtRecipAlphas[t] * (dNoiseCond - self.betas[t] * predictedNoiseCond / self.sqrtOneMinusAlphasCumprod[t])

                dNoise = modelMean[:, cond.shape[1]:modelMean.shape[1]] # discard prediction of conditioning
                if i != 0:
                    # sample randomly (only for non-final prediction), use mean directly for final prediction
                    dNoise = dNoise + self.sqrtPosteriorVariance[t] * torch.randn_like(dNoise)

            # unstack batch and sequence dimension again
            dNoise = torch.reshape(dNoise, (-1, seqLen, data.shape[2], data.shape[3], data.shape[4]))

            return dNoise
12/12:
device = "cuda" if torch.cuda.is_available() else "cpu"
print("Training device: %s" % device)

startFromCheckpoint = True

batch = 32 # training batch size
if startFromCheckpoint:
    epochs = 10 # finetune only for a small number of epochs
    lr = 0.00001 # since the model is already trained, a conservatively low learning rate
else:
    epochs = 10000 # train from scratch for large number of epochs
    lr = 0.0001 # larger learning rate for training from scratch

sequenceLength = [3,2] # three timesteps (two input steps and one target step) with a temporal stride of 2
simFields = ["dens", "pres"] # the provided data set contains velocity (implict), as well as density and pressure values
simParams = ["mach"] # scalar simulation parameters on which the model is conditioned only contain the Mach number here
diffusionSteps = 20 # the provided model checkpoint was pretrained on 20 diffusion steps

# data set and data loading
trainSet = TurbulenceDataset("Training", ["data"], filterTop=["128_small_tra"], filterSim=[[0]], excludefilterSim=False, filterFrame=[(250,1000)],
                sequenceLength=[sequenceLength], randSeqOffset=True, simFields=simFields, simParams=simParams, printLevel="sim")
trainSet.transform = DataTransforms(normalizeMode="traMixed", simFields=simFields, simParams=simParams)
trainSet.printDatasetInfo()
trainSampler = RandomSampler(trainSet)
#trainSampler = SequentialSampler(trainSet)
trainLoader = DataLoader(trainSet, sampler=trainSampler, batch_size=batch, drop_last=True, num_workers=2)

# model definition
condChannels = 2 * (2 + len(simFields) + len(simParams))
dataChannels = 2 + len(simFields) + len(simParams)
model = DiffusionModel(diffusionSteps, condChannels, dataChannels)

if startFromCheckpoint:
    # load weights from checkpoint
    loaded = torch.load("models/models_tra/128_acdm-r20_02/Model.pth", map_location=torch.device('cpu'))
    model.load_state_dict(loaded["stateDictDecoder"])
model.train()
model.to(device)

# print model info and trainable weigths
paramsTrainable = sum([np.prod(p.size()) for p in filter(lambda p: p.requires_grad, model.parameters())])
params = sum([np.prod(p.size()) for p in model.parameters()])
#print(model)
print("Trainable Weights (All Weights): %d (%d)" % (paramsTrainable, params))

# training loop
print("\nStarting training...")
optimizer = torch.optim.Adam(model.parameters(), lr=lr)
for epoch in range(epochs):
    losses = []
    for s, sample in enumerate(trainLoader, 0):
        optimizer.zero_grad()

        d = sample["data"].to(device)

        inputSteps = 2
        cond = []
        for i in range(inputSteps):
            cond += [d[:,i:i+1]] # collect input steps
        conditioning = torch.concat(cond, dim=2) # combine along channel dimension
        data = d[:, inputSteps:inputSteps+1]

        noise, predictedNoise = model(conditioning=conditioning, data=data)

        loss = F.smooth_l1_loss(noise, predictedNoise)
        print("    [Epoch %2d, Batch %4d]: %1.7f" % (epoch, s, loss.detach().cpu().item()))
        loss.backward()

        losses += [loss.detach().cpu().item()]

        optimizer.step()
    print("[Epoch %2d, FULL]: %1.7f" % (epoch, sum(losses)/len(losses)))

print("Training complete!")
12/13:
device = "cuda" if torch.cuda.is_available() else "cpu"

numSamples = 5
sequenceLength = [60,2]
simFields = ["dens", "pres"]
simParams = ["mach"]
diffusionSteps = 20

try: # load model if not trained/finetuned above
    model
except NameError:
    condChannels = 2 * (2 + len(simFields) + len(simParams))
    dataChannels = 2 + len(simFields) + len(simParams)
    model = DiffusionModel(diffusionSteps, condChannels, dataChannels)

    # load weights from checkpoint
    loaded = torch.load("models/models_tra/128_acdm-r20_02/Model.pth", map_location=torch.device('cpu'))
    model.load_state_dict(loaded["stateDictDecoder"])
model.eval()
model.to(device)

testSet = TurbulenceDataset("Test", ["data"], filterTop=["128_small_tra"], filterSim=[[0]], excludefilterSim=False, filterFrame=[(0,250)],
                sequenceLength=[sequenceLength], randSeqOffset=False, simFields=simFields, simParams=simParams, printLevel="sim")
testSet.transform = DataTransforms(normalizeMode="traMixed", simFields=simFields, simParams=simParams)
testSet.printDatasetInfo()
testSampler = SequentialSampler(testSet)
testLoader = DataLoader(testSet, sampler=testSampler, batch_size=1, drop_last=False)

# sampling loop
print("\nStarting sampling...")
gt = []
pred = []
with torch.no_grad():
    for s, sample in enumerate(testLoader, 0):
        gt += [sample["data"].unsqueeze(0).cpu().numpy()]
        d = sample["data"].to(device).repeat(numSamples,1,1,1,1) # reuse batch dim for samples

        prediction = torch.zeros_like(d, device=device)
        inputSteps = 2

        for i in range(inputSteps): # no prediction of first steps
            prediction[:,i] = d[:,i]

        for i in range(inputSteps, d.shape[1]):
            cond = []
            for j in range(inputSteps,0,-1):
                cond += [prediction[:, i-j : i-(j-1)]] # collect input steps
            cond = torch.concat(cond, dim=2) # combine along channel dimension

            result = model(conditioning=cond, data=d[:,i-1:i]) # auto-regressive inference
            result[:,:,-len(simParams):] = d[:,i:i+1,-len(simParams):] # replace simparam prediction with true values
            prediction[:,i:i+1] = result

        prediction = torch.reshape(prediction, (numSamples, -1, d.shape[1], d.shape[2], d.shape[3], d.shape[4]))
        pred += [prediction.cpu().numpy()]
        print("  Sequence %d finished" % s)


print("Sampling complete!\n")

gt = np.concatenate(gt, axis=1)
pred = np.concatenate(pred, axis=1)

# undo data normalization
normMean = testSet.transform.normMean[[0,1,2,3,5]]
normStd = testSet.transform.normStd[[0,1,2,3,5]]
normMean = np.expand_dims(normMean, axis=(0,1,2,4,5))
normStd = np.expand_dims(normStd, axis=(0,1,2,4,5))
gt = (gt * normStd) + normMean
pred = (pred * normStd) + normMean

print("Ground truth and prediction tensor with shape:")
print("(samples, sequences, sequenceLength, channels, sizeX, sizeY)")
print("GT: %s" % str(gt.shape))
print("Prediction: %s" % str(pred.shape))
12/14:
sequence = 0
samples = [0,4]
timeSteps = [0,19,39,59]
field = 3 # velocity_x (0), velocity_y (1), density (2), or pressure (3)

predPart = pred[samples]
gtPred = np.concatenate([gt[:,sequence,timeSteps,field], predPart[:,sequence,timeSteps,field]])

fig, axs = plt.subplots(nrows=gtPred.shape[0], ncols=gtPred.shape[1], figsize=(gtPred.shape[1]*1.9, gtPred.shape[0]), dpi=150, squeeze=False)

for i in range(gtPred.shape[0]):
    for j in range(gtPred.shape[1]):
        if i == gtPred.shape[0]-1:
            axs[i,j].set_xlabel("$t=%s$" % (timeSteps[j]+1), fontsize=10)
        if j == 0:
            if i == 0:
              axs[i,j].set_ylabel("Ground\nTruth", fontsize=10)
            else:
              axs[i,j].set_ylabel("ACDM\nSample %d" % i, fontsize=10)
        axs[i,j].set_xticks([])
        axs[i,j].set_yticks([])
        im = axs[i,j].imshow(gtPred[i][j].transpose(), interpolation="catrom", cmap="viridis")

plt.show()
12/15:
gtTemp = gt[:,:,:,0:4] # ignore scalar Mach number here
predTemp = pred[:,:,:,0:4]

diffGt = np.abs( gtTemp[:,:,1:gtTemp.shape[2]-1] - gtTemp[:,:,2:gtTemp.shape[2]])
diffGt = np.mean(diffGt, axis=(3,4,5)) # channel-wise and spatial mean
minGt = np.min(diffGt, axis=(0,1)) # lower bound over sequences
maxGt = np.max(diffGt, axis=(0,1)) # upper bound over sequences
meanGt = np.mean(diffGt, axis=(0,1)) # sample- and sequence mean

diffPred = np.abs( predTemp[:,:,1:predTemp.shape[2]-1] - predTemp[:,:,2:predTemp.shape[2]])
diffPred = np.mean(diffPred, axis=(3,4,5)) # channel-wise and spatial mean
minPred = np.min(diffPred, axis=(0,1)) # lower bound over samples and sequences
maxPred = np.max(diffPred, axis=(0,1)) # upper bound over samples and sequences
meanPred = np.mean(diffPred, axis=(0,1)) # sample- and sequence mean


fig, ax = plt.subplots(1, figsize=(5,2), dpi=150)
ax.set_title("Temporal Stability")
ax.set_ylabel("$\Vert \, (s^{t} - s^{t-1}) / \Delta t \, \Vert_1$")
ax.yaxis.grid(True)
ax.set_xlabel("Time step $t$")

ax.plot(np.arange(meanGt.shape[0]), meanGt, color="k", label="Simulation", linestyle="dashed")
ax.fill_between(np.arange(meanGt.shape[0]), minGt, maxGt, facecolor="k", alpha=0.15)

ax.plot(np.arange(meanPred.shape[0]), meanPred, color="tab:orange", label="ACDM")
ax.fill_between(np.arange(meanPred.shape[0]), minPred, maxPred, facecolor="tab:orange", alpha=0.15)

fig.legend()
plt.show()
12/16:
sequence = 0
fracX = 0.25 # closely behing the cylinder
fracY = 0.5 # vertically centered
field = 1 # velocity_x (0), velocity_y (1), density (2), or pressure (3)

posX = int(fracX * gt.shape[4])
posY = int(fracY * gt.shape[5])

gtPred = np.concatenate([gt[:,sequence,:,field, posX, posY], pred[:,sequence,:,field, posX, posY]])

fft = np.fft.fft(gtPred, axis=1)
fft = np.real(fft * np.conj(fft))
n = fft.shape[1]
gridSpacing = 0.002 # delta t between frames from simulation
freq = np.fft.fftfreq(n, d=gridSpacing)[1:int(n/2)]
fft = fft[:,1:int(n/2)] # only use positive fourier frequencies

gtFFT = fft[0]
minPredFFT = np.min(fft[1:], axis=0) # lower bound over samples
maxPredFFT = np.max(fft[1:], axis=0) # upper bound over samples
meanPredFFT = np.mean(fft[1:], axis=0) # sample mean


# plot eval point
fig, ax = plt.subplots(1, figsize=(5,2), dpi=150)
ax.set_title("Evaluation Point")
ax.imshow(gt[0,sequence,0,field].transpose(), interpolation="catrom", cmap="viridis")
ax.scatter(posX, posY, s=200, color="red", marker="x", linewidth=2)
ax.set_xticks([])
ax.set_yticks([])
plt.show()


# plot spectral analysis
fig, ax = plt.subplots(1, figsize=(5,2), dpi=150)
ax.set_title("Spectral Analysis")
ax.set_xlabel("Temporal frequency $f$ (at point downstream)")
ax.set_ylabel("Amplitude $*f^2$")
ax.set_xscale("log", base=2)
ax.set_yscale("log", base=10)
ax.yaxis.grid(True)

ax.plot(freq, gtFFT * (freq**2), color="k", label="Simulation", linestyle="dashed")

ax.plot(freq, meanPredFFT * (freq**2), color="tab:orange", label="ACDM")
ax.fill_between(freq, minPredFFT * (freq**2), maxPredFFT * (freq**2), facecolor="tab:orange", alpha=0.15)

fig.legend()
plt.show()
12/17:
!wget -nc "https://dataserv.ub.tum.de/s/m1734798.001/download?path=/&files=128_tra_small.zip" -O data/128_tra_small.zip --no-check-certificate 
!unzip -nq data/128_tra_small.zip -d data
!wget -nc "https://dataserv.ub.tum.de/s/m1734798.001/download?path=/&files=checkpoints_acdm_tra.zip" -O models/checkpoints_acdm_tra.zip --no-check-certificate 
!unzip -nq models/checkpoints_acdm_tra.zip -d models
12/18:
try:
    import google.colab  # only to ensure that we are inside colab
    !pip install einops
except ImportError:
    print("This notebook is running locally, please follow the ACDM installation instructions first, then continue with the cell below.")
    pass
12/19:
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader, SequentialSampler, RandomSampler

from einops import rearrange
from functools import partial

import matplotlib.pyplot as plt
import numpy as np

import math
import os, json
from typing import List,Tuple,Dict
12/20:
class TurbulenceDataset(Dataset):
    """Data set for turbulence and wavelet noise data

    Args:
        name: name of the dataset
        dataDirs: list of paths to data directories
        filterTop: filter for top level folder names (e.g. different types of data)
        excludeFilterTop: mode for filterTop (exclude or include)
        filterSim: filter simulations by min and max (min inclusive, max exclusive)
        excludefilterSim: mode for filterSim (exclude or include)
        filterFrame: mandatory filter for simulation frames by min and max (min inclusive, max exclusive)
        sequenceLength: number of frames to group into a sequence and number of frames to omit in between
        randSeqOffset: randomizes the starting frame of each sequence
        simFields: list of simulation fields to include (vel is always included) ["dens", "pres"]
        simParams: list of simulation parameters to include ["rey", "mach"]
        printLevel: print mode for contents of the dataset ["none", "top", "sim", "full"]
    """

    def __init__(self, name:str, dataDirs:List[str], filterTop:List[str], excludeFilterTop:bool=False, filterSim:List[Tuple[int, int]]=[],
                excludefilterSim:bool=False, filterFrame:List[Tuple[int, int]]=[], sequenceLength:List[Tuple[int, int]]=[],
                randSeqOffset:bool=False, simFields:List[str]=[], simParams:List[str]=[], printLevel:str="none"):

        self.transform = None
        self.name = name
        self.dataDirs = dataDirs
        self.filterTop = filterTop
        self.excludeFilterTop = excludeFilterTop
        self.filterSim = filterSim
        self.excludefilterSim = excludefilterSim
        self.filterFrame = filterFrame
        self.sequenceLength = sequenceLength
        self.randSeqOffset = randSeqOffset
        self.simFields = ["velocity"]
        if "dens" in simFields:
            self.simFields += ["density"]
        if "pres" in simFields:
            self.simFields += ["pressure"]

        self.simParams = simParams
        self.printLevel = printLevel

        self.summaryPrint = []
        self.summaryPrint += ["Dataset " + name + " at " + str(dataDirs)]
        self.summaryPrint += [self.getFilterInfoString()]

        # BUILD FULL FILE LIST
        self.dataPaths = []
        self.dataPathModes = []

        for dataDir in dataDirs:
            topDirs = os.listdir(dataDir)
            topDirs.sort()

            # top level folders
            for topDir in topDirs:
                if filterTop:
                    # continue when excluding or including according to filter
                    if excludeFilterTop == any( item in topDir for item in filterTop ):
                        continue

                match = -1
                # compute matching top filter for according sim or frame filtering
                if len(filterSim) > 1 or len(filterFrame) > 1:
                    for i in range(len(filterTop)):
                        if filterTop[i] in topDir:
                            match = i
                            break
                    assert (match >= 0), "Match computation error"

                simDir = os.path.join(dataDir, topDir)
                sims = os.listdir(simDir)
                sims.sort()

                if printLevel == "top":
                    self.summaryPrint += ["Top folder loaded: " + simDir.replace(dataDir + "/", "")]

                # sim_000001 folders
                for sim in sims:
                    currentDir = os.path.join(simDir, sim)
                    if not os.path.isdir(currentDir):
                        continue

                    if len(filterSim) > 0:
                        simNum = int(sim.split("_")[1])
                        if len(filterSim) == 1:
                            if type(filterSim[0]) is tuple:
                                inside = simNum >= filterSim[0][0] and simNum < filterSim[0][1]
                            elif type(filterSim[0]) is list:
                                inside = simNum in filterSim[0]
                        else:
                            if type(filterSim[match]) is tuple:
                                inside = simNum >= filterSim[match][0] and simNum < filterSim[match][1]
                            elif type(filterSim[match]) is list:
                                inside = simNum in filterSim[match]
                        # continue when excluding or including according to filter
                        if inside == excludefilterSim:
                            continue

                    if printLevel == "sim":
                        self.summaryPrint += ["Sim loaded: " + currentDir.replace(dataDir + "/", "")]

                    # individual simulation frames
                    minFrame = filterFrame[0][0] if len(filterFrame) == 1 else filterFrame[match][0]
                    maxFrame = filterFrame[0][1] if len(filterFrame) == 1 else filterFrame[match][1]
                    seqLength = sequenceLength[0][0] if len(sequenceLength) == 1 else sequenceLength[match][0]
                    seqSkip   = sequenceLength[0][1] if len(sequenceLength) == 1 else sequenceLength[match][1]
                    for seqStart in range(minFrame, maxFrame, seqLength*seqSkip):
                        validSeq = True
                        for frame in range(seqStart, seqStart+seqLength*seqSkip, seqSkip):
                            # discard incomplete sequences at simulation end
                            if seqStart+seqLength*seqSkip > maxFrame:
                                validSeq = False
                                break

                            for field in self.simFields:
                                currentField = os.path.join(currentDir, "%s_%06d.npz" % (field, frame))
                                if not os.path.isfile(currentField):
                                    raise FileNotFoundError("Could not load %s file: %s" % (field, currentField))

                        # imcomplete sequence means there are no more frames left
                        if not validSeq:
                            break

                        if printLevel == "full":
                            self.summaryPrint += ["Frames %s loaded: %s/%s_%06d-%06d(%03d).npz" % ("-".join(self.simFields),
                                        currentDir.replace(dataDir + "/", ""), "-".join(self.simFields), seqStart, seqStart + seqLength*(seqSkip-1), seqSkip)]

                        self.dataPaths.append((currentDir, seqStart, seqStart + seqLength*seqSkip, seqSkip))

        self.summaryPrint += ["Dataset Length: %d\n" % len(self.dataPaths)]


    def __len__(self) -> int:
        return len(self.dataPaths)


    def __getitem__(self, idx:int) -> dict:
        # sequence indexing
        basePath, seqStart, seqEnd, seqSkip = self.dataPaths[idx]
        seqLen = int((seqEnd - seqStart) / seqSkip)
        if self.randSeqOffset:
            halfSeq = int((seqEnd-seqStart) / 2)
            offset = torch.randint(-halfSeq, halfSeq+1, (1,)).item()
            if seqStart + offset >= self.filterFrame[0][0] and seqEnd + offset < self.filterFrame[0][1]:
                seqStart = seqStart + offset
                seqEnd = seqEnd + offset

        # loading simulation parameters
        with open(os.path.join(basePath, "src", "description.json")) as f:
            loadedJSON = json.load(f)

            loadNames = ["Reynolds Number", "Mach Number", "Drag Coefficient", "Lift Coefficient", "Z Slice"]
            loadedParams = {}
            for loadName in loadNames:
                loadedParam = np.zeros(seqLen, dtype=np.float32)
                if loadName in loadedJSON:
                    temp = loadedJSON[loadName]
                    if isinstance(temp, int) or isinstance(temp, float):
                        temp = np.array(temp, dtype=np.float32)
                        loadedParam[0:] = np.repeat(temp, seqLen)
                    elif isinstance(temp, list):
                        loadedParam[0:] = temp[seqStart:seqEnd:seqSkip]
                    else:
                        raise ValueError("Invalid simulation parameter data type")
                loadedParams[loadName] = loadedParam

            if "rey" in self.simParams and "mach" in self.simParams:
                simParameters = np.stack([loadedParams["Reynolds Number"], loadedParams["Mach Number"]], axis=1)
            elif "rey" in self.simParams:
                simParameters = np.reshape(loadedParams["Reynolds Number"], (-1,1))
            elif "mach" in self.simParams:
                simParameters = np.reshape(loadedParams["Mach Number"], (-1,1))
            elif "zslice" in self.simParams:
                simParameters = np.reshape(loadedParams["Z Slice"], (-1,1))
            elif not self.simParams:
                simParameters ={}
            else:
                raise ValueError("Invalid specification of simulation parameters")

        # loading obstacle mask
        if os.path.isfile(os.path.join(basePath, "obstacle_mask.npz")):
            obsMask = np.load(os.path.join(basePath, "obstacle_mask.npz"))['arr_0']
        else:
            obsMask = None

        # loading fields and combining them with simulation parameters
        loaded = {}
        for field in self.simFields:
            loaded[field] = []

        for frame in range(seqStart, seqEnd, seqSkip):
            for field in self.simFields:
                loadedArr = np.load(os.path.join(basePath, "%s_%06d.npz" % (field,frame)))['arr_0']
                loaded[field] += [loadedArr.astype(np.float32)]

        loadedFields = []
        for field in self.simFields:
            loadedFields += [np.stack(loaded[field], axis=0)]

        if type(simParameters) is not dict:
            vel = loadedFields[0]
            if vel.ndim == 4:
                simParExpanded = simParameters[:,:,np.newaxis,np.newaxis]
                simParExpanded = np.repeat(np.repeat(simParExpanded, vel.shape[2], axis=2), vel.shape[3], axis=3)
            elif vel.ndim == 5:
                simParExpanded = simParameters[:,:,np.newaxis,np.newaxis,np.newaxis]
                simParExpanded = np.repeat(np.repeat(np.repeat(simParExpanded, vel.shape[2], axis=2), vel.shape[3], axis=3), vel.shape[4], axis=4)
            else:
                raise ValueError("Invalid input shape when loading samples!")
            loadedFields += [simParExpanded]

        data = np.concatenate(loadedFields, axis=1) # ORDER (fields): velocity (x,y), velocity z / density, pressure, ORDER (params): rey, mach, zslice

        # output
        dataPath = "%s/%s_%06d-%06d(%03d).npz" % (basePath, "-".join(self.simFields), seqStart, seqEnd - seqSkip, seqSkip)
        sample = {"data" : data, "simParameters" : simParameters, "allParameters" : loadedParams, "path" : dataPath}
        if obsMask is not None:
            sample["obsMask"] = obsMask

        if self.transform:
            sample = self.transform(sample)
        else:
            print("WARNING: no data transformations are employed!")

        return sample


    def printDatasetInfo(self):
        if self.transform:
            s  = "%s - Data Normalization Transformation: ACTIVE\n" % (self.name)
            self.summaryPrint += [s]
        print('\n'.join(self.summaryPrint))

    def getFilterInfoString(self) -> str:
        s  = "%s - Data Filter Setup: \n" % (self.name)
        s += "\tdataDirs: %s\n" % (str(self.dataDirs))
        s += "\tfilterTop: %s  exlude: %s\n" % (str(self.filterTop), self.excludeFilterTop)
        s += "\tfilterSim: %s  exlude: %s\n" % (str(self.filterSim), self.excludefilterSim)
        s += "\tfilterFrame: %s\n" % (str(self.filterFrame))
        s += "\tsequenceLength: %s\n" % (str(self.sequenceLength))
        return s
12/21:
class DataTransforms(object):

    def __init__(self, normalizeMode="traMixed", simFields=["dens","pres"], simParams=["mach"]):
        self.simFields = simFields
        self.simParams = simParams

        # mean and std statistics from whole dataset for normalization
        if "tra" in normalizeMode.lower() and "mixed" in normalizeMode.lower():
            # ORDER (fields): velocity (x,y), density, pressure, ORDER (params): rey, mach
            self.normMean = np.array([0.560642, -0.000129, 0.903352, 0.637941, 10000.000000, 0.700000], dtype=np.float32)
            self.normStd =  np.array([0.216987, 0.216987, 0.145391, 0.119944, 1, 0.118322], dtype=np.float32)


    def __call__(self, sample:dict):
        data = sample["data"]
        simParameters = sample["simParameters"]
        allParameters = sample["allParameters"]
        obsMask = sample.get("obsMask", None)
        path = sample["path"]

        # normalization to std. normal distr. with zero mean and unit std via statistics from whole dataset
        # ORDER (fields): velocity (x,y), velocity z / density, pressure, ORDER (params): rey, mach
        filterList = [0, 1]
        if "dens" in self.simFields:
            filterList += [2]
        if "pres" in self.simFields:
            filterList += [3]
        if "rey" in self.simParams:
            filterList += [4]
        if "mach" in self.simParams:
            filterList += [5]
        filterArr = np.array(filterList)
        filterArrParam = filterArr[-len(self.simParams):]

        if self.simParams:
            meanParam = self.normMean[filterArrParam].reshape((1,-1))
            stdParam = self.normStd[filterArrParam].reshape((1,-1))
            simParameters = (simParameters - meanParam) / stdParam

        meanData = self.normMean[filterArr].reshape((1,-1,1,1))
        stdData = self.normStd[filterArr].reshape((1,-1,1,1))
        data = (data - meanData) / stdData

        # toTensor
        result = torch.from_numpy(data)
        if obsMask is not None:
            obsMask = torch.from_numpy(obsMask)

        outDict = {"data": result, "simParameters": simParameters, "allParameters": allParameters, "path": path}
        if obsMask is not None:
            outDict["obsMask"] = obsMask
        return outDict
12/22:
class Residual(nn.Module):
    def __init__(self, fn):
        super().__init__()
        self.fn = fn

    def forward(self, x, *args, **kwargs):
        return self.fn(x, *args, **kwargs) + x

def Upsample(dim):
    return nn.ConvTranspose2d(dim, dim, 4, 2, 1)

def Downsample(dim):
    return nn.Conv2d(dim, dim, 4, 2, 1)


class SinusoidalPositionEmbeddings(nn.Module):
    def __init__(self, dim):
        super().__init__()
        self.dim = dim

    def forward(self, time):
        device = time.device
        half_dim = self.dim // 2
        embeddings = math.log(10000) / (half_dim - 1)
        embeddings = torch.exp(torch.arange(half_dim, device=device) * -embeddings)
        embeddings = time[:, None] * embeddings[None, :]
        embeddings = torch.cat((embeddings.sin(), embeddings.cos()), dim=-1)
        return embeddings
12/23:
class ConvNextBlock(nn.Module):

    def __init__(self, dim, dim_out, *, time_emb_dim=None, mult=2, norm=True):
        super().__init__()
        self.mlp = (
            nn.Sequential(nn.GELU(), nn.Linear(time_emb_dim, dim))
            if time_emb_dim is not None else None
        )

        self.ds_conv = nn.Conv2d(dim, dim, 7, padding=3, groups=dim)

        self.net = nn.Sequential(
            nn.GroupNorm(1, dim) if norm else nn.Identity(),
            nn.Conv2d(dim, dim_out * mult, 3, padding=1),
            nn.GELU(),
            nn.GroupNorm(1, dim_out * mult),
            nn.Conv2d(dim_out * mult, dim_out, 3, padding=1),
        )

        self.res_conv = nn.Conv2d(dim, dim_out, 1) if dim != dim_out else nn.Identity()

    def forward(self, x, time_emb=None):
        h = self.ds_conv(x)

        if self.mlp is not None and time_emb is not None:
            assert time_emb is not None, "time embedding must be passed in"
            condition = self.mlp(time_emb)
            h = h + rearrange(condition, "b c -> b c 1 1")

        h = self.net(h)
        return h + self.res_conv(x)
12/24:
class Attention(nn.Module):
    def __init__(self, dim, heads=4, dim_head=32):
        super().__init__()
        self.scale = dim_head**-0.5
        self.heads = heads
        hidden_dim = dim_head * heads
        self.to_qkv = nn.Conv2d(dim, hidden_dim * 3, 1, bias=False)
        self.to_out = nn.Conv2d(hidden_dim, dim, 1)

    def forward(self, x):
        b, c, h, w = x.shape
        qkv = self.to_qkv(x).chunk(3, dim=1)
        q, k, v = map(
            lambda t: rearrange(t, "b (h c) x y -> b h c (x y)", h=self.heads), qkv
        )
        q = q * self.scale

        sim = torch.einsum("b h d i, b h d j -> b h i j", q, k)
        sim = sim - sim.amax(dim=-1, keepdim=True).detach()
        attn = sim.softmax(dim=-1)

        out = torch.einsum("b h i j, b h d j -> b h i d", attn, v)
        out = rearrange(out, "b h (x y) d -> b (h d) x y", x=h, y=w)
        return self.to_out(out)


class LinearAttention(nn.Module):
    def __init__(self, dim, heads=4, dim_head=32):
        super().__init__()
        self.scale = dim_head**-0.5
        self.heads = heads
        hidden_dim = dim_head * heads
        self.to_qkv = nn.Conv2d(dim, hidden_dim * 3, 1, bias=False)

        self.to_out = nn.Sequential(nn.Conv2d(hidden_dim, dim, 1),
                                    nn.GroupNorm(1, dim))

    def forward(self, x):
        b, c, h, w = x.shape
        qkv = self.to_qkv(x).chunk(3, dim=1)
        q, k, v = map(
            lambda t: rearrange(t, "b (h c) x y -> b h c (x y)", h=self.heads), qkv
        )

        q = q.softmax(dim=-2)
        k = k.softmax(dim=-1)

        q = q * self.scale
        context = torch.einsum("b h d n, b h e n -> b h d e", k, v)

        out = torch.einsum("b h d e, b h d n -> b h e n", context, q)
        out = rearrange(out, "b h c (x y) -> b (h c) x y", h=self.heads, x=h, y=w)
        return self.to_out(out)
12/25:
class PreNorm(nn.Module):
    def __init__(self, dim, fn):
        super().__init__()
        self.fn = fn
        self.norm = nn.GroupNorm(1, dim)

    def forward(self, x):
        x = self.norm(x)
        return self.fn(x)


class Unet(nn.Module):
    def __init__(
        self,
        dim,
        init_dim=None,
        out_dim=None,
        dim_mults=(1, 2, 4, 8),
        channels=3,
        with_time_emb=True,
        resnet_block_groups=8,
        use_convnext=True,
        convnext_mult=2,
    ):
        super().__init__()

        # determine dimensions
        self.channels = channels

        init_dim = init_dim if init_dim is not None else dim // 3 * 2
        self.init_conv = nn.Conv2d(channels, init_dim, 7, padding=3)

        dims = [init_dim, *map(lambda m: dim * m, dim_mults)]
        in_out = list(zip(dims[:-1], dims[1:]))

        if use_convnext:
            block_klass = partial(ConvNextBlock, mult=convnext_mult)
        else:
            raise NotImplementedError()

        # time embeddings
        if with_time_emb:
            time_dim = dim * 4
            self.time_mlp = nn.Sequential(
                SinusoidalPositionEmbeddings(dim),
                nn.Linear(dim, time_dim),
                nn.GELU(),
                nn.Linear(time_dim, time_dim),
            )

        else:
            time_dim = None
            self.time_mlp = None
            self.cond_mlp = None
            self.sim_mlp = None

        # layers
        self.downs = nn.ModuleList([])
        self.ups = nn.ModuleList([])
        num_resolutions = len(in_out)

        for ind, (dim_in, dim_out) in enumerate(in_out):
            is_last = ind >= (num_resolutions - 1)

            self.downs.append(
                nn.ModuleList(
                    [
                        block_klass(dim_in, dim_out, time_emb_dim=time_dim),
                        block_klass(dim_out, dim_out, time_emb_dim=time_dim),
                        Residual(PreNorm(dim_out, LinearAttention(dim_out))),
                        Downsample(dim_out) if not is_last else nn.Identity(),
                    ]
                )
            )

        mid_dim = dims[-1]
        self.mid_block1 = block_klass(mid_dim, mid_dim, time_emb_dim=time_dim)
        self.mid_attn = Residual(PreNorm(mid_dim, Attention(mid_dim)))
        self.mid_block2 = block_klass(mid_dim, mid_dim, time_emb_dim=time_dim)

        for ind, (dim_in, dim_out) in enumerate(reversed(in_out[1:])):
            is_last = ind >= (num_resolutions - 1)

            self.ups.append(
                nn.ModuleList(
                    [
                        block_klass(dim_out * 2, dim_in, time_emb_dim=time_dim),
                        block_klass(dim_in, dim_in, time_emb_dim=time_dim),
                        Residual(PreNorm(dim_in, LinearAttention(dim_in))),
                        Upsample(dim_in) if not is_last else nn.Identity(),
                    ]
                )
            )

        out_dim = out_dim if out_dim is not None else channels
        self.final_conv = nn.Sequential(
            block_klass(dim, dim), nn.Conv2d(dim, out_dim, 1)
        )

    def forward(self, x, time):
        x = self.init_conv(x)

        t = self.time_mlp(time) if self.time_mlp is not None else None

        h = []

        # downsample
        for block1, block2, attn, downsample in self.downs:
            x = block1(x, t)
            x = block2(x, t)
            x = attn(x)
            h.append(x)
            x = downsample(x)

        # bottleneck
        x = self.mid_block1(x, t)
        x = self.mid_attn(x)
        x = self.mid_block2(x, t)

        # upsample
        for block1, block2, attn, upsample in self.ups:
            x = torch.cat((x, h.pop()), dim=1)
            x = block1(x, t)
            x = block2(x, t)
            x = attn(x)
            x = upsample(x)

        return self.final_conv(x)
12/26:
def linear_beta_schedule(timesteps):
    if timesteps < 10:
        raise ValueError("Warning: Less than 10 timesteps require adjustments to this schedule!")

    beta_start = 0.0001 * (500/timesteps) # adjust reference values determined for 500 steps
    beta_end = 0.02 * (500/timesteps)
    betas = torch.linspace(beta_start, beta_end, timesteps)
    return torch.clip(betas, 0.0001, 0.9999)
12/27:
class DiffusionModel(nn.Module):
    def __init__(self, diffusionSteps:int, condChannels:int, dataChannels:int):
        super(DiffusionModel, self).__init__()

        self.timesteps = diffusionSteps
        betas = linear_beta_schedule(timesteps=self.timesteps)

        betas = betas.unsqueeze(1).unsqueeze(2).unsqueeze(3)
        alphas = 1.0 - betas
        alphasCumprod = torch.cumprod(alphas, axis=0)
        alphasCumprodPrev = F.pad(alphasCumprod[:-1], (0,0,0,0,0,0,1,0), value=1.0)
        sqrtRecipAlphas = torch.sqrt(1.0 / alphas)

        # calculations for diffusion q(x_t | x_{t-1}) and others
        sqrtAlphasCumprod = torch.sqrt(alphasCumprod)
        sqrtOneMinusAlphasCumprod = torch.sqrt(1. - alphasCumprod)

        # calculations for posterior q(x_{t-1} | x_t, x_0)
        posteriorVariance = betas * (1. - alphasCumprodPrev) / (1. - alphasCumprod)
        sqrtPosteriorVariance = torch.sqrt(posteriorVariance)

        self.register_buffer("betas", betas)
        self.register_buffer("sqrtRecipAlphas", sqrtRecipAlphas)
        self.register_buffer("sqrtAlphasCumprod", sqrtAlphasCumprod)
        self.register_buffer("sqrtOneMinusAlphasCumprod", sqrtOneMinusAlphasCumprod)
        self.register_buffer("sqrtPosteriorVariance", sqrtPosteriorVariance)

        # backbone model
        self.unet = Unet(
            dim=128,
            channels= condChannels + dataChannels,
            dim_mults=(1,1,1),
            use_convnext=True,
            convnext_mult=1,
        )


    # input shape (both inputs): B S C W H (D) -> output shape (both outputs): B S nC W H (D)
    def forward(self, conditioning:torch.Tensor, data:torch.Tensor) -> torch.Tensor:
        device = "cuda" if data.is_cuda else "cpu"
        seqLen = data.shape[1]

        # combine batch and sequence dimension for decoder processing
        d = torch.reshape(data, (-1, data.shape[2], data.shape[3], data.shape[4]))
        cond = torch.reshape(conditioning, (-1, conditioning.shape[2], conditioning.shape[3], conditioning.shape[4]))

        # TRAINING
        if self.training:

            # forward diffusion process that adds noise to data
            d = torch.concat((cond, d), dim=1)
            noise = torch.randn_like(d, device=device)
            t = torch.randint(0, self.timesteps, (d.shape[0],), device=device).long()
            dNoisy = self.sqrtAlphasCumprod[t] * d + self.sqrtOneMinusAlphasCumprod[t] * noise

            # noise prediction with network
            predictedNoise = self.unet(dNoisy, t)

            # unstack batch and sequence dimension again
            noise = torch.reshape(noise, (-1, seqLen, conditioning.shape[2] + data.shape[2], data.shape[3], data.shape[4]))
            predictedNoise = torch.reshape(predictedNoise, (-1, seqLen, conditioning.shape[2] + data.shape[2], data.shape[3], data.shape[4]))

            return noise, predictedNoise


        # INFERENCE
        else:
            # conditioned reverse diffusion process
            dNoise = torch.randn_like(d, device=device)
            cNoise = torch.randn_like(cond, device=device)

            for i in reversed(range(0, self.timesteps)):
                t = i * torch.ones(cond.shape[0], device=device).long()

                # compute conditioned part with normal forward diffusion
                condNoisy = self.sqrtAlphasCumprod[t] * cond + self.sqrtOneMinusAlphasCumprod[t] * cNoise

                dNoiseCond = torch.concat((condNoisy, dNoise), dim=1)

                # backward diffusion process that removes noise to create data
                predictedNoiseCond = self.unet(dNoiseCond, t)

                # use model (noise predictor) to predict mean
                modelMean = self.sqrtRecipAlphas[t] * (dNoiseCond - self.betas[t] * predictedNoiseCond / self.sqrtOneMinusAlphasCumprod[t])

                dNoise = modelMean[:, cond.shape[1]:modelMean.shape[1]] # discard prediction of conditioning
                if i != 0:
                    # sample randomly (only for non-final prediction), use mean directly for final prediction
                    dNoise = dNoise + self.sqrtPosteriorVariance[t] * torch.randn_like(dNoise)

            # unstack batch and sequence dimension again
            dNoise = torch.reshape(dNoise, (-1, seqLen, data.shape[2], data.shape[3], data.shape[4]))

            return dNoise
12/28:
device = "cuda" if torch.cuda.is_available() else "cpu"
print("Training device: %s" % device)

startFromCheckpoint = False

batch = 32 # training batch size
if startFromCheckpoint:
    epochs = 10 # finetune only for a small number of epochs
    lr = 0.00001 # since the model is already trained, a conservatively low learning rate
else:
    epochs = 10000 # train from scratch for large number of epochs
    lr = 0.0001 # larger learning rate for training from scratch

sequenceLength = [3,2] # three timesteps (two input steps and one target step) with a temporal stride of 2
simFields = ["dens", "pres"] # the provided data set contains velocity (implict), as well as density and pressure values
simParams = ["mach"] # scalar simulation parameters on which the model is conditioned only contain the Mach number here
diffusionSteps = 20 # the provided model checkpoint was pretrained on 20 diffusion steps

# data set and data loading
trainSet = TurbulenceDataset("Training", ["data"], filterTop=["128_small_tra"], filterSim=[[0]], excludefilterSim=False, filterFrame=[(250,1000)],
                sequenceLength=[sequenceLength], randSeqOffset=True, simFields=simFields, simParams=simParams, printLevel="sim")
trainSet.transform = DataTransforms(normalizeMode="traMixed", simFields=simFields, simParams=simParams)
trainSet.printDatasetInfo()
trainSampler = RandomSampler(trainSet)
#trainSampler = SequentialSampler(trainSet)
trainLoader = DataLoader(trainSet, sampler=trainSampler, batch_size=batch, drop_last=True, num_workers=2)

# model definition
condChannels = 2 * (2 + len(simFields) + len(simParams))
dataChannels = 2 + len(simFields) + len(simParams)
model = DiffusionModel(diffusionSteps, condChannels, dataChannels)

if startFromCheckpoint:
    # load weights from checkpoint
    loaded = torch.load("models/models_tra/128_acdm-r20_02/Model.pth", map_location=torch.device('cpu'))
    model.load_state_dict(loaded["stateDictDecoder"])
model.train()
model.to(device)

# print model info and trainable weigths
paramsTrainable = sum([np.prod(p.size()) for p in filter(lambda p: p.requires_grad, model.parameters())])
params = sum([np.prod(p.size()) for p in model.parameters()])
#print(model)
print("Trainable Weights (All Weights): %d (%d)" % (paramsTrainable, params))

# training loop
print("\nStarting training...")
optimizer = torch.optim.Adam(model.parameters(), lr=lr)
for epoch in range(epochs):
    losses = []
    for s, sample in enumerate(trainLoader, 0):
        optimizer.zero_grad()

        d = sample["data"].to(device)

        inputSteps = 2
        cond = []
        for i in range(inputSteps):
            cond += [d[:,i:i+1]] # collect input steps
        conditioning = torch.concat(cond, dim=2) # combine along channel dimension
        data = d[:, inputSteps:inputSteps+1]

        noise, predictedNoise = model(conditioning=conditioning, data=data)

        loss = F.smooth_l1_loss(noise, predictedNoise)
        print("    [Epoch %2d, Batch %4d]: %1.7f" % (epoch, s, loss.detach().cpu().item()))
        loss.backward()

        losses += [loss.detach().cpu().item()]

        optimizer.step()
    print("[Epoch %2d, FULL]: %1.7f" % (epoch, sum(losses)/len(losses)))

print("Training complete!")
12/29:
device = "cuda" if torch.cuda.is_available() else "cpu"

numSamples = 5
sequenceLength = [60,2]
simFields = ["dens", "pres"]
simParams = ["mach"]
diffusionSteps = 20

try: # load model if not trained/finetuned above
    model
except NameError:
    condChannels = 2 * (2 + len(simFields) + len(simParams))
    dataChannels = 2 + len(simFields) + len(simParams)
    model = DiffusionModel(diffusionSteps, condChannels, dataChannels)

    # load weights from checkpoint
    loaded = torch.load("models/models_tra/128_acdm-r20_02/Model.pth", map_location=torch.device('cpu'))
    model.load_state_dict(loaded["stateDictDecoder"])
model.eval()
model.to(device)

testSet = TurbulenceDataset("Test", ["data"], filterTop=["128_small_tra"], filterSim=[[0]], excludefilterSim=False, filterFrame=[(0,250)],
                sequenceLength=[sequenceLength], randSeqOffset=False, simFields=simFields, simParams=simParams, printLevel="sim")
testSet.transform = DataTransforms(normalizeMode="traMixed", simFields=simFields, simParams=simParams)
testSet.printDatasetInfo()
testSampler = SequentialSampler(testSet)
testLoader = DataLoader(testSet, sampler=testSampler, batch_size=1, drop_last=False)

# sampling loop
print("\nStarting sampling...")
gt = []
pred = []
with torch.no_grad():
    for s, sample in enumerate(testLoader, 0):
        gt += [sample["data"].unsqueeze(0).cpu().numpy()]
        d = sample["data"].to(device).repeat(numSamples,1,1,1,1) # reuse batch dim for samples

        prediction = torch.zeros_like(d, device=device)
        inputSteps = 2

        for i in range(inputSteps): # no prediction of first steps
            prediction[:,i] = d[:,i]

        for i in range(inputSteps, d.shape[1]):
            cond = []
            for j in range(inputSteps,0,-1):
                cond += [prediction[:, i-j : i-(j-1)]] # collect input steps
            cond = torch.concat(cond, dim=2) # combine along channel dimension

            result = model(conditioning=cond, data=d[:,i-1:i]) # auto-regressive inference
            result[:,:,-len(simParams):] = d[:,i:i+1,-len(simParams):] # replace simparam prediction with true values
            prediction[:,i:i+1] = result

        prediction = torch.reshape(prediction, (numSamples, -1, d.shape[1], d.shape[2], d.shape[3], d.shape[4]))
        pred += [prediction.cpu().numpy()]
        print("  Sequence %d finished" % s)


print("Sampling complete!\n")

gt = np.concatenate(gt, axis=1)
pred = np.concatenate(pred, axis=1)

# undo data normalization
normMean = testSet.transform.normMean[[0,1,2,3,5]]
normStd = testSet.transform.normStd[[0,1,2,3,5]]
normMean = np.expand_dims(normMean, axis=(0,1,2,4,5))
normStd = np.expand_dims(normStd, axis=(0,1,2,4,5))
gt = (gt * normStd) + normMean
pred = (pred * normStd) + normMean

print("Ground truth and prediction tensor with shape:")
print("(samples, sequences, sequenceLength, channels, sizeX, sizeY)")
print("GT: %s" % str(gt.shape))
print("Prediction: %s" % str(pred.shape))
12/30:
sequence = 0
samples = [0,4]
timeSteps = [0,19,39,59]
field = 3 # velocity_x (0), velocity_y (1), density (2), or pressure (3)

predPart = pred[samples]
gtPred = np.concatenate([gt[:,sequence,timeSteps,field], predPart[:,sequence,timeSteps,field]])

fig, axs = plt.subplots(nrows=gtPred.shape[0], ncols=gtPred.shape[1], figsize=(gtPred.shape[1]*1.9, gtPred.shape[0]), dpi=150, squeeze=False)

for i in range(gtPred.shape[0]):
    for j in range(gtPred.shape[1]):
        if i == gtPred.shape[0]-1:
            axs[i,j].set_xlabel("$t=%s$" % (timeSteps[j]+1), fontsize=10)
        if j == 0:
            if i == 0:
              axs[i,j].set_ylabel("Ground\nTruth", fontsize=10)
            else:
              axs[i,j].set_ylabel("ACDM\nSample %d" % i, fontsize=10)
        axs[i,j].set_xticks([])
        axs[i,j].set_yticks([])
        im = axs[i,j].imshow(gtPred[i][j].transpose(), interpolation="catrom", cmap="viridis")

plt.show()
12/31:
gtTemp = gt[:,:,:,0:4] # ignore scalar Mach number here
predTemp = pred[:,:,:,0:4]

diffGt = np.abs( gtTemp[:,:,1:gtTemp.shape[2]-1] - gtTemp[:,:,2:gtTemp.shape[2]])
diffGt = np.mean(diffGt, axis=(3,4,5)) # channel-wise and spatial mean
minGt = np.min(diffGt, axis=(0,1)) # lower bound over sequences
maxGt = np.max(diffGt, axis=(0,1)) # upper bound over sequences
meanGt = np.mean(diffGt, axis=(0,1)) # sample- and sequence mean

diffPred = np.abs( predTemp[:,:,1:predTemp.shape[2]-1] - predTemp[:,:,2:predTemp.shape[2]])
diffPred = np.mean(diffPred, axis=(3,4,5)) # channel-wise and spatial mean
minPred = np.min(diffPred, axis=(0,1)) # lower bound over samples and sequences
maxPred = np.max(diffPred, axis=(0,1)) # upper bound over samples and sequences
meanPred = np.mean(diffPred, axis=(0,1)) # sample- and sequence mean


fig, ax = plt.subplots(1, figsize=(5,2), dpi=150)
ax.set_title("Temporal Stability")
ax.set_ylabel("$\Vert \, (s^{t} - s^{t-1}) / \Delta t \, \Vert_1$")
ax.yaxis.grid(True)
ax.set_xlabel("Time step $t$")

ax.plot(np.arange(meanGt.shape[0]), meanGt, color="k", label="Simulation", linestyle="dashed")
ax.fill_between(np.arange(meanGt.shape[0]), minGt, maxGt, facecolor="k", alpha=0.15)

ax.plot(np.arange(meanPred.shape[0]), meanPred, color="tab:orange", label="ACDM")
ax.fill_between(np.arange(meanPred.shape[0]), minPred, maxPred, facecolor="tab:orange", alpha=0.15)

fig.legend()
plt.show()
12/32:
sequence = 0
fracX = 0.25 # closely behing the cylinder
fracY = 0.5 # vertically centered
field = 1 # velocity_x (0), velocity_y (1), density (2), or pressure (3)

posX = int(fracX * gt.shape[4])
posY = int(fracY * gt.shape[5])

gtPred = np.concatenate([gt[:,sequence,:,field, posX, posY], pred[:,sequence,:,field, posX, posY]])

fft = np.fft.fft(gtPred, axis=1)
fft = np.real(fft * np.conj(fft))
n = fft.shape[1]
gridSpacing = 0.002 # delta t between frames from simulation
freq = np.fft.fftfreq(n, d=gridSpacing)[1:int(n/2)]
fft = fft[:,1:int(n/2)] # only use positive fourier frequencies

gtFFT = fft[0]
minPredFFT = np.min(fft[1:], axis=0) # lower bound over samples
maxPredFFT = np.max(fft[1:], axis=0) # upper bound over samples
meanPredFFT = np.mean(fft[1:], axis=0) # sample mean


# plot eval point
fig, ax = plt.subplots(1, figsize=(5,2), dpi=150)
ax.set_title("Evaluation Point")
ax.imshow(gt[0,sequence,0,field].transpose(), interpolation="catrom", cmap="viridis")
ax.scatter(posX, posY, s=200, color="red", marker="x", linewidth=2)
ax.set_xticks([])
ax.set_yticks([])
plt.show()


# plot spectral analysis
fig, ax = plt.subplots(1, figsize=(5,2), dpi=150)
ax.set_title("Spectral Analysis")
ax.set_xlabel("Temporal frequency $f$ (at point downstream)")
ax.set_ylabel("Amplitude $*f^2$")
ax.set_xscale("log", base=2)
ax.set_yscale("log", base=10)
ax.yaxis.grid(True)

ax.plot(freq, gtFFT * (freq**2), color="k", label="Simulation", linestyle="dashed")

ax.plot(freq, meanPredFFT * (freq**2), color="tab:orange", label="ACDM")
ax.fill_between(freq, minPredFFT * (freq**2), maxPredFFT * (freq**2), facecolor="tab:orange", alpha=0.15)

fig.legend()
plt.show()
12/33: model
12/34: torch.save("models/Model_8000.pth", map_location=torch.device('cpu'))
12/35: torch.save("models/Model_8000.pth")
12/36: torch.save(model, "models/Model_8000.pth")
12/37: torch.save(model, "models/Model_8000.pth")
12/38: torch.save(model, "models/Model_8000.pth")
12/39: torch.save(model.state_dict(), "models/Model_8000.pth")
12/40: torch.save(model.state_dict(), "./model_8000")
12/41: torch.save(model.state_dict(), './model_8000')
12/42: torch.save(model.state_dict(), PATH)
12/43: torch.save(model.state_dict(), './')
12/44: torch.save(model.state_dict(), './HERE')
12/45: torch.save(model.state_dict(), './HERE.pth')
12/46: torch.save(model.state_dict(), './HERE.zip')
12/47: torch.save(model.state_dict(), '.models/HERE.zip')
12/48: torch.save(model.state_dict(), './models/HERE.zip')
13/1:
!wget -nc "https://dataserv.ub.tum.de/s/m1734798.001/download?path=/&files=128_tra_small.zip" -O data/128_tra_small.zip --no-check-certificate 
!unzip -nq data/128_tra_small.zip -d data
!wget -nc "https://dataserv.ub.tum.de/s/m1734798.001/download?path=/&files=checkpoints_acdm_tra.zip" -O models/checkpoints_acdm_tra.zip --no-check-certificate 
!unzip -nq models/checkpoints_acdm_tra.zip -d models
13/2:
try:
    import google.colab  # only to ensure that we are inside colab
    !pip install einops
except ImportError:
    print("This notebook is running locally, please follow the ACDM installation instructions first, then continue with the cell below.")
    pass
13/3:
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader, SequentialSampler, RandomSampler

from einops import rearrange
from functools import partial

import matplotlib.pyplot as plt
import numpy as np

import math
import os, json
from typing import List,Tuple,Dict
13/4:
class TurbulenceDataset(Dataset):
    """Data set for turbulence and wavelet noise data

    Args:
        name: name of the dataset
        dataDirs: list of paths to data directories
        filterTop: filter for top level folder names (e.g. different types of data)
        excludeFilterTop: mode for filterTop (exclude or include)
        filterSim: filter simulations by min and max (min inclusive, max exclusive)
        excludefilterSim: mode for filterSim (exclude or include)
        filterFrame: mandatory filter for simulation frames by min and max (min inclusive, max exclusive)
        sequenceLength: number of frames to group into a sequence and number of frames to omit in between
        randSeqOffset: randomizes the starting frame of each sequence
        simFields: list of simulation fields to include (vel is always included) ["dens", "pres"]
        simParams: list of simulation parameters to include ["rey", "mach"]
        printLevel: print mode for contents of the dataset ["none", "top", "sim", "full"]
    """

    def __init__(self, name:str, dataDirs:List[str], filterTop:List[str], excludeFilterTop:bool=False, filterSim:List[Tuple[int, int]]=[],
                excludefilterSim:bool=False, filterFrame:List[Tuple[int, int]]=[], sequenceLength:List[Tuple[int, int]]=[],
                randSeqOffset:bool=False, simFields:List[str]=[], simParams:List[str]=[], printLevel:str="none"):

        self.transform = None
        self.name = name
        self.dataDirs = dataDirs
        self.filterTop = filterTop
        self.excludeFilterTop = excludeFilterTop
        self.filterSim = filterSim
        self.excludefilterSim = excludefilterSim
        self.filterFrame = filterFrame
        self.sequenceLength = sequenceLength
        self.randSeqOffset = randSeqOffset
        self.simFields = ["velocity"]
        if "dens" in simFields:
            self.simFields += ["density"]
        if "pres" in simFields:
            self.simFields += ["pressure"]

        self.simParams = simParams
        self.printLevel = printLevel

        self.summaryPrint = []
        self.summaryPrint += ["Dataset " + name + " at " + str(dataDirs)]
        self.summaryPrint += [self.getFilterInfoString()]

        # BUILD FULL FILE LIST
        self.dataPaths = []
        self.dataPathModes = []

        for dataDir in dataDirs:
            topDirs = os.listdir(dataDir)
            topDirs.sort()

            # top level folders
            for topDir in topDirs:
                if filterTop:
                    # continue when excluding or including according to filter
                    if excludeFilterTop == any( item in topDir for item in filterTop ):
                        continue

                match = -1
                # compute matching top filter for according sim or frame filtering
                if len(filterSim) > 1 or len(filterFrame) > 1:
                    for i in range(len(filterTop)):
                        if filterTop[i] in topDir:
                            match = i
                            break
                    assert (match >= 0), "Match computation error"

                simDir = os.path.join(dataDir, topDir)
                sims = os.listdir(simDir)
                sims.sort()

                if printLevel == "top":
                    self.summaryPrint += ["Top folder loaded: " + simDir.replace(dataDir + "/", "")]

                # sim_000001 folders
                for sim in sims:
                    currentDir = os.path.join(simDir, sim)
                    if not os.path.isdir(currentDir):
                        continue

                    if len(filterSim) > 0:
                        simNum = int(sim.split("_")[1])
                        if len(filterSim) == 1:
                            if type(filterSim[0]) is tuple:
                                inside = simNum >= filterSim[0][0] and simNum < filterSim[0][1]
                            elif type(filterSim[0]) is list:
                                inside = simNum in filterSim[0]
                        else:
                            if type(filterSim[match]) is tuple:
                                inside = simNum >= filterSim[match][0] and simNum < filterSim[match][1]
                            elif type(filterSim[match]) is list:
                                inside = simNum in filterSim[match]
                        # continue when excluding or including according to filter
                        if inside == excludefilterSim:
                            continue

                    if printLevel == "sim":
                        self.summaryPrint += ["Sim loaded: " + currentDir.replace(dataDir + "/", "")]

                    # individual simulation frames
                    minFrame = filterFrame[0][0] if len(filterFrame) == 1 else filterFrame[match][0]
                    maxFrame = filterFrame[0][1] if len(filterFrame) == 1 else filterFrame[match][1]
                    seqLength = sequenceLength[0][0] if len(sequenceLength) == 1 else sequenceLength[match][0]
                    seqSkip   = sequenceLength[0][1] if len(sequenceLength) == 1 else sequenceLength[match][1]
                    for seqStart in range(minFrame, maxFrame, seqLength*seqSkip):
                        validSeq = True
                        for frame in range(seqStart, seqStart+seqLength*seqSkip, seqSkip):
                            # discard incomplete sequences at simulation end
                            if seqStart+seqLength*seqSkip > maxFrame:
                                validSeq = False
                                break

                            for field in self.simFields:
                                currentField = os.path.join(currentDir, "%s_%06d.npz" % (field, frame))
                                if not os.path.isfile(currentField):
                                    raise FileNotFoundError("Could not load %s file: %s" % (field, currentField))

                        # imcomplete sequence means there are no more frames left
                        if not validSeq:
                            break

                        if printLevel == "full":
                            self.summaryPrint += ["Frames %s loaded: %s/%s_%06d-%06d(%03d).npz" % ("-".join(self.simFields),
                                        currentDir.replace(dataDir + "/", ""), "-".join(self.simFields), seqStart, seqStart + seqLength*(seqSkip-1), seqSkip)]

                        self.dataPaths.append((currentDir, seqStart, seqStart + seqLength*seqSkip, seqSkip))

        self.summaryPrint += ["Dataset Length: %d\n" % len(self.dataPaths)]


    def __len__(self) -> int:
        return len(self.dataPaths)


    def __getitem__(self, idx:int) -> dict:
        # sequence indexing
        basePath, seqStart, seqEnd, seqSkip = self.dataPaths[idx]
        seqLen = int((seqEnd - seqStart) / seqSkip)
        if self.randSeqOffset:
            halfSeq = int((seqEnd-seqStart) / 2)
            offset = torch.randint(-halfSeq, halfSeq+1, (1,)).item()
            if seqStart + offset >= self.filterFrame[0][0] and seqEnd + offset < self.filterFrame[0][1]:
                seqStart = seqStart + offset
                seqEnd = seqEnd + offset

        # loading simulation parameters
        with open(os.path.join(basePath, "src", "description.json")) as f:
            loadedJSON = json.load(f)

            loadNames = ["Reynolds Number", "Mach Number", "Drag Coefficient", "Lift Coefficient", "Z Slice"]
            loadedParams = {}
            for loadName in loadNames:
                loadedParam = np.zeros(seqLen, dtype=np.float32)
                if loadName in loadedJSON:
                    temp = loadedJSON[loadName]
                    if isinstance(temp, int) or isinstance(temp, float):
                        temp = np.array(temp, dtype=np.float32)
                        loadedParam[0:] = np.repeat(temp, seqLen)
                    elif isinstance(temp, list):
                        loadedParam[0:] = temp[seqStart:seqEnd:seqSkip]
                    else:
                        raise ValueError("Invalid simulation parameter data type")
                loadedParams[loadName] = loadedParam

            if "rey" in self.simParams and "mach" in self.simParams:
                simParameters = np.stack([loadedParams["Reynolds Number"], loadedParams["Mach Number"]], axis=1)
            elif "rey" in self.simParams:
                simParameters = np.reshape(loadedParams["Reynolds Number"], (-1,1))
            elif "mach" in self.simParams:
                simParameters = np.reshape(loadedParams["Mach Number"], (-1,1))
            elif "zslice" in self.simParams:
                simParameters = np.reshape(loadedParams["Z Slice"], (-1,1))
            elif not self.simParams:
                simParameters ={}
            else:
                raise ValueError("Invalid specification of simulation parameters")

        # loading obstacle mask
        if os.path.isfile(os.path.join(basePath, "obstacle_mask.npz")):
            obsMask = np.load(os.path.join(basePath, "obstacle_mask.npz"))['arr_0']
        else:
            obsMask = None

        # loading fields and combining them with simulation parameters
        loaded = {}
        for field in self.simFields:
            loaded[field] = []

        for frame in range(seqStart, seqEnd, seqSkip):
            for field in self.simFields:
                loadedArr = np.load(os.path.join(basePath, "%s_%06d.npz" % (field,frame)))['arr_0']
                loaded[field] += [loadedArr.astype(np.float32)]

        loadedFields = []
        for field in self.simFields:
            loadedFields += [np.stack(loaded[field], axis=0)]

        if type(simParameters) is not dict:
            vel = loadedFields[0]
            if vel.ndim == 4:
                simParExpanded = simParameters[:,:,np.newaxis,np.newaxis]
                simParExpanded = np.repeat(np.repeat(simParExpanded, vel.shape[2], axis=2), vel.shape[3], axis=3)
            elif vel.ndim == 5:
                simParExpanded = simParameters[:,:,np.newaxis,np.newaxis,np.newaxis]
                simParExpanded = np.repeat(np.repeat(np.repeat(simParExpanded, vel.shape[2], axis=2), vel.shape[3], axis=3), vel.shape[4], axis=4)
            else:
                raise ValueError("Invalid input shape when loading samples!")
            loadedFields += [simParExpanded]

        data = np.concatenate(loadedFields, axis=1) # ORDER (fields): velocity (x,y), velocity z / density, pressure, ORDER (params): rey, mach, zslice

        # output
        dataPath = "%s/%s_%06d-%06d(%03d).npz" % (basePath, "-".join(self.simFields), seqStart, seqEnd - seqSkip, seqSkip)
        sample = {"data" : data, "simParameters" : simParameters, "allParameters" : loadedParams, "path" : dataPath}
        if obsMask is not None:
            sample["obsMask"] = obsMask

        if self.transform:
            sample = self.transform(sample)
        else:
            print("WARNING: no data transformations are employed!")

        return sample


    def printDatasetInfo(self):
        if self.transform:
            s  = "%s - Data Normalization Transformation: ACTIVE\n" % (self.name)
            self.summaryPrint += [s]
        print('\n'.join(self.summaryPrint))

    def getFilterInfoString(self) -> str:
        s  = "%s - Data Filter Setup: \n" % (self.name)
        s += "\tdataDirs: %s\n" % (str(self.dataDirs))
        s += "\tfilterTop: %s  exlude: %s\n" % (str(self.filterTop), self.excludeFilterTop)
        s += "\tfilterSim: %s  exlude: %s\n" % (str(self.filterSim), self.excludefilterSim)
        s += "\tfilterFrame: %s\n" % (str(self.filterFrame))
        s += "\tsequenceLength: %s\n" % (str(self.sequenceLength))
        return s
13/5:
class DataTransforms(object):

    def __init__(self, normalizeMode="traMixed", simFields=["dens","pres"], simParams=["mach"]):
        self.simFields = simFields
        self.simParams = simParams

        # mean and std statistics from whole dataset for normalization
        if "tra" in normalizeMode.lower() and "mixed" in normalizeMode.lower():
            # ORDER (fields): velocity (x,y), density, pressure, ORDER (params): rey, mach
            self.normMean = np.array([0.560642, -0.000129, 0.903352, 0.637941, 10000.000000, 0.700000], dtype=np.float32)
            self.normStd =  np.array([0.216987, 0.216987, 0.145391, 0.119944, 1, 0.118322], dtype=np.float32)


    def __call__(self, sample:dict):
        data = sample["data"]
        simParameters = sample["simParameters"]
        allParameters = sample["allParameters"]
        obsMask = sample.get("obsMask", None)
        path = sample["path"]

        # normalization to std. normal distr. with zero mean and unit std via statistics from whole dataset
        # ORDER (fields): velocity (x,y), velocity z / density, pressure, ORDER (params): rey, mach
        filterList = [0, 1]
        if "dens" in self.simFields:
            filterList += [2]
        if "pres" in self.simFields:
            filterList += [3]
        if "rey" in self.simParams:
            filterList += [4]
        if "mach" in self.simParams:
            filterList += [5]
        filterArr = np.array(filterList)
        filterArrParam = filterArr[-len(self.simParams):]

        if self.simParams:
            meanParam = self.normMean[filterArrParam].reshape((1,-1))
            stdParam = self.normStd[filterArrParam].reshape((1,-1))
            simParameters = (simParameters - meanParam) / stdParam

        meanData = self.normMean[filterArr].reshape((1,-1,1,1))
        stdData = self.normStd[filterArr].reshape((1,-1,1,1))
        data = (data - meanData) / stdData

        # toTensor
        result = torch.from_numpy(data)
        if obsMask is not None:
            obsMask = torch.from_numpy(obsMask)

        outDict = {"data": result, "simParameters": simParameters, "allParameters": allParameters, "path": path}
        if obsMask is not None:
            outDict["obsMask"] = obsMask
        return outDict
13/6:
class Residual(nn.Module):
    def __init__(self, fn):
        super().__init__()
        self.fn = fn

    def forward(self, x, *args, **kwargs):
        return self.fn(x, *args, **kwargs) + x

def Upsample(dim):
    return nn.ConvTranspose2d(dim, dim, 4, 2, 1)

def Downsample(dim):
    return nn.Conv2d(dim, dim, 4, 2, 1)


class SinusoidalPositionEmbeddings(nn.Module):
    def __init__(self, dim):
        super().__init__()
        self.dim = dim

    def forward(self, time):
        device = time.device
        half_dim = self.dim // 2
        embeddings = math.log(10000) / (half_dim - 1)
        embeddings = torch.exp(torch.arange(half_dim, device=device) * -embeddings)
        embeddings = time[:, None] * embeddings[None, :]
        embeddings = torch.cat((embeddings.sin(), embeddings.cos()), dim=-1)
        return embeddings
13/7:
class ConvNextBlock(nn.Module):

    def __init__(self, dim, dim_out, *, time_emb_dim=None, mult=2, norm=True):
        super().__init__()
        self.mlp = (
            nn.Sequential(nn.GELU(), nn.Linear(time_emb_dim, dim))
            if time_emb_dim is not None else None
        )

        self.ds_conv = nn.Conv2d(dim, dim, 7, padding=3, groups=dim)

        self.net = nn.Sequential(
            nn.GroupNorm(1, dim) if norm else nn.Identity(),
            nn.Conv2d(dim, dim_out * mult, 3, padding=1),
            nn.GELU(),
            nn.GroupNorm(1, dim_out * mult),
            nn.Conv2d(dim_out * mult, dim_out, 3, padding=1),
        )

        self.res_conv = nn.Conv2d(dim, dim_out, 1) if dim != dim_out else nn.Identity()

    def forward(self, x, time_emb=None):
        h = self.ds_conv(x)

        if self.mlp is not None and time_emb is not None:
            assert time_emb is not None, "time embedding must be passed in"
            condition = self.mlp(time_emb)
            h = h + rearrange(condition, "b c -> b c 1 1")

        h = self.net(h)
        return h + self.res_conv(x)
13/8:
class Attention(nn.Module):
    def __init__(self, dim, heads=4, dim_head=32):
        super().__init__()
        self.scale = dim_head**-0.5
        self.heads = heads
        hidden_dim = dim_head * heads
        self.to_qkv = nn.Conv2d(dim, hidden_dim * 3, 1, bias=False)
        self.to_out = nn.Conv2d(hidden_dim, dim, 1)

    def forward(self, x):
        b, c, h, w = x.shape
        qkv = self.to_qkv(x).chunk(3, dim=1)
        q, k, v = map(
            lambda t: rearrange(t, "b (h c) x y -> b h c (x y)", h=self.heads), qkv
        )
        q = q * self.scale

        sim = torch.einsum("b h d i, b h d j -> b h i j", q, k)
        sim = sim - sim.amax(dim=-1, keepdim=True).detach()
        attn = sim.softmax(dim=-1)

        out = torch.einsum("b h i j, b h d j -> b h i d", attn, v)
        out = rearrange(out, "b h (x y) d -> b (h d) x y", x=h, y=w)
        return self.to_out(out)


class LinearAttention(nn.Module):
    def __init__(self, dim, heads=4, dim_head=32):
        super().__init__()
        self.scale = dim_head**-0.5
        self.heads = heads
        hidden_dim = dim_head * heads
        self.to_qkv = nn.Conv2d(dim, hidden_dim * 3, 1, bias=False)

        self.to_out = nn.Sequential(nn.Conv2d(hidden_dim, dim, 1),
                                    nn.GroupNorm(1, dim))

    def forward(self, x):
        b, c, h, w = x.shape
        qkv = self.to_qkv(x).chunk(3, dim=1)
        q, k, v = map(
            lambda t: rearrange(t, "b (h c) x y -> b h c (x y)", h=self.heads), qkv
        )

        q = q.softmax(dim=-2)
        k = k.softmax(dim=-1)

        q = q * self.scale
        context = torch.einsum("b h d n, b h e n -> b h d e", k, v)

        out = torch.einsum("b h d e, b h d n -> b h e n", context, q)
        out = rearrange(out, "b h c (x y) -> b (h c) x y", h=self.heads, x=h, y=w)
        return self.to_out(out)
13/9:
class PreNorm(nn.Module):
    def __init__(self, dim, fn):
        super().__init__()
        self.fn = fn
        self.norm = nn.GroupNorm(1, dim)

    def forward(self, x):
        x = self.norm(x)
        return self.fn(x)


class Unet(nn.Module):
    def __init__(
        self,
        dim,
        init_dim=None,
        out_dim=None,
        dim_mults=(1, 2, 4, 8),
        channels=3,
        with_time_emb=True,
        resnet_block_groups=8,
        use_convnext=True,
        convnext_mult=2,
    ):
        super().__init__()

        # determine dimensions
        self.channels = channels

        init_dim = init_dim if init_dim is not None else dim // 3 * 2
        self.init_conv = nn.Conv2d(channels, init_dim, 7, padding=3)

        dims = [init_dim, *map(lambda m: dim * m, dim_mults)]
        in_out = list(zip(dims[:-1], dims[1:]))

        if use_convnext:
            block_klass = partial(ConvNextBlock, mult=convnext_mult)
        else:
            raise NotImplementedError()

        # time embeddings
        if with_time_emb:
            time_dim = dim * 4
            self.time_mlp = nn.Sequential(
                SinusoidalPositionEmbeddings(dim),
                nn.Linear(dim, time_dim),
                nn.GELU(),
                nn.Linear(time_dim, time_dim),
            )

        else:
            time_dim = None
            self.time_mlp = None
            self.cond_mlp = None
            self.sim_mlp = None

        # layers
        self.downs = nn.ModuleList([])
        self.ups = nn.ModuleList([])
        num_resolutions = len(in_out)

        for ind, (dim_in, dim_out) in enumerate(in_out):
            is_last = ind >= (num_resolutions - 1)

            self.downs.append(
                nn.ModuleList(
                    [
                        block_klass(dim_in, dim_out, time_emb_dim=time_dim),
                        block_klass(dim_out, dim_out, time_emb_dim=time_dim),
                        Residual(PreNorm(dim_out, LinearAttention(dim_out))),
                        Downsample(dim_out) if not is_last else nn.Identity(),
                    ]
                )
            )

        mid_dim = dims[-1]
        self.mid_block1 = block_klass(mid_dim, mid_dim, time_emb_dim=time_dim)
        self.mid_attn = Residual(PreNorm(mid_dim, Attention(mid_dim)))
        self.mid_block2 = block_klass(mid_dim, mid_dim, time_emb_dim=time_dim)

        for ind, (dim_in, dim_out) in enumerate(reversed(in_out[1:])):
            is_last = ind >= (num_resolutions - 1)

            self.ups.append(
                nn.ModuleList(
                    [
                        block_klass(dim_out * 2, dim_in, time_emb_dim=time_dim),
                        block_klass(dim_in, dim_in, time_emb_dim=time_dim),
                        Residual(PreNorm(dim_in, LinearAttention(dim_in))),
                        Upsample(dim_in) if not is_last else nn.Identity(),
                    ]
                )
            )

        out_dim = out_dim if out_dim is not None else channels
        self.final_conv = nn.Sequential(
            block_klass(dim, dim), nn.Conv2d(dim, out_dim, 1)
        )

    def forward(self, x, time):
        x = self.init_conv(x)

        t = self.time_mlp(time) if self.time_mlp is not None else None

        h = []

        # downsample
        for block1, block2, attn, downsample in self.downs:
            x = block1(x, t)
            x = block2(x, t)
            x = attn(x)
            h.append(x)
            x = downsample(x)

        # bottleneck
        x = self.mid_block1(x, t)
        x = self.mid_attn(x)
        x = self.mid_block2(x, t)

        # upsample
        for block1, block2, attn, upsample in self.ups:
            x = torch.cat((x, h.pop()), dim=1)
            x = block1(x, t)
            x = block2(x, t)
            x = attn(x)
            x = upsample(x)

        return self.final_conv(x)
13/10:
def linear_beta_schedule(timesteps):
    if timesteps < 10:
        raise ValueError("Warning: Less than 10 timesteps require adjustments to this schedule!")

    beta_start = 0.0001 * (500/timesteps) # adjust reference values determined for 500 steps
    beta_end = 0.02 * (500/timesteps)
    betas = torch.linspace(beta_start, beta_end, timesteps)
    return torch.clip(betas, 0.0001, 0.9999)
13/11:
class DiffusionModel(nn.Module):
    def __init__(self, diffusionSteps:int, condChannels:int, dataChannels:int):
        super(DiffusionModel, self).__init__()

        self.timesteps = diffusionSteps
        betas = linear_beta_schedule(timesteps=self.timesteps)

        betas = betas.unsqueeze(1).unsqueeze(2).unsqueeze(3)
        alphas = 1.0 - betas
        alphasCumprod = torch.cumprod(alphas, axis=0)
        alphasCumprodPrev = F.pad(alphasCumprod[:-1], (0,0,0,0,0,0,1,0), value=1.0)
        sqrtRecipAlphas = torch.sqrt(1.0 / alphas)

        # calculations for diffusion q(x_t | x_{t-1}) and others
        sqrtAlphasCumprod = torch.sqrt(alphasCumprod)
        sqrtOneMinusAlphasCumprod = torch.sqrt(1. - alphasCumprod)

        # calculations for posterior q(x_{t-1} | x_t, x_0)
        posteriorVariance = betas * (1. - alphasCumprodPrev) / (1. - alphasCumprod)
        sqrtPosteriorVariance = torch.sqrt(posteriorVariance)

        self.register_buffer("betas", betas)
        self.register_buffer("sqrtRecipAlphas", sqrtRecipAlphas)
        self.register_buffer("sqrtAlphasCumprod", sqrtAlphasCumprod)
        self.register_buffer("sqrtOneMinusAlphasCumprod", sqrtOneMinusAlphasCumprod)
        self.register_buffer("sqrtPosteriorVariance", sqrtPosteriorVariance)

        # backbone model
        self.unet = Unet(
            dim=128,
            channels= condChannels + dataChannels,
            dim_mults=(1,1,1),
            use_convnext=True,
            convnext_mult=1,
        )


    # input shape (both inputs): B S C W H (D) -> output shape (both outputs): B S nC W H (D)
    def forward(self, conditioning:torch.Tensor, data:torch.Tensor) -> torch.Tensor:
        device = "cuda" if data.is_cuda else "cpu"
        seqLen = data.shape[1]

        # combine batch and sequence dimension for decoder processing
        d = torch.reshape(data, (-1, data.shape[2], data.shape[3], data.shape[4]))
        cond = torch.reshape(conditioning, (-1, conditioning.shape[2], conditioning.shape[3], conditioning.shape[4]))

        # TRAINING
        if self.training:

            # forward diffusion process that adds noise to data
            d = torch.concat((cond, d), dim=1)
            noise = torch.randn_like(d, device=device)
            t = torch.randint(0, self.timesteps, (d.shape[0],), device=device).long()
            dNoisy = self.sqrtAlphasCumprod[t] * d + self.sqrtOneMinusAlphasCumprod[t] * noise

            # noise prediction with network
            predictedNoise = self.unet(dNoisy, t)

            # unstack batch and sequence dimension again
            noise = torch.reshape(noise, (-1, seqLen, conditioning.shape[2] + data.shape[2], data.shape[3], data.shape[4]))
            predictedNoise = torch.reshape(predictedNoise, (-1, seqLen, conditioning.shape[2] + data.shape[2], data.shape[3], data.shape[4]))

            return noise, predictedNoise


        # INFERENCE
        else:
            # conditioned reverse diffusion process
            dNoise = torch.randn_like(d, device=device)
            cNoise = torch.randn_like(cond, device=device)

            for i in reversed(range(0, self.timesteps)):
                t = i * torch.ones(cond.shape[0], device=device).long()

                # compute conditioned part with normal forward diffusion
                condNoisy = self.sqrtAlphasCumprod[t] * cond + self.sqrtOneMinusAlphasCumprod[t] * cNoise

                dNoiseCond = torch.concat((condNoisy, dNoise), dim=1)

                # backward diffusion process that removes noise to create data
                predictedNoiseCond = self.unet(dNoiseCond, t)

                # use model (noise predictor) to predict mean
                modelMean = self.sqrtRecipAlphas[t] * (dNoiseCond - self.betas[t] * predictedNoiseCond / self.sqrtOneMinusAlphasCumprod[t])

                dNoise = modelMean[:, cond.shape[1]:modelMean.shape[1]] # discard prediction of conditioning
                if i != 0:
                    # sample randomly (only for non-final prediction), use mean directly for final prediction
                    dNoise = dNoise + self.sqrtPosteriorVariance[t] * torch.randn_like(dNoise)

            # unstack batch and sequence dimension again
            dNoise = torch.reshape(dNoise, (-1, seqLen, data.shape[2], data.shape[3], data.shape[4]))

            return dNoise
13/12:
device = "cuda" if torch.cuda.is_available() else "cpu"
print("Training device: %s" % device)

startFromCheckpoint = False

batch = 32 # training batch size
if startFromCheckpoint:
    epochs = 10 # finetune only for a small number of epochs
    lr = 0.00001 # since the model is already trained, a conservatively low learning rate
else:
    epochs = 10000 # train from scratch for large number of epochs
    lr = 0.0001 # larger learning rate for training from scratch

sequenceLength = [3,2] # three timesteps (two input steps and one target step) with a temporal stride of 2
simFields = ["dens", "pres"] # the provided data set contains velocity (implict), as well as density and pressure values
simParams = ["mach"] # scalar simulation parameters on which the model is conditioned only contain the Mach number here
diffusionSteps = 20 # the provided model checkpoint was pretrained on 20 diffusion steps

# data set and data loading
trainSet = TurbulenceDataset("Training", ["data"], filterTop=["128_small_tra"], filterSim=[[0]], excludefilterSim=False, filterFrame=[(250,1000)],
                sequenceLength=[sequenceLength], randSeqOffset=True, simFields=simFields, simParams=simParams, printLevel="sim")
trainSet.transform = DataTransforms(normalizeMode="traMixed", simFields=simFields, simParams=simParams)
trainSet.printDatasetInfo()
trainSampler = RandomSampler(trainSet)
#trainSampler = SequentialSampler(trainSet)
trainLoader = DataLoader(trainSet, sampler=trainSampler, batch_size=batch, drop_last=True, num_workers=2)

# model definition
condChannels = 2 * (2 + len(simFields) + len(simParams))
dataChannels = 2 + len(simFields) + len(simParams)
model = DiffusionModel(diffusionSteps, condChannels, dataChannels)

if startFromCheckpoint:
    # load weights from checkpoint
    loaded = torch.load("models/models_tra/128_acdm-r20_02/Model.pth", map_location=torch.device('cpu'))
    model.load_state_dict(loaded["stateDictDecoder"])
model.train()
model.to(device)

# print model info and trainable weigths
paramsTrainable = sum([np.prod(p.size()) for p in filter(lambda p: p.requires_grad, model.parameters())])
params = sum([np.prod(p.size()) for p in model.parameters()])
#print(model)
print("Trainable Weights (All Weights): %d (%d)" % (paramsTrainable, params))

# training loop
print("\nStarting training...")
optimizer = torch.optim.Adam(model.parameters(), lr=lr)
for epoch in range(epochs):
    losses = []
    for s, sample in enumerate(trainLoader, 0):
        optimizer.zero_grad()

        d = sample["data"].to(device)

        inputSteps = 2
        cond = []
        for i in range(inputSteps):
            cond += [d[:,i:i+1]] # collect input steps
        conditioning = torch.concat(cond, dim=2) # combine along channel dimension
        data = d[:, inputSteps:inputSteps+1]

        noise, predictedNoise = model(conditioning=conditioning, data=data)

        loss = F.smooth_l1_loss(noise, predictedNoise)
        print("    [Epoch %2d, Batch %4d]: %1.7f" % (epoch, s, loss.detach().cpu().item()))
        loss.backward()

        losses += [loss.detach().cpu().item()]

        optimizer.step()
    print("[Epoch %2d, FULL]: %1.7f" % (epoch, sum(losses)/len(losses)))

print("Training complete!")
15/1:
!wget -nc "https://dataserv.ub.tum.de/s/m1734798.001/download?path=/&files=128_tra_small.zip" -O data/128_tra_small.zip --no-check-certificate 
!unzip -nq data/128_tra_small.zip -d data
!wget -nc "https://dataserv.ub.tum.de/s/m1734798.001/download?path=/&files=checkpoints_acdm_tra.zip" -O models/checkpoints_acdm_tra.zip --no-check-certificate 
!unzip -nq models/checkpoints_acdm_tra.zip -d models
15/2:
try:
    import google.colab  # only to ensure that we are inside colab
    !pip install einops
except ImportError:
    print("This notebook is running locally, please follow the ACDM installation instructions first, then continue with the cell below.")
    pass
15/3:
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader, SequentialSampler, RandomSampler

from einops import rearrange
from functools import partial

import matplotlib.pyplot as plt
import numpy as np

import math
import os, json
from typing import List,Tuple,Dict
15/4:
class TurbulenceDataset(Dataset):
    """Data set for turbulence and wavelet noise data

    Args:
        name: name of the dataset
        dataDirs: list of paths to data directories
        filterTop: filter for top level folder names (e.g. different types of data)
        excludeFilterTop: mode for filterTop (exclude or include)
        filterSim: filter simulations by min and max (min inclusive, max exclusive)
        excludefilterSim: mode for filterSim (exclude or include)
        filterFrame: mandatory filter for simulation frames by min and max (min inclusive, max exclusive)
        sequenceLength: number of frames to group into a sequence and number of frames to omit in between
        randSeqOffset: randomizes the starting frame of each sequence
        simFields: list of simulation fields to include (vel is always included) ["dens", "pres"]
        simParams: list of simulation parameters to include ["rey", "mach"]
        printLevel: print mode for contents of the dataset ["none", "top", "sim", "full"]
    """

    def __init__(self, name:str, dataDirs:List[str], filterTop:List[str], excludeFilterTop:bool=False, filterSim:List[Tuple[int, int]]=[],
                excludefilterSim:bool=False, filterFrame:List[Tuple[int, int]]=[], sequenceLength:List[Tuple[int, int]]=[],
                randSeqOffset:bool=False, simFields:List[str]=[], simParams:List[str]=[], printLevel:str="none"):

        self.transform = None
        self.name = name
        self.dataDirs = dataDirs
        self.filterTop = filterTop
        self.excludeFilterTop = excludeFilterTop
        self.filterSim = filterSim
        self.excludefilterSim = excludefilterSim
        self.filterFrame = filterFrame
        self.sequenceLength = sequenceLength
        self.randSeqOffset = randSeqOffset
        self.simFields = ["velocity"]
        if "dens" in simFields:
            self.simFields += ["density"]
        if "pres" in simFields:
            self.simFields += ["pressure"]

        self.simParams = simParams
        self.printLevel = printLevel

        self.summaryPrint = []
        self.summaryPrint += ["Dataset " + name + " at " + str(dataDirs)]
        self.summaryPrint += [self.getFilterInfoString()]

        # BUILD FULL FILE LIST
        self.dataPaths = []
        self.dataPathModes = []

        for dataDir in dataDirs:
            topDirs = os.listdir(dataDir)
            topDirs.sort()

            # top level folders
            for topDir in topDirs:
                if filterTop:
                    # continue when excluding or including according to filter
                    if excludeFilterTop == any( item in topDir for item in filterTop ):
                        continue

                match = -1
                # compute matching top filter for according sim or frame filtering
                if len(filterSim) > 1 or len(filterFrame) > 1:
                    for i in range(len(filterTop)):
                        if filterTop[i] in topDir:
                            match = i
                            break
                    assert (match >= 0), "Match computation error"

                simDir = os.path.join(dataDir, topDir)
                sims = os.listdir(simDir)
                sims.sort()

                if printLevel == "top":
                    self.summaryPrint += ["Top folder loaded: " + simDir.replace(dataDir + "/", "")]

                # sim_000001 folders
                for sim in sims:
                    currentDir = os.path.join(simDir, sim)
                    if not os.path.isdir(currentDir):
                        continue

                    if len(filterSim) > 0:
                        simNum = int(sim.split("_")[1])
                        if len(filterSim) == 1:
                            if type(filterSim[0]) is tuple:
                                inside = simNum >= filterSim[0][0] and simNum < filterSim[0][1]
                            elif type(filterSim[0]) is list:
                                inside = simNum in filterSim[0]
                        else:
                            if type(filterSim[match]) is tuple:
                                inside = simNum >= filterSim[match][0] and simNum < filterSim[match][1]
                            elif type(filterSim[match]) is list:
                                inside = simNum in filterSim[match]
                        # continue when excluding or including according to filter
                        if inside == excludefilterSim:
                            continue

                    if printLevel == "sim":
                        self.summaryPrint += ["Sim loaded: " + currentDir.replace(dataDir + "/", "")]

                    # individual simulation frames
                    minFrame = filterFrame[0][0] if len(filterFrame) == 1 else filterFrame[match][0]
                    maxFrame = filterFrame[0][1] if len(filterFrame) == 1 else filterFrame[match][1]
                    seqLength = sequenceLength[0][0] if len(sequenceLength) == 1 else sequenceLength[match][0]
                    seqSkip   = sequenceLength[0][1] if len(sequenceLength) == 1 else sequenceLength[match][1]
                    for seqStart in range(minFrame, maxFrame, seqLength*seqSkip):
                        validSeq = True
                        for frame in range(seqStart, seqStart+seqLength*seqSkip, seqSkip):
                            # discard incomplete sequences at simulation end
                            if seqStart+seqLength*seqSkip > maxFrame:
                                validSeq = False
                                break

                            for field in self.simFields:
                                currentField = os.path.join(currentDir, "%s_%06d.npz" % (field, frame))
                                if not os.path.isfile(currentField):
                                    raise FileNotFoundError("Could not load %s file: %s" % (field, currentField))

                        # imcomplete sequence means there are no more frames left
                        if not validSeq:
                            break

                        if printLevel == "full":
                            self.summaryPrint += ["Frames %s loaded: %s/%s_%06d-%06d(%03d).npz" % ("-".join(self.simFields),
                                        currentDir.replace(dataDir + "/", ""), "-".join(self.simFields), seqStart, seqStart + seqLength*(seqSkip-1), seqSkip)]

                        self.dataPaths.append((currentDir, seqStart, seqStart + seqLength*seqSkip, seqSkip))

        self.summaryPrint += ["Dataset Length: %d\n" % len(self.dataPaths)]


    def __len__(self) -> int:
        return len(self.dataPaths)


    def __getitem__(self, idx:int) -> dict:
        # sequence indexing
        basePath, seqStart, seqEnd, seqSkip = self.dataPaths[idx]
        seqLen = int((seqEnd - seqStart) / seqSkip)
        if self.randSeqOffset:
            halfSeq = int((seqEnd-seqStart) / 2)
            offset = torch.randint(-halfSeq, halfSeq+1, (1,)).item()
            if seqStart + offset >= self.filterFrame[0][0] and seqEnd + offset < self.filterFrame[0][1]:
                seqStart = seqStart + offset
                seqEnd = seqEnd + offset

        # loading simulation parameters
        with open(os.path.join(basePath, "src", "description.json")) as f:
            loadedJSON = json.load(f)

            loadNames = ["Reynolds Number", "Mach Number", "Drag Coefficient", "Lift Coefficient", "Z Slice"]
            loadedParams = {}
            for loadName in loadNames:
                loadedParam = np.zeros(seqLen, dtype=np.float32)
                if loadName in loadedJSON:
                    temp = loadedJSON[loadName]
                    if isinstance(temp, int) or isinstance(temp, float):
                        temp = np.array(temp, dtype=np.float32)
                        loadedParam[0:] = np.repeat(temp, seqLen)
                    elif isinstance(temp, list):
                        loadedParam[0:] = temp[seqStart:seqEnd:seqSkip]
                    else:
                        raise ValueError("Invalid simulation parameter data type")
                loadedParams[loadName] = loadedParam

            if "rey" in self.simParams and "mach" in self.simParams:
                simParameters = np.stack([loadedParams["Reynolds Number"], loadedParams["Mach Number"]], axis=1)
            elif "rey" in self.simParams:
                simParameters = np.reshape(loadedParams["Reynolds Number"], (-1,1))
            elif "mach" in self.simParams:
                simParameters = np.reshape(loadedParams["Mach Number"], (-1,1))
            elif "zslice" in self.simParams:
                simParameters = np.reshape(loadedParams["Z Slice"], (-1,1))
            elif not self.simParams:
                simParameters ={}
            else:
                raise ValueError("Invalid specification of simulation parameters")

        # loading obstacle mask
        if os.path.isfile(os.path.join(basePath, "obstacle_mask.npz")):
            obsMask = np.load(os.path.join(basePath, "obstacle_mask.npz"))['arr_0']
        else:
            obsMask = None

        # loading fields and combining them with simulation parameters
        loaded = {}
        for field in self.simFields:
            loaded[field] = []

        for frame in range(seqStart, seqEnd, seqSkip):
            for field in self.simFields:
                loadedArr = np.load(os.path.join(basePath, "%s_%06d.npz" % (field,frame)))['arr_0']
                loaded[field] += [loadedArr.astype(np.float32)]

        loadedFields = []
        for field in self.simFields:
            loadedFields += [np.stack(loaded[field], axis=0)]

        if type(simParameters) is not dict:
            vel = loadedFields[0]
            if vel.ndim == 4:
                simParExpanded = simParameters[:,:,np.newaxis,np.newaxis]
                simParExpanded = np.repeat(np.repeat(simParExpanded, vel.shape[2], axis=2), vel.shape[3], axis=3)
            elif vel.ndim == 5:
                simParExpanded = simParameters[:,:,np.newaxis,np.newaxis,np.newaxis]
                simParExpanded = np.repeat(np.repeat(np.repeat(simParExpanded, vel.shape[2], axis=2), vel.shape[3], axis=3), vel.shape[4], axis=4)
            else:
                raise ValueError("Invalid input shape when loading samples!")
            loadedFields += [simParExpanded]

        data = np.concatenate(loadedFields, axis=1) # ORDER (fields): velocity (x,y), velocity z / density, pressure, ORDER (params): rey, mach, zslice

        # output
        dataPath = "%s/%s_%06d-%06d(%03d).npz" % (basePath, "-".join(self.simFields), seqStart, seqEnd - seqSkip, seqSkip)
        sample = {"data" : data, "simParameters" : simParameters, "allParameters" : loadedParams, "path" : dataPath}
        if obsMask is not None:
            sample["obsMask"] = obsMask

        if self.transform:
            sample = self.transform(sample)
        else:
            print("WARNING: no data transformations are employed!")

        return sample


    def printDatasetInfo(self):
        if self.transform:
            s  = "%s - Data Normalization Transformation: ACTIVE\n" % (self.name)
            self.summaryPrint += [s]
        print('\n'.join(self.summaryPrint))

    def getFilterInfoString(self) -> str:
        s  = "%s - Data Filter Setup: \n" % (self.name)
        s += "\tdataDirs: %s\n" % (str(self.dataDirs))
        s += "\tfilterTop: %s  exlude: %s\n" % (str(self.filterTop), self.excludeFilterTop)
        s += "\tfilterSim: %s  exlude: %s\n" % (str(self.filterSim), self.excludefilterSim)
        s += "\tfilterFrame: %s\n" % (str(self.filterFrame))
        s += "\tsequenceLength: %s\n" % (str(self.sequenceLength))
        return s
15/5:
class DataTransforms(object):

    def __init__(self, normalizeMode="traMixed", simFields=["dens","pres"], simParams=["mach"]):
        self.simFields = simFields
        self.simParams = simParams

        # mean and std statistics from whole dataset for normalization
        if "tra" in normalizeMode.lower() and "mixed" in normalizeMode.lower():
            # ORDER (fields): velocity (x,y), density, pressure, ORDER (params): rey, mach
            self.normMean = np.array([0.560642, -0.000129, 0.903352, 0.637941, 10000.000000, 0.700000], dtype=np.float32)
            self.normStd =  np.array([0.216987, 0.216987, 0.145391, 0.119944, 1, 0.118322], dtype=np.float32)


    def __call__(self, sample:dict):
        data = sample["data"]
        simParameters = sample["simParameters"]
        allParameters = sample["allParameters"]
        obsMask = sample.get("obsMask", None)
        path = sample["path"]

        # normalization to std. normal distr. with zero mean and unit std via statistics from whole dataset
        # ORDER (fields): velocity (x,y), velocity z / density, pressure, ORDER (params): rey, mach
        filterList = [0, 1]
        if "dens" in self.simFields:
            filterList += [2]
        if "pres" in self.simFields:
            filterList += [3]
        if "rey" in self.simParams:
            filterList += [4]
        if "mach" in self.simParams:
            filterList += [5]
        filterArr = np.array(filterList)
        filterArrParam = filterArr[-len(self.simParams):]

        if self.simParams:
            meanParam = self.normMean[filterArrParam].reshape((1,-1))
            stdParam = self.normStd[filterArrParam].reshape((1,-1))
            simParameters = (simParameters - meanParam) / stdParam

        meanData = self.normMean[filterArr].reshape((1,-1,1,1))
        stdData = self.normStd[filterArr].reshape((1,-1,1,1))
        data = (data - meanData) / stdData

        # toTensor
        result = torch.from_numpy(data)
        if obsMask is not None:
            obsMask = torch.from_numpy(obsMask)

        outDict = {"data": result, "simParameters": simParameters, "allParameters": allParameters, "path": path}
        if obsMask is not None:
            outDict["obsMask"] = obsMask
        return outDict
15/6:
class Residual(nn.Module):
    def __init__(self, fn):
        super().__init__()
        self.fn = fn

    def forward(self, x, *args, **kwargs):
        return self.fn(x, *args, **kwargs) + x

def Upsample(dim):
    return nn.ConvTranspose2d(dim, dim, 4, 2, 1)

def Downsample(dim):
    return nn.Conv2d(dim, dim, 4, 2, 1)


class SinusoidalPositionEmbeddings(nn.Module):
    def __init__(self, dim):
        super().__init__()
        self.dim = dim

    def forward(self, time):
        device = time.device
        half_dim = self.dim // 2
        embeddings = math.log(10000) / (half_dim - 1)
        embeddings = torch.exp(torch.arange(half_dim, device=device) * -embeddings)
        embeddings = time[:, None] * embeddings[None, :]
        embeddings = torch.cat((embeddings.sin(), embeddings.cos()), dim=-1)
        return embeddings
15/7:
class ConvNextBlock(nn.Module):

    def __init__(self, dim, dim_out, *, time_emb_dim=None, mult=2, norm=True):
        super().__init__()
        self.mlp = (
            nn.Sequential(nn.GELU(), nn.Linear(time_emb_dim, dim))
            if time_emb_dim is not None else None
        )

        self.ds_conv = nn.Conv2d(dim, dim, 7, padding=3, groups=dim)

        self.net = nn.Sequential(
            nn.GroupNorm(1, dim) if norm else nn.Identity(),
            nn.Conv2d(dim, dim_out * mult, 3, padding=1),
            nn.GELU(),
            nn.GroupNorm(1, dim_out * mult),
            nn.Conv2d(dim_out * mult, dim_out, 3, padding=1),
        )

        self.res_conv = nn.Conv2d(dim, dim_out, 1) if dim != dim_out else nn.Identity()

    def forward(self, x, time_emb=None):
        h = self.ds_conv(x)

        if self.mlp is not None and time_emb is not None:
            assert time_emb is not None, "time embedding must be passed in"
            condition = self.mlp(time_emb)
            h = h + rearrange(condition, "b c -> b c 1 1")

        h = self.net(h)
        return h + self.res_conv(x)
15/8:
class Attention(nn.Module):
    def __init__(self, dim, heads=4, dim_head=32):
        super().__init__()
        self.scale = dim_head**-0.5
        self.heads = heads
        hidden_dim = dim_head * heads
        self.to_qkv = nn.Conv2d(dim, hidden_dim * 3, 1, bias=False)
        self.to_out = nn.Conv2d(hidden_dim, dim, 1)

    def forward(self, x):
        b, c, h, w = x.shape
        qkv = self.to_qkv(x).chunk(3, dim=1)
        q, k, v = map(
            lambda t: rearrange(t, "b (h c) x y -> b h c (x y)", h=self.heads), qkv
        )
        q = q * self.scale

        sim = torch.einsum("b h d i, b h d j -> b h i j", q, k)
        sim = sim - sim.amax(dim=-1, keepdim=True).detach()
        attn = sim.softmax(dim=-1)

        out = torch.einsum("b h i j, b h d j -> b h i d", attn, v)
        out = rearrange(out, "b h (x y) d -> b (h d) x y", x=h, y=w)
        return self.to_out(out)


class LinearAttention(nn.Module):
    def __init__(self, dim, heads=4, dim_head=32):
        super().__init__()
        self.scale = dim_head**-0.5
        self.heads = heads
        hidden_dim = dim_head * heads
        self.to_qkv = nn.Conv2d(dim, hidden_dim * 3, 1, bias=False)

        self.to_out = nn.Sequential(nn.Conv2d(hidden_dim, dim, 1),
                                    nn.GroupNorm(1, dim))

    def forward(self, x):
        b, c, h, w = x.shape
        qkv = self.to_qkv(x).chunk(3, dim=1)
        q, k, v = map(
            lambda t: rearrange(t, "b (h c) x y -> b h c (x y)", h=self.heads), qkv
        )

        q = q.softmax(dim=-2)
        k = k.softmax(dim=-1)

        q = q * self.scale
        context = torch.einsum("b h d n, b h e n -> b h d e", k, v)

        out = torch.einsum("b h d e, b h d n -> b h e n", context, q)
        out = rearrange(out, "b h c (x y) -> b (h c) x y", h=self.heads, x=h, y=w)
        return self.to_out(out)
15/9:
class PreNorm(nn.Module):
    def __init__(self, dim, fn):
        super().__init__()
        self.fn = fn
        self.norm = nn.GroupNorm(1, dim)

    def forward(self, x):
        x = self.norm(x)
        return self.fn(x)


class Unet(nn.Module):
    def __init__(
        self,
        dim,
        init_dim=None,
        out_dim=None,
        dim_mults=(1, 2, 4, 8),
        channels=3,
        with_time_emb=True,
        resnet_block_groups=8,
        use_convnext=True,
        convnext_mult=2,
    ):
        super().__init__()

        # determine dimensions
        self.channels = channels

        init_dim = init_dim if init_dim is not None else dim // 3 * 2
        self.init_conv = nn.Conv2d(channels, init_dim, 7, padding=3)

        dims = [init_dim, *map(lambda m: dim * m, dim_mults)]
        in_out = list(zip(dims[:-1], dims[1:]))

        if use_convnext:
            block_klass = partial(ConvNextBlock, mult=convnext_mult)
        else:
            raise NotImplementedError()

        # time embeddings
        if with_time_emb:
            time_dim = dim * 4
            self.time_mlp = nn.Sequential(
                SinusoidalPositionEmbeddings(dim),
                nn.Linear(dim, time_dim),
                nn.GELU(),
                nn.Linear(time_dim, time_dim),
            )

        else:
            time_dim = None
            self.time_mlp = None
            self.cond_mlp = None
            self.sim_mlp = None

        # layers
        self.downs = nn.ModuleList([])
        self.ups = nn.ModuleList([])
        num_resolutions = len(in_out)

        for ind, (dim_in, dim_out) in enumerate(in_out):
            is_last = ind >= (num_resolutions - 1)

            self.downs.append(
                nn.ModuleList(
                    [
                        block_klass(dim_in, dim_out, time_emb_dim=time_dim),
                        block_klass(dim_out, dim_out, time_emb_dim=time_dim),
                        Residual(PreNorm(dim_out, LinearAttention(dim_out))),
                        Downsample(dim_out) if not is_last else nn.Identity(),
                    ]
                )
            )

        mid_dim = dims[-1]
        self.mid_block1 = block_klass(mid_dim, mid_dim, time_emb_dim=time_dim)
        self.mid_attn = Residual(PreNorm(mid_dim, Attention(mid_dim)))
        self.mid_block2 = block_klass(mid_dim, mid_dim, time_emb_dim=time_dim)

        for ind, (dim_in, dim_out) in enumerate(reversed(in_out[1:])):
            is_last = ind >= (num_resolutions - 1)

            self.ups.append(
                nn.ModuleList(
                    [
                        block_klass(dim_out * 2, dim_in, time_emb_dim=time_dim),
                        block_klass(dim_in, dim_in, time_emb_dim=time_dim),
                        Residual(PreNorm(dim_in, LinearAttention(dim_in))),
                        Upsample(dim_in) if not is_last else nn.Identity(),
                    ]
                )
            )

        out_dim = out_dim if out_dim is not None else channels
        self.final_conv = nn.Sequential(
            block_klass(dim, dim), nn.Conv2d(dim, out_dim, 1)
        )

    def forward(self, x, time):
        x = self.init_conv(x)

        t = self.time_mlp(time) if self.time_mlp is not None else None

        h = []

        # downsample
        for block1, block2, attn, downsample in self.downs:
            x = block1(x, t)
            x = block2(x, t)
            x = attn(x)
            h.append(x)
            x = downsample(x)

        # bottleneck
        x = self.mid_block1(x, t)
        x = self.mid_attn(x)
        x = self.mid_block2(x, t)

        # upsample
        for block1, block2, attn, upsample in self.ups:
            x = torch.cat((x, h.pop()), dim=1)
            x = block1(x, t)
            x = block2(x, t)
            x = attn(x)
            x = upsample(x)

        return self.final_conv(x)
15/10:
def linear_beta_schedule(timesteps):
    if timesteps < 10:
        raise ValueError("Warning: Less than 10 timesteps require adjustments to this schedule!")

    beta_start = 0.0001 * (500/timesteps) # adjust reference values determined for 500 steps
    beta_end = 0.02 * (500/timesteps)
    betas = torch.linspace(beta_start, beta_end, timesteps)
    return torch.clip(betas, 0.0001, 0.9999)
15/11:
class DiffusionModel(nn.Module):
    def __init__(self, diffusionSteps:int, condChannels:int, dataChannels:int):
        super(DiffusionModel, self).__init__()

        self.timesteps = diffusionSteps
        betas = linear_beta_schedule(timesteps=self.timesteps)

        betas = betas.unsqueeze(1).unsqueeze(2).unsqueeze(3)
        alphas = 1.0 - betas
        alphasCumprod = torch.cumprod(alphas, axis=0)
        alphasCumprodPrev = F.pad(alphasCumprod[:-1], (0,0,0,0,0,0,1,0), value=1.0)
        sqrtRecipAlphas = torch.sqrt(1.0 / alphas)

        # calculations for diffusion q(x_t | x_{t-1}) and others
        sqrtAlphasCumprod = torch.sqrt(alphasCumprod)
        sqrtOneMinusAlphasCumprod = torch.sqrt(1. - alphasCumprod)

        # calculations for posterior q(x_{t-1} | x_t, x_0)
        posteriorVariance = betas * (1. - alphasCumprodPrev) / (1. - alphasCumprod)
        sqrtPosteriorVariance = torch.sqrt(posteriorVariance)

        self.register_buffer("betas", betas)
        self.register_buffer("sqrtRecipAlphas", sqrtRecipAlphas)
        self.register_buffer("sqrtAlphasCumprod", sqrtAlphasCumprod)
        self.register_buffer("sqrtOneMinusAlphasCumprod", sqrtOneMinusAlphasCumprod)
        self.register_buffer("sqrtPosteriorVariance", sqrtPosteriorVariance)

        # backbone model
        self.unet = Unet(
            dim=128,
            channels= condChannels + dataChannels,
            dim_mults=(1,1,1),
            use_convnext=True,
            convnext_mult=1,
        )


    # input shape (both inputs): B S C W H (D) -> output shape (both outputs): B S nC W H (D)
    def forward(self, conditioning:torch.Tensor, data:torch.Tensor) -> torch.Tensor:
        device = "cuda" if data.is_cuda else "cpu"
        seqLen = data.shape[1]

        # combine batch and sequence dimension for decoder processing
        d = torch.reshape(data, (-1, data.shape[2], data.shape[3], data.shape[4]))
        cond = torch.reshape(conditioning, (-1, conditioning.shape[2], conditioning.shape[3], conditioning.shape[4]))

        # TRAINING
        if self.training:

            # forward diffusion process that adds noise to data
            d = torch.concat((cond, d), dim=1)
            noise = torch.randn_like(d, device=device)
            t = torch.randint(0, self.timesteps, (d.shape[0],), device=device).long()
            dNoisy = self.sqrtAlphasCumprod[t] * d + self.sqrtOneMinusAlphasCumprod[t] * noise

            # noise prediction with network
            predictedNoise = self.unet(dNoisy, t)

            # unstack batch and sequence dimension again
            noise = torch.reshape(noise, (-1, seqLen, conditioning.shape[2] + data.shape[2], data.shape[3], data.shape[4]))
            predictedNoise = torch.reshape(predictedNoise, (-1, seqLen, conditioning.shape[2] + data.shape[2], data.shape[3], data.shape[4]))

            return noise, predictedNoise


        # INFERENCE
        else:
            # conditioned reverse diffusion process
            dNoise = torch.randn_like(d, device=device)
            cNoise = torch.randn_like(cond, device=device)

            for i in reversed(range(0, self.timesteps)):
                t = i * torch.ones(cond.shape[0], device=device).long()

                # compute conditioned part with normal forward diffusion
                condNoisy = self.sqrtAlphasCumprod[t] * cond + self.sqrtOneMinusAlphasCumprod[t] * cNoise

                dNoiseCond = torch.concat((condNoisy, dNoise), dim=1)

                # backward diffusion process that removes noise to create data
                predictedNoiseCond = self.unet(dNoiseCond, t)

                # use model (noise predictor) to predict mean
                modelMean = self.sqrtRecipAlphas[t] * (dNoiseCond - self.betas[t] * predictedNoiseCond / self.sqrtOneMinusAlphasCumprod[t])

                dNoise = modelMean[:, cond.shape[1]:modelMean.shape[1]] # discard prediction of conditioning
                if i != 0:
                    # sample randomly (only for non-final prediction), use mean directly for final prediction
                    dNoise = dNoise + self.sqrtPosteriorVariance[t] * torch.randn_like(dNoise)

            # unstack batch and sequence dimension again
            dNoise = torch.reshape(dNoise, (-1, seqLen, data.shape[2], data.shape[3], data.shape[4]))

            return dNoise
15/12:
device = "cuda" if torch.cuda.is_available() else "cpu"
print("Training device: %s" % device)

startFromCheckpoint = False

batch = 32 # training batch size
if startFromCheckpoint:
    epochs = 10 # finetune only for a small number of epochs
    lr = 0.00001 # since the model is already trained, a conservatively low learning rate
else:
    epochs = 10000 # train from scratch for large number of epochs
    lr = 0.0001 # larger learning rate for training from scratch

sequenceLength = [3,2] # three timesteps (two input steps and one target step) with a temporal stride of 2
simFields = ["dens", "pres"] # the provided data set contains velocity (implict), as well as density and pressure values
simParams = ["mach"] # scalar simulation parameters on which the model is conditioned only contain the Mach number here
diffusionSteps = 20 # the provided model checkpoint was pretrained on 20 diffusion steps

# data set and data loading
trainSet = TurbulenceDataset("Training", ["data"], filterTop=["128_small_tra"], filterSim=[[0]], excludefilterSim=False, filterFrame=[(250,1000)],
                sequenceLength=[sequenceLength], randSeqOffset=True, simFields=simFields, simParams=simParams, printLevel="sim")
trainSet.transform = DataTransforms(normalizeMode="traMixed", simFields=simFields, simParams=simParams)
trainSet.printDatasetInfo()
trainSampler = RandomSampler(trainSet)
#trainSampler = SequentialSampler(trainSet)
trainLoader = DataLoader(trainSet, sampler=trainSampler, batch_size=batch, drop_last=True, num_workers=2)

# model definition
condChannels = 2 * (2 + len(simFields) + len(simParams))
dataChannels = 2 + len(simFields) + len(simParams)
model = DiffusionModel(diffusionSteps, condChannels, dataChannels)

if startFromCheckpoint:
    # load weights from checkpoint
    loaded = torch.load("models/models_tra/128_acdm-r20_02/Model.pth", map_location=torch.device('cpu'))
    model.load_state_dict(loaded["stateDictDecoder"])
model.train()
model.to(device)

# print model info and trainable weigths
paramsTrainable = sum([np.prod(p.size()) for p in filter(lambda p: p.requires_grad, model.parameters())])
params = sum([np.prod(p.size()) for p in model.parameters()])
#print(model)
print("Trainable Weights (All Weights): %d (%d)" % (paramsTrainable, params))

# training loop
print("\nStarting training...")
optimizer = torch.optim.Adam(model.parameters(), lr=lr)
for epoch in range(epochs):
    losses = []
    for s, sample in enumerate(trainLoader, 0):
        optimizer.zero_grad()

        d = sample["data"].to(device)

        inputSteps = 2
        cond = []
        for i in range(inputSteps):
            cond += [d[:,i:i+1]] # collect input steps
        conditioning = torch.concat(cond, dim=2) # combine along channel dimension
        data = d[:, inputSteps:inputSteps+1]

        noise, predictedNoise = model(conditioning=conditioning, data=data)

        loss = F.smooth_l1_loss(noise, predictedNoise)
        print("    [Epoch %2d, Batch %4d]: %1.7f" % (epoch, s, loss.detach().cpu().item()))
        loss.backward()

        losses += [loss.detach().cpu().item()]

        optimizer.step()
    print("[Epoch %2d, FULL]: %1.7f" % (epoch, sum(losses)/len(losses)))

print("Training complete!")
18/1:
from phi.torch.flow import *
from tqdm.notebook import trange
import torch
import matplotlib.pyplot as plt
18/2: import warp
18/3:
# fluid specification & initialization
RES = 128
BOUND = 100
NUM_TIME_STEPS = 200
DT = 0.5
domain = Box(x=BOUND, y=BOUND)
INFLOW_RATE = 0.5
BUOYANCY = 0.1
inflow = Sphere(x=50, y=9.5, radius=8)

v0 = StaggeredGrid(0, 0, domain, x=RES, y=RES)
smoke0 = CenteredGrid(0, math.extrapolation.BOUNDARY, domain, x=RES, y=RES)
18/4:
# noise specification & initialization
batch_size = 2
num_channel = 2
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
up_level = 2 # noise upsampling level
res_up = RES * (2 ** up_level)
18/5:
# conditional noise upsampling & visualization
x = math.random_normal(batch(b=batch_size),math.channel(vec=num_channel),spatial(x=RES, y=RES))
x_up = warp.upsample_noise_cond(x, up_level)
vis.plot({'noise':x.b[0].vec[0],'conditional upsampled noise':x_up.b[0].vec[0]})
18/6:
# fluid step function with smoke inflow
@jit_compile
def step(v, s, p, dt):
    s = advect.mac_cormack(s, v, dt) + INFLOW_RATE * resample(inflow, to=s, soft=True)
    buoyancy = resample(s * (0, BUOYANCY), to=v)
    v = advect.semi_lagrangian(v, v, dt) + buoyancy * dt
    v, p = fluid.make_incompressible(v, (), Solve('CG', 1e-3, x0=p))
    return v, s, p
18/7: v_trj, s_trj, p_trj = iterate(step, batch(time=NUM_TIME_STEPS), v0, smoke0, None, dt=DT, range=trange, substeps=3)
18/8:
# resampling the grid to a finer grid for noise transport
part_level = 2 # partition level for triangulation
tris_per_pix_dim = 2 ** (part_level-1) # triangles per pixel per dimension
tris_per_dim = tris_per_pix_dim * RES # triangles per dimension
vtx_per_dim = tris_per_pix_dim * RES + 1 # vertices per dimention
domain1=Box(x=(-BOUND/RES/tris_per_pix_dim/2, BOUND+BOUND/RES/tris_per_pix_dim/2),y=(-BOUND/RES/tris_per_pix_dim/2,BOUND+BOUND/RES/tris_per_pix_dim/2))
grid1 = CenteredGrid(0, math.extrapolation.BOUNDARY, domain1, x=vtx_per_dim, y=vtx_per_dim)
v_trj_rs = field.resample(value=v_trj, to=grid1)

vis.plot({'velocity': v_trj.time[-1], 'velocity resampled': v_trj_rs.time[-1]})
18/9:
# vertices & triangles (represented by vertex indices) generation
_, vertices = warp.vertices_gen(RES, RES, part_level)
reshaped_mesh_idxs = warp.mesh_idx_gen(RES, RES, part_level)
18/10:
# complete noise warping step function
def noise_step(vtx_pos, noise, up_level,mesh_idxs,vertices):
    res, _ = math.spatial(noise).sizes

    part_level = up_level
    resolution = res * (2 ** up_level)
    tris_per_row = 2 ** (part_level-1)

    noise_up = warp.upsample_noise_cond(noise, up_level)

    idx_y = mesh_idxs[:,0].int()
    idx_x = mesh_idxs[:,1].int()
    warped_coords = vtx_pos.native(['x','y','vector'])[idx_y, idx_x].fliplr()
    rast_out = warp.rasterize(warped_coords, vertices, res * tris_per_row, resolution, device)

    noise_warped = warp.transport_noise(noise_up, res, rast_out, part_level)

    return noise_warped
18/11:
# normalize the grid and corresponding vertex velocities for warping
grid_nmlzd = grid1.center * tris_per_dim / BOUND
v_trj_nmlzd = v_trj_rs * tris_per_dim / BOUND
18/12:
def calc_grid_pos(grid, vel, dt):
    grid_warp = grid - vel.values*dt
    return grid_warp

def gen_grids_warped(grid, vels, dt):
    # maps = []
    maps = [grid]
    for i in range(vels.time.size-1):
        grid_warp = calc_grid_pos(grid,vels.time[i+1],dt)
        maps.append(grid_warp)
    maps = math.stack(maps, batch('time'))
    return maps
18/13:
# generate the warped grid positions
grids_warped = gen_grids_warped(grid_nmlzd,v_trj_nmlzd,.5)
18/14:
# noise warping by the proposed method, no disclusion fix
noise_trj = [x]
x_in = x
for i in range(NUM_TIME_STEPS):
    x_warped = noise_step(grids_warped.time[i+1], x_in, up_level, reshaped_mesh_idxs, vertices)
    noise_trj.append(x_warped)
    x_in = x_warped
noise_trj = math.stack(noise_trj, batch('time'))
18/15:
# noise warping by the proposed method, filling empty cell with warping from previous frame
noise_trj_prev = [x]
x_in = x
for i in range(NUM_TIME_STEPS):
    x_warped = noise_step(grids_warped.time[i+1], x_in, up_level, reshaped_mesh_idxs, vertices)
    x_warped_prev = noise_step(grids_warped.time[i], x_in, up_level, reshaped_mesh_idxs, vertices)
    x_warped = math.where(math.is_nan(x_warped),x_warped_prev,x_warped)
    noise_trj_prev.append(x_warped)
    x_in = x_warped
noise_trj_prev = math.stack(noise_trj_prev, batch('time'))
18/16:
# noise warping by the proposed method, filling empty cell with warping from last frame + random noise
noise_trj_prev_rand = [x]
x_in = x
for i in range(NUM_TIME_STEPS):
    x_warped = noise_step(grids_warped.time[i+1], x_in, up_level, reshaped_mesh_idxs, vertices)
    x_warped_prev = noise_step(grids_warped.time[i], x_in, up_level, reshaped_mesh_idxs, vertices)
    x_warped = math.where(math.is_nan(x_warped),x_warped_prev,x_warped)
    x_warped = math.where(math.is_nan(x_warped), math.random_normal(x_warped.shape), x_warped)
    noise_trj_prev_rand.append(x_warped)
    x_in = x_warped
noise_trj_prev_rand = math.stack(noise_trj_prev_rand, batch('time'))
18/17:
# noise warping comparison
row1 = math.stack([noise_trj.b[0].vec[0],noise_trj_prev.b[0].vec[0]],batch('row'))
row2 = math.stack([noise_trj_prev_rand.b[0].vec[0],s_trj.values / s_trj.values.max],batch('row'))
ani = math.stack([row1,row2],batch('col'))
t1 = math.stack(['original dubbed noise','with previous frame'],batch('row'))
t2 = math.stack(['with previous frame + random noise', 'density'],batch('row'))
ttl = math.stack([t1,t2],batch('col'))

vis.plot(ani,row_dims='row',col_dims='col', frame_time=40,animate='time',size=(10,6),title=ttl)
19/1:
!wget -nc "https://dataserv.ub.tum.de/s/m1734798.001/download?path=/&files=128_tra_small.zip" -O data/128_tra_small.zip --no-check-certificate 
!unzip -nq data/128_tra_small.zip -d data
!wget -nc "https://dataserv.ub.tum.de/s/m1734798.001/download?path=/&files=checkpoints_acdm_tra.zip" -O models/checkpoints_acdm_tra.zip --no-check-certificate 
!unzip -nq models/checkpoints_acdm_tra.zip -d models
19/2:
try:
    import google.colab  # only to ensure that we are inside colab
    !pip install einops
except ImportError:
    print("This notebook is running locally, please follow the ACDM installation instructions first, then continue with the cell below.")
    pass
19/3:
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader, SequentialSampler, RandomSampler

from einops import rearrange
from functools import partial

import matplotlib.pyplot as plt
import numpy as np

import math
import os, json
from typing import List,Tuple,Dict
19/4:
class TurbulenceDataset(Dataset):
    """Data set for turbulence and wavelet noise data

    Args:
        name: name of the dataset
        dataDirs: list of paths to data directories
        filterTop: filter for top level folder names (e.g. different types of data)
        excludeFilterTop: mode for filterTop (exclude or include)
        filterSim: filter simulations by min and max (min inclusive, max exclusive)
        excludefilterSim: mode for filterSim (exclude or include)
        filterFrame: mandatory filter for simulation frames by min and max (min inclusive, max exclusive)
        sequenceLength: number of frames to group into a sequence and number of frames to omit in between
        randSeqOffset: randomizes the starting frame of each sequence
        simFields: list of simulation fields to include (vel is always included) ["dens", "pres"]
        simParams: list of simulation parameters to include ["rey", "mach"]
        printLevel: print mode for contents of the dataset ["none", "top", "sim", "full"]
    """

    def __init__(self, name:str, dataDirs:List[str], filterTop:List[str], excludeFilterTop:bool=False, filterSim:List[Tuple[int, int]]=[],
                excludefilterSim:bool=False, filterFrame:List[Tuple[int, int]]=[], sequenceLength:List[Tuple[int, int]]=[],
                randSeqOffset:bool=False, simFields:List[str]=[], simParams:List[str]=[], printLevel:str="none"):

        self.transform = None
        self.name = name
        self.dataDirs = dataDirs
        self.filterTop = filterTop
        self.excludeFilterTop = excludeFilterTop
        self.filterSim = filterSim
        self.excludefilterSim = excludefilterSim
        self.filterFrame = filterFrame
        self.sequenceLength = sequenceLength
        self.randSeqOffset = randSeqOffset
        self.simFields = ["velocity"]
        if "dens" in simFields:
            self.simFields += ["density"]
        if "pres" in simFields:
            self.simFields += ["pressure"]

        self.simParams = simParams
        self.printLevel = printLevel

        self.summaryPrint = []
        self.summaryPrint += ["Dataset " + name + " at " + str(dataDirs)]
        self.summaryPrint += [self.getFilterInfoString()]

        # BUILD FULL FILE LIST
        self.dataPaths = []
        self.dataPathModes = []

        for dataDir in dataDirs:
            topDirs = os.listdir(dataDir)
            topDirs.sort()

            # top level folders
            for topDir in topDirs:
                if filterTop:
                    # continue when excluding or including according to filter
                    if excludeFilterTop == any( item in topDir for item in filterTop ):
                        continue

                match = -1
                # compute matching top filter for according sim or frame filtering
                if len(filterSim) > 1 or len(filterFrame) > 1:
                    for i in range(len(filterTop)):
                        if filterTop[i] in topDir:
                            match = i
                            break
                    assert (match >= 0), "Match computation error"

                simDir = os.path.join(dataDir, topDir)
                sims = os.listdir(simDir)
                sims.sort()

                if printLevel == "top":
                    self.summaryPrint += ["Top folder loaded: " + simDir.replace(dataDir + "/", "")]

                # sim_000001 folders
                for sim in sims:
                    currentDir = os.path.join(simDir, sim)
                    if not os.path.isdir(currentDir):
                        continue

                    if len(filterSim) > 0:
                        simNum = int(sim.split("_")[1])
                        if len(filterSim) == 1:
                            if type(filterSim[0]) is tuple:
                                inside = simNum >= filterSim[0][0] and simNum < filterSim[0][1]
                            elif type(filterSim[0]) is list:
                                inside = simNum in filterSim[0]
                        else:
                            if type(filterSim[match]) is tuple:
                                inside = simNum >= filterSim[match][0] and simNum < filterSim[match][1]
                            elif type(filterSim[match]) is list:
                                inside = simNum in filterSim[match]
                        # continue when excluding or including according to filter
                        if inside == excludefilterSim:
                            continue

                    if printLevel == "sim":
                        self.summaryPrint += ["Sim loaded: " + currentDir.replace(dataDir + "/", "")]

                    # individual simulation frames
                    minFrame = filterFrame[0][0] if len(filterFrame) == 1 else filterFrame[match][0]
                    maxFrame = filterFrame[0][1] if len(filterFrame) == 1 else filterFrame[match][1]
                    seqLength = sequenceLength[0][0] if len(sequenceLength) == 1 else sequenceLength[match][0]
                    seqSkip   = sequenceLength[0][1] if len(sequenceLength) == 1 else sequenceLength[match][1]
                    for seqStart in range(minFrame, maxFrame, seqLength*seqSkip):
                        validSeq = True
                        for frame in range(seqStart, seqStart+seqLength*seqSkip, seqSkip):
                            # discard incomplete sequences at simulation end
                            if seqStart+seqLength*seqSkip > maxFrame:
                                validSeq = False
                                break

                            for field in self.simFields:
                                currentField = os.path.join(currentDir, "%s_%06d.npz" % (field, frame))
                                if not os.path.isfile(currentField):
                                    raise FileNotFoundError("Could not load %s file: %s" % (field, currentField))

                        # imcomplete sequence means there are no more frames left
                        if not validSeq:
                            break

                        if printLevel == "full":
                            self.summaryPrint += ["Frames %s loaded: %s/%s_%06d-%06d(%03d).npz" % ("-".join(self.simFields),
                                        currentDir.replace(dataDir + "/", ""), "-".join(self.simFields), seqStart, seqStart + seqLength*(seqSkip-1), seqSkip)]

                        self.dataPaths.append((currentDir, seqStart, seqStart + seqLength*seqSkip, seqSkip))

        self.summaryPrint += ["Dataset Length: %d\n" % len(self.dataPaths)]


    def __len__(self) -> int:
        return len(self.dataPaths)


    def __getitem__(self, idx:int) -> dict:
        # sequence indexing
        basePath, seqStart, seqEnd, seqSkip = self.dataPaths[idx]
        seqLen = int((seqEnd - seqStart) / seqSkip)
        if self.randSeqOffset:
            halfSeq = int((seqEnd-seqStart) / 2)
            offset = torch.randint(-halfSeq, halfSeq+1, (1,)).item()
            if seqStart + offset >= self.filterFrame[0][0] and seqEnd + offset < self.filterFrame[0][1]:
                seqStart = seqStart + offset
                seqEnd = seqEnd + offset

        # loading simulation parameters
        with open(os.path.join(basePath, "src", "description.json")) as f:
            loadedJSON = json.load(f)

            loadNames = ["Reynolds Number", "Mach Number", "Drag Coefficient", "Lift Coefficient", "Z Slice"]
            loadedParams = {}
            for loadName in loadNames:
                loadedParam = np.zeros(seqLen, dtype=np.float32)
                if loadName in loadedJSON:
                    temp = loadedJSON[loadName]
                    if isinstance(temp, int) or isinstance(temp, float):
                        temp = np.array(temp, dtype=np.float32)
                        loadedParam[0:] = np.repeat(temp, seqLen)
                    elif isinstance(temp, list):
                        loadedParam[0:] = temp[seqStart:seqEnd:seqSkip]
                    else:
                        raise ValueError("Invalid simulation parameter data type")
                loadedParams[loadName] = loadedParam

            if "rey" in self.simParams and "mach" in self.simParams:
                simParameters = np.stack([loadedParams["Reynolds Number"], loadedParams["Mach Number"]], axis=1)
            elif "rey" in self.simParams:
                simParameters = np.reshape(loadedParams["Reynolds Number"], (-1,1))
            elif "mach" in self.simParams:
                simParameters = np.reshape(loadedParams["Mach Number"], (-1,1))
            elif "zslice" in self.simParams:
                simParameters = np.reshape(loadedParams["Z Slice"], (-1,1))
            elif not self.simParams:
                simParameters ={}
            else:
                raise ValueError("Invalid specification of simulation parameters")

        # loading obstacle mask
        if os.path.isfile(os.path.join(basePath, "obstacle_mask.npz")):
            obsMask = np.load(os.path.join(basePath, "obstacle_mask.npz"))['arr_0']
        else:
            obsMask = None

        # loading fields and combining them with simulation parameters
        loaded = {}
        for field in self.simFields:
            loaded[field] = []

        for frame in range(seqStart, seqEnd, seqSkip):
            for field in self.simFields:
                loadedArr = np.load(os.path.join(basePath, "%s_%06d.npz" % (field,frame)))['arr_0']
                loaded[field] += [loadedArr.astype(np.float32)]

        loadedFields = []
        for field in self.simFields:
            loadedFields += [np.stack(loaded[field], axis=0)]

        if type(simParameters) is not dict:
            vel = loadedFields[0]
            if vel.ndim == 4:
                simParExpanded = simParameters[:,:,np.newaxis,np.newaxis]
                simParExpanded = np.repeat(np.repeat(simParExpanded, vel.shape[2], axis=2), vel.shape[3], axis=3)
            elif vel.ndim == 5:
                simParExpanded = simParameters[:,:,np.newaxis,np.newaxis,np.newaxis]
                simParExpanded = np.repeat(np.repeat(np.repeat(simParExpanded, vel.shape[2], axis=2), vel.shape[3], axis=3), vel.shape[4], axis=4)
            else:
                raise ValueError("Invalid input shape when loading samples!")
            loadedFields += [simParExpanded]

        data = np.concatenate(loadedFields, axis=1) # ORDER (fields): velocity (x,y), velocity z / density, pressure, ORDER (params): rey, mach, zslice

        # output
        dataPath = "%s/%s_%06d-%06d(%03d).npz" % (basePath, "-".join(self.simFields), seqStart, seqEnd - seqSkip, seqSkip)
        sample = {"data" : data, "simParameters" : simParameters, "allParameters" : loadedParams, "path" : dataPath}
        if obsMask is not None:
            sample["obsMask"] = obsMask

        if self.transform:
            sample = self.transform(sample)
        else:
            print("WARNING: no data transformations are employed!")

        return sample


    def printDatasetInfo(self):
        if self.transform:
            s  = "%s - Data Normalization Transformation: ACTIVE\n" % (self.name)
            self.summaryPrint += [s]
        print('\n'.join(self.summaryPrint))

    def getFilterInfoString(self) -> str:
        s  = "%s - Data Filter Setup: \n" % (self.name)
        s += "\tdataDirs: %s\n" % (str(self.dataDirs))
        s += "\tfilterTop: %s  exlude: %s\n" % (str(self.filterTop), self.excludeFilterTop)
        s += "\tfilterSim: %s  exlude: %s\n" % (str(self.filterSim), self.excludefilterSim)
        s += "\tfilterFrame: %s\n" % (str(self.filterFrame))
        s += "\tsequenceLength: %s\n" % (str(self.sequenceLength))
        return s
19/5:
class DataTransforms(object):

    def __init__(self, normalizeMode="traMixed", simFields=["dens","pres"], simParams=["mach"]):
        self.simFields = simFields
        self.simParams = simParams

        # mean and std statistics from whole dataset for normalization
        if "tra" in normalizeMode.lower() and "mixed" in normalizeMode.lower():
            # ORDER (fields): velocity (x,y), density, pressure, ORDER (params): rey, mach
            self.normMean = np.array([0.560642, -0.000129, 0.903352, 0.637941, 10000.000000, 0.700000], dtype=np.float32)
            self.normStd =  np.array([0.216987, 0.216987, 0.145391, 0.119944, 1, 0.118322], dtype=np.float32)


    def __call__(self, sample:dict):
        data = sample["data"]
        simParameters = sample["simParameters"]
        allParameters = sample["allParameters"]
        obsMask = sample.get("obsMask", None)
        path = sample["path"]

        # normalization to std. normal distr. with zero mean and unit std via statistics from whole dataset
        # ORDER (fields): velocity (x,y), velocity z / density, pressure, ORDER (params): rey, mach
        filterList = [0, 1]
        if "dens" in self.simFields:
            filterList += [2]
        if "pres" in self.simFields:
            filterList += [3]
        if "rey" in self.simParams:
            filterList += [4]
        if "mach" in self.simParams:
            filterList += [5]
        filterArr = np.array(filterList)
        filterArrParam = filterArr[-len(self.simParams):]

        if self.simParams:
            meanParam = self.normMean[filterArrParam].reshape((1,-1))
            stdParam = self.normStd[filterArrParam].reshape((1,-1))
            simParameters = (simParameters - meanParam) / stdParam

        meanData = self.normMean[filterArr].reshape((1,-1,1,1))
        stdData = self.normStd[filterArr].reshape((1,-1,1,1))
        data = (data - meanData) / stdData

        # toTensor
        result = torch.from_numpy(data)
        if obsMask is not None:
            obsMask = torch.from_numpy(obsMask)

        outDict = {"data": result, "simParameters": simParameters, "allParameters": allParameters, "path": path}
        if obsMask is not None:
            outDict["obsMask"] = obsMask
        return outDict
19/6:
class Residual(nn.Module):
    def __init__(self, fn):
        super().__init__()
        self.fn = fn

    def forward(self, x, *args, **kwargs):
        return self.fn(x, *args, **kwargs) + x

def Upsample(dim):
    return nn.ConvTranspose2d(dim, dim, 4, 2, 1)

def Downsample(dim):
    return nn.Conv2d(dim, dim, 4, 2, 1)


class SinusoidalPositionEmbeddings(nn.Module):
    def __init__(self, dim):
        super().__init__()
        self.dim = dim

    def forward(self, time):
        device = time.device
        half_dim = self.dim // 2
        embeddings = math.log(10000) / (half_dim - 1)
        embeddings = torch.exp(torch.arange(half_dim, device=device) * -embeddings)
        embeddings = time[:, None] * embeddings[None, :]
        embeddings = torch.cat((embeddings.sin(), embeddings.cos()), dim=-1)
        return embeddings
19/7:
class ConvNextBlock(nn.Module):

    def __init__(self, dim, dim_out, *, time_emb_dim=None, mult=2, norm=True):
        super().__init__()
        self.mlp = (
            nn.Sequential(nn.GELU(), nn.Linear(time_emb_dim, dim))
            if time_emb_dim is not None else None
        )

        self.ds_conv = nn.Conv2d(dim, dim, 7, padding=3, groups=dim)

        self.net = nn.Sequential(
            nn.GroupNorm(1, dim) if norm else nn.Identity(),
            nn.Conv2d(dim, dim_out * mult, 3, padding=1),
            nn.GELU(),
            nn.GroupNorm(1, dim_out * mult),
            nn.Conv2d(dim_out * mult, dim_out, 3, padding=1),
        )

        self.res_conv = nn.Conv2d(dim, dim_out, 1) if dim != dim_out else nn.Identity()

    def forward(self, x, time_emb=None):
        h = self.ds_conv(x)

        if self.mlp is not None and time_emb is not None:
            assert time_emb is not None, "time embedding must be passed in"
            condition = self.mlp(time_emb)
            h = h + rearrange(condition, "b c -> b c 1 1")

        h = self.net(h)
        return h + self.res_conv(x)
19/8:
class Attention(nn.Module):
    def __init__(self, dim, heads=4, dim_head=32):
        super().__init__()
        self.scale = dim_head**-0.5
        self.heads = heads
        hidden_dim = dim_head * heads
        self.to_qkv = nn.Conv2d(dim, hidden_dim * 3, 1, bias=False)
        self.to_out = nn.Conv2d(hidden_dim, dim, 1)

    def forward(self, x):
        b, c, h, w = x.shape
        qkv = self.to_qkv(x).chunk(3, dim=1)
        q, k, v = map(
            lambda t: rearrange(t, "b (h c) x y -> b h c (x y)", h=self.heads), qkv
        )
        q = q * self.scale

        sim = torch.einsum("b h d i, b h d j -> b h i j", q, k)
        sim = sim - sim.amax(dim=-1, keepdim=True).detach()
        attn = sim.softmax(dim=-1)

        out = torch.einsum("b h i j, b h d j -> b h i d", attn, v)
        out = rearrange(out, "b h (x y) d -> b (h d) x y", x=h, y=w)
        return self.to_out(out)


class LinearAttention(nn.Module):
    def __init__(self, dim, heads=4, dim_head=32):
        super().__init__()
        self.scale = dim_head**-0.5
        self.heads = heads
        hidden_dim = dim_head * heads
        self.to_qkv = nn.Conv2d(dim, hidden_dim * 3, 1, bias=False)

        self.to_out = nn.Sequential(nn.Conv2d(hidden_dim, dim, 1),
                                    nn.GroupNorm(1, dim))

    def forward(self, x):
        b, c, h, w = x.shape
        qkv = self.to_qkv(x).chunk(3, dim=1)
        q, k, v = map(
            lambda t: rearrange(t, "b (h c) x y -> b h c (x y)", h=self.heads), qkv
        )

        q = q.softmax(dim=-2)
        k = k.softmax(dim=-1)

        q = q * self.scale
        context = torch.einsum("b h d n, b h e n -> b h d e", k, v)

        out = torch.einsum("b h d e, b h d n -> b h e n", context, q)
        out = rearrange(out, "b h c (x y) -> b (h c) x y", h=self.heads, x=h, y=w)
        return self.to_out(out)
19/9:
class PreNorm(nn.Module):
    def __init__(self, dim, fn):
        super().__init__()
        self.fn = fn
        self.norm = nn.GroupNorm(1, dim)

    def forward(self, x):
        x = self.norm(x)
        return self.fn(x)


class Unet(nn.Module):
    def __init__(
        self,
        dim,
        init_dim=None,
        out_dim=None,
        dim_mults=(1, 2, 4, 8),
        channels=3,
        with_time_emb=True,
        resnet_block_groups=8,
        use_convnext=True,
        convnext_mult=2,
    ):
        super().__init__()

        # determine dimensions
        self.channels = channels

        init_dim = init_dim if init_dim is not None else dim // 3 * 2
        self.init_conv = nn.Conv2d(channels, init_dim, 7, padding=3)

        dims = [init_dim, *map(lambda m: dim * m, dim_mults)]
        in_out = list(zip(dims[:-1], dims[1:]))

        if use_convnext:
            block_klass = partial(ConvNextBlock, mult=convnext_mult)
        else:
            raise NotImplementedError()

        # time embeddings
        if with_time_emb:
            time_dim = dim * 4
            self.time_mlp = nn.Sequential(
                SinusoidalPositionEmbeddings(dim),
                nn.Linear(dim, time_dim),
                nn.GELU(),
                nn.Linear(time_dim, time_dim),
            )

        else:
            time_dim = None
            self.time_mlp = None
            self.cond_mlp = None
            self.sim_mlp = None

        # layers
        self.downs = nn.ModuleList([])
        self.ups = nn.ModuleList([])
        num_resolutions = len(in_out)

        for ind, (dim_in, dim_out) in enumerate(in_out):
            is_last = ind >= (num_resolutions - 1)

            self.downs.append(
                nn.ModuleList(
                    [
                        block_klass(dim_in, dim_out, time_emb_dim=time_dim),
                        block_klass(dim_out, dim_out, time_emb_dim=time_dim),
                        Residual(PreNorm(dim_out, LinearAttention(dim_out))),
                        Downsample(dim_out) if not is_last else nn.Identity(),
                    ]
                )
            )

        mid_dim = dims[-1]
        self.mid_block1 = block_klass(mid_dim, mid_dim, time_emb_dim=time_dim)
        self.mid_attn = Residual(PreNorm(mid_dim, Attention(mid_dim)))
        self.mid_block2 = block_klass(mid_dim, mid_dim, time_emb_dim=time_dim)

        for ind, (dim_in, dim_out) in enumerate(reversed(in_out[1:])):
            is_last = ind >= (num_resolutions - 1)

            self.ups.append(
                nn.ModuleList(
                    [
                        block_klass(dim_out * 2, dim_in, time_emb_dim=time_dim),
                        block_klass(dim_in, dim_in, time_emb_dim=time_dim),
                        Residual(PreNorm(dim_in, LinearAttention(dim_in))),
                        Upsample(dim_in) if not is_last else nn.Identity(),
                    ]
                )
            )

        out_dim = out_dim if out_dim is not None else channels
        self.final_conv = nn.Sequential(
            block_klass(dim, dim), nn.Conv2d(dim, out_dim, 1)
        )

    def forward(self, x, time):
        x = self.init_conv(x)

        t = self.time_mlp(time) if self.time_mlp is not None else None

        h = []

        # downsample
        for block1, block2, attn, downsample in self.downs:
            x = block1(x, t)
            x = block2(x, t)
            x = attn(x)
            h.append(x)
            x = downsample(x)

        # bottleneck
        x = self.mid_block1(x, t)
        x = self.mid_attn(x)
        x = self.mid_block2(x, t)

        # upsample
        for block1, block2, attn, upsample in self.ups:
            x = torch.cat((x, h.pop()), dim=1)
            x = block1(x, t)
            x = block2(x, t)
            x = attn(x)
            x = upsample(x)

        return self.final_conv(x)
19/10:
def linear_beta_schedule(timesteps):
    if timesteps < 10:
        raise ValueError("Warning: Less than 10 timesteps require adjustments to this schedule!")

    beta_start = 0.0001 * (500/timesteps) # adjust reference values determined for 500 steps
    beta_end = 0.02 * (500/timesteps)
    betas = torch.linspace(beta_start, beta_end, timesteps)
    return torch.clip(betas, 0.0001, 0.9999)
19/11:
class DiffusionModel(nn.Module):
    def __init__(self, diffusionSteps:int, condChannels:int, dataChannels:int):
        super(DiffusionModel, self).__init__()

        self.timesteps = diffusionSteps
        betas = linear_beta_schedule(timesteps=self.timesteps)

        betas = betas.unsqueeze(1).unsqueeze(2).unsqueeze(3)
        alphas = 1.0 - betas
        alphasCumprod = torch.cumprod(alphas, axis=0)
        alphasCumprodPrev = F.pad(alphasCumprod[:-1], (0,0,0,0,0,0,1,0), value=1.0)
        sqrtRecipAlphas = torch.sqrt(1.0 / alphas)

        # calculations for diffusion q(x_t | x_{t-1}) and others
        sqrtAlphasCumprod = torch.sqrt(alphasCumprod)
        sqrtOneMinusAlphasCumprod = torch.sqrt(1. - alphasCumprod)

        # calculations for posterior q(x_{t-1} | x_t, x_0)
        posteriorVariance = betas * (1. - alphasCumprodPrev) / (1. - alphasCumprod)
        sqrtPosteriorVariance = torch.sqrt(posteriorVariance)

        self.register_buffer("betas", betas)
        self.register_buffer("sqrtRecipAlphas", sqrtRecipAlphas)
        self.register_buffer("sqrtAlphasCumprod", sqrtAlphasCumprod)
        self.register_buffer("sqrtOneMinusAlphasCumprod", sqrtOneMinusAlphasCumprod)
        self.register_buffer("sqrtPosteriorVariance", sqrtPosteriorVariance)

        # backbone model
        self.unet = Unet(
            dim=128,
            channels= condChannels + dataChannels,
            dim_mults=(1,1,1),
            use_convnext=True,
            convnext_mult=1,
        )


    # input shape (both inputs): B S C W H (D) -> output shape (both outputs): B S nC W H (D)
    def forward(self, conditioning:torch.Tensor, data:torch.Tensor) -> torch.Tensor:
        device = "cuda" if data.is_cuda else "cpu"
        seqLen = data.shape[1]

        # combine batch and sequence dimension for decoder processing
        d = torch.reshape(data, (-1, data.shape[2], data.shape[3], data.shape[4]))
        cond = torch.reshape(conditioning, (-1, conditioning.shape[2], conditioning.shape[3], conditioning.shape[4]))

        # TRAINING
        if self.training:

            # forward diffusion process that adds noise to data
            d = torch.concat((cond, d), dim=1)
            noise = torch.randn_like(d, device=device)
            t = torch.randint(0, self.timesteps, (d.shape[0],), device=device).long()
            dNoisy = self.sqrtAlphasCumprod[t] * d + self.sqrtOneMinusAlphasCumprod[t] * noise

            # noise prediction with network
            predictedNoise = self.unet(dNoisy, t)

            # unstack batch and sequence dimension again
            noise = torch.reshape(noise, (-1, seqLen, conditioning.shape[2] + data.shape[2], data.shape[3], data.shape[4]))
            predictedNoise = torch.reshape(predictedNoise, (-1, seqLen, conditioning.shape[2] + data.shape[2], data.shape[3], data.shape[4]))

            return noise, predictedNoise


        # INFERENCE
        else:
            # conditioned reverse diffusion process
            dNoise = torch.randn_like(d, device=device)
            cNoise = torch.randn_like(cond, device=device)

            for i in reversed(range(0, self.timesteps)):
                t = i * torch.ones(cond.shape[0], device=device).long()

                # compute conditioned part with normal forward diffusion
                condNoisy = self.sqrtAlphasCumprod[t] * cond + self.sqrtOneMinusAlphasCumprod[t] * cNoise

                dNoiseCond = torch.concat((condNoisy, dNoise), dim=1)

                # backward diffusion process that removes noise to create data
                predictedNoiseCond = self.unet(dNoiseCond, t)

                # use model (noise predictor) to predict mean
                modelMean = self.sqrtRecipAlphas[t] * (dNoiseCond - self.betas[t] * predictedNoiseCond / self.sqrtOneMinusAlphasCumprod[t])

                dNoise = modelMean[:, cond.shape[1]:modelMean.shape[1]] # discard prediction of conditioning
                if i != 0:
                    # sample randomly (only for non-final prediction), use mean directly for final prediction
                    dNoise = dNoise + self.sqrtPosteriorVariance[t] * torch.randn_like(dNoise)

            # unstack batch and sequence dimension again
            dNoise = torch.reshape(dNoise, (-1, seqLen, data.shape[2], data.shape[3], data.shape[4]))

            return dNoise
19/12:
device = "cuda" if torch.cuda.is_available() else "cpu"
print("Training device: %s" % device)

startFromCheckpoint = True

batch = 32 # training batch size
if startFromCheckpoint:
    epochs = 10 # finetune only for a small number of epochs
    lr = 0.00001 # since the model is already trained, a conservatively low learning rate
else:
    epochs = 10000 # train from scratch for large number of epochs
    lr = 0.0001 # larger learning rate for training from scratch

sequenceLength = [3,2] # three timesteps (two input steps and one target step) with a temporal stride of 2
simFields = ["dens", "pres"] # the provided data set contains velocity (implict), as well as density and pressure values
simParams = ["mach"] # scalar simulation parameters on which the model is conditioned only contain the Mach number here
diffusionSteps = 20 # the provided model checkpoint was pretrained on 20 diffusion steps

# data set and data loading
trainSet = TurbulenceDataset("Training", ["data"], filterTop=["128_small_tra"], filterSim=[[0]], excludefilterSim=False, filterFrame=[(250,1000)],
                sequenceLength=[sequenceLength], randSeqOffset=True, simFields=simFields, simParams=simParams, printLevel="sim")
trainSet.transform = DataTransforms(normalizeMode="traMixed", simFields=simFields, simParams=simParams)
trainSet.printDatasetInfo()
trainSampler = RandomSampler(trainSet)
#trainSampler = SequentialSampler(trainSet)
trainLoader = DataLoader(trainSet, sampler=trainSampler, batch_size=batch, drop_last=True, num_workers=2)

# model definition
condChannels = 2 * (2 + len(simFields) + len(simParams))
dataChannels = 2 + len(simFields) + len(simParams)
model = DiffusionModel(diffusionSteps, condChannels, dataChannels)

if startFromCheckpoint:
    # load weights from checkpoint
    # loaded = torch.load("models/models_tra/128_acdm-r20_02/Model.pth", map_location=torch.device('cpu'))
    loaded = torch.load("models/NEW.zip", map_location=torch.device('cpu'))
    model.load_state_dict(loaded["stateDictDecoder"])
model.train()
model.to(device)

# print model info and trainable weigths
paramsTrainable = sum([np.prod(p.size()) for p in filter(lambda p: p.requires_grad, model.parameters())])
params = sum([np.prod(p.size()) for p in model.parameters()])
#print(model)
print("Trainable Weights (All Weights): %d (%d)" % (paramsTrainable, params))

# training loop
print("\nStarting training...")
optimizer = torch.optim.Adam(model.parameters(), lr=lr)
for epoch in range(epochs):
    losses = []
    for s, sample in enumerate(trainLoader, 0):
        optimizer.zero_grad()

        d = sample["data"].to(device)

        inputSteps = 2
        cond = []
        for i in range(inputSteps):
            cond += [d[:,i:i+1]] # collect input steps
        conditioning = torch.concat(cond, dim=2) # combine along channel dimension
        data = d[:, inputSteps:inputSteps+1]

        noise, predictedNoise = model(conditioning=conditioning, data=data)

        loss = F.smooth_l1_loss(noise, predictedNoise)
        print("    [Epoch %2d, Batch %4d]: %1.7f" % (epoch, s, loss.detach().cpu().item()))
        loss.backward()

        losses += [loss.detach().cpu().item()]

        optimizer.step()
    print("[Epoch %2d, FULL]: %1.7f" % (epoch, sum(losses)/len(losses)))

print("Training complete!")
19/13:
!wget -nc "https://dataserv.ub.tum.de/s/m1734798.001/download?path=/&files=128_tra_small.zip" -O data/128_tra_small.zip --no-check-certificate 
!unzip -nq data/128_tra_small.zip -d data
!wget -nc "https://dataserv.ub.tum.de/s/m1734798.001/download?path=/&files=checkpoints_acdm_tra.zip" -O models/checkpoints_acdm_tra.zip --no-check-certificate 
!unzip -nq models/checkpoints_acdm_tra.zip -d models
19/14:
try:
    import google.colab  # only to ensure that we are inside colab
    !pip install einops
except ImportError:
    print("This notebook is running locally, please follow the ACDM installation instructions first, then continue with the cell below.")
    pass
19/15:
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader, SequentialSampler, RandomSampler

from einops import rearrange
from functools import partial

import matplotlib.pyplot as plt
import numpy as np

import math
import os, json
from typing import List,Tuple,Dict
19/16:
class TurbulenceDataset(Dataset):
    """Data set for turbulence and wavelet noise data

    Args:
        name: name of the dataset
        dataDirs: list of paths to data directories
        filterTop: filter for top level folder names (e.g. different types of data)
        excludeFilterTop: mode for filterTop (exclude or include)
        filterSim: filter simulations by min and max (min inclusive, max exclusive)
        excludefilterSim: mode for filterSim (exclude or include)
        filterFrame: mandatory filter for simulation frames by min and max (min inclusive, max exclusive)
        sequenceLength: number of frames to group into a sequence and number of frames to omit in between
        randSeqOffset: randomizes the starting frame of each sequence
        simFields: list of simulation fields to include (vel is always included) ["dens", "pres"]
        simParams: list of simulation parameters to include ["rey", "mach"]
        printLevel: print mode for contents of the dataset ["none", "top", "sim", "full"]
    """

    def __init__(self, name:str, dataDirs:List[str], filterTop:List[str], excludeFilterTop:bool=False, filterSim:List[Tuple[int, int]]=[],
                excludefilterSim:bool=False, filterFrame:List[Tuple[int, int]]=[], sequenceLength:List[Tuple[int, int]]=[],
                randSeqOffset:bool=False, simFields:List[str]=[], simParams:List[str]=[], printLevel:str="none"):

        self.transform = None
        self.name = name
        self.dataDirs = dataDirs
        self.filterTop = filterTop
        self.excludeFilterTop = excludeFilterTop
        self.filterSim = filterSim
        self.excludefilterSim = excludefilterSim
        self.filterFrame = filterFrame
        self.sequenceLength = sequenceLength
        self.randSeqOffset = randSeqOffset
        self.simFields = ["velocity"]
        if "dens" in simFields:
            self.simFields += ["density"]
        if "pres" in simFields:
            self.simFields += ["pressure"]

        self.simParams = simParams
        self.printLevel = printLevel

        self.summaryPrint = []
        self.summaryPrint += ["Dataset " + name + " at " + str(dataDirs)]
        self.summaryPrint += [self.getFilterInfoString()]

        # BUILD FULL FILE LIST
        self.dataPaths = []
        self.dataPathModes = []

        for dataDir in dataDirs:
            topDirs = os.listdir(dataDir)
            topDirs.sort()

            # top level folders
            for topDir in topDirs:
                if filterTop:
                    # continue when excluding or including according to filter
                    if excludeFilterTop == any( item in topDir for item in filterTop ):
                        continue

                match = -1
                # compute matching top filter for according sim or frame filtering
                if len(filterSim) > 1 or len(filterFrame) > 1:
                    for i in range(len(filterTop)):
                        if filterTop[i] in topDir:
                            match = i
                            break
                    assert (match >= 0), "Match computation error"

                simDir = os.path.join(dataDir, topDir)
                sims = os.listdir(simDir)
                sims.sort()

                if printLevel == "top":
                    self.summaryPrint += ["Top folder loaded: " + simDir.replace(dataDir + "/", "")]

                # sim_000001 folders
                for sim in sims:
                    currentDir = os.path.join(simDir, sim)
                    if not os.path.isdir(currentDir):
                        continue

                    if len(filterSim) > 0:
                        simNum = int(sim.split("_")[1])
                        if len(filterSim) == 1:
                            if type(filterSim[0]) is tuple:
                                inside = simNum >= filterSim[0][0] and simNum < filterSim[0][1]
                            elif type(filterSim[0]) is list:
                                inside = simNum in filterSim[0]
                        else:
                            if type(filterSim[match]) is tuple:
                                inside = simNum >= filterSim[match][0] and simNum < filterSim[match][1]
                            elif type(filterSim[match]) is list:
                                inside = simNum in filterSim[match]
                        # continue when excluding or including according to filter
                        if inside == excludefilterSim:
                            continue

                    if printLevel == "sim":
                        self.summaryPrint += ["Sim loaded: " + currentDir.replace(dataDir + "/", "")]

                    # individual simulation frames
                    minFrame = filterFrame[0][0] if len(filterFrame) == 1 else filterFrame[match][0]
                    maxFrame = filterFrame[0][1] if len(filterFrame) == 1 else filterFrame[match][1]
                    seqLength = sequenceLength[0][0] if len(sequenceLength) == 1 else sequenceLength[match][0]
                    seqSkip   = sequenceLength[0][1] if len(sequenceLength) == 1 else sequenceLength[match][1]
                    for seqStart in range(minFrame, maxFrame, seqLength*seqSkip):
                        validSeq = True
                        for frame in range(seqStart, seqStart+seqLength*seqSkip, seqSkip):
                            # discard incomplete sequences at simulation end
                            if seqStart+seqLength*seqSkip > maxFrame:
                                validSeq = False
                                break

                            for field in self.simFields:
                                currentField = os.path.join(currentDir, "%s_%06d.npz" % (field, frame))
                                if not os.path.isfile(currentField):
                                    raise FileNotFoundError("Could not load %s file: %s" % (field, currentField))

                        # imcomplete sequence means there are no more frames left
                        if not validSeq:
                            break

                        if printLevel == "full":
                            self.summaryPrint += ["Frames %s loaded: %s/%s_%06d-%06d(%03d).npz" % ("-".join(self.simFields),
                                        currentDir.replace(dataDir + "/", ""), "-".join(self.simFields), seqStart, seqStart + seqLength*(seqSkip-1), seqSkip)]

                        self.dataPaths.append((currentDir, seqStart, seqStart + seqLength*seqSkip, seqSkip))

        self.summaryPrint += ["Dataset Length: %d\n" % len(self.dataPaths)]


    def __len__(self) -> int:
        return len(self.dataPaths)


    def __getitem__(self, idx:int) -> dict:
        # sequence indexing
        basePath, seqStart, seqEnd, seqSkip = self.dataPaths[idx]
        seqLen = int((seqEnd - seqStart) / seqSkip)
        if self.randSeqOffset:
            halfSeq = int((seqEnd-seqStart) / 2)
            offset = torch.randint(-halfSeq, halfSeq+1, (1,)).item()
            if seqStart + offset >= self.filterFrame[0][0] and seqEnd + offset < self.filterFrame[0][1]:
                seqStart = seqStart + offset
                seqEnd = seqEnd + offset

        # loading simulation parameters
        with open(os.path.join(basePath, "src", "description.json")) as f:
            loadedJSON = json.load(f)

            loadNames = ["Reynolds Number", "Mach Number", "Drag Coefficient", "Lift Coefficient", "Z Slice"]
            loadedParams = {}
            for loadName in loadNames:
                loadedParam = np.zeros(seqLen, dtype=np.float32)
                if loadName in loadedJSON:
                    temp = loadedJSON[loadName]
                    if isinstance(temp, int) or isinstance(temp, float):
                        temp = np.array(temp, dtype=np.float32)
                        loadedParam[0:] = np.repeat(temp, seqLen)
                    elif isinstance(temp, list):
                        loadedParam[0:] = temp[seqStart:seqEnd:seqSkip]
                    else:
                        raise ValueError("Invalid simulation parameter data type")
                loadedParams[loadName] = loadedParam

            if "rey" in self.simParams and "mach" in self.simParams:
                simParameters = np.stack([loadedParams["Reynolds Number"], loadedParams["Mach Number"]], axis=1)
            elif "rey" in self.simParams:
                simParameters = np.reshape(loadedParams["Reynolds Number"], (-1,1))
            elif "mach" in self.simParams:
                simParameters = np.reshape(loadedParams["Mach Number"], (-1,1))
            elif "zslice" in self.simParams:
                simParameters = np.reshape(loadedParams["Z Slice"], (-1,1))
            elif not self.simParams:
                simParameters ={}
            else:
                raise ValueError("Invalid specification of simulation parameters")

        # loading obstacle mask
        if os.path.isfile(os.path.join(basePath, "obstacle_mask.npz")):
            obsMask = np.load(os.path.join(basePath, "obstacle_mask.npz"))['arr_0']
        else:
            obsMask = None

        # loading fields and combining them with simulation parameters
        loaded = {}
        for field in self.simFields:
            loaded[field] = []

        for frame in range(seqStart, seqEnd, seqSkip):
            for field in self.simFields:
                loadedArr = np.load(os.path.join(basePath, "%s_%06d.npz" % (field,frame)))['arr_0']
                loaded[field] += [loadedArr.astype(np.float32)]

        loadedFields = []
        for field in self.simFields:
            loadedFields += [np.stack(loaded[field], axis=0)]

        if type(simParameters) is not dict:
            vel = loadedFields[0]
            if vel.ndim == 4:
                simParExpanded = simParameters[:,:,np.newaxis,np.newaxis]
                simParExpanded = np.repeat(np.repeat(simParExpanded, vel.shape[2], axis=2), vel.shape[3], axis=3)
            elif vel.ndim == 5:
                simParExpanded = simParameters[:,:,np.newaxis,np.newaxis,np.newaxis]
                simParExpanded = np.repeat(np.repeat(np.repeat(simParExpanded, vel.shape[2], axis=2), vel.shape[3], axis=3), vel.shape[4], axis=4)
            else:
                raise ValueError("Invalid input shape when loading samples!")
            loadedFields += [simParExpanded]

        data = np.concatenate(loadedFields, axis=1) # ORDER (fields): velocity (x,y), velocity z / density, pressure, ORDER (params): rey, mach, zslice

        # output
        dataPath = "%s/%s_%06d-%06d(%03d).npz" % (basePath, "-".join(self.simFields), seqStart, seqEnd - seqSkip, seqSkip)
        sample = {"data" : data, "simParameters" : simParameters, "allParameters" : loadedParams, "path" : dataPath}
        if obsMask is not None:
            sample["obsMask"] = obsMask

        if self.transform:
            sample = self.transform(sample)
        else:
            print("WARNING: no data transformations are employed!")

        return sample


    def printDatasetInfo(self):
        if self.transform:
            s  = "%s - Data Normalization Transformation: ACTIVE\n" % (self.name)
            self.summaryPrint += [s]
        print('\n'.join(self.summaryPrint))

    def getFilterInfoString(self) -> str:
        s  = "%s - Data Filter Setup: \n" % (self.name)
        s += "\tdataDirs: %s\n" % (str(self.dataDirs))
        s += "\tfilterTop: %s  exlude: %s\n" % (str(self.filterTop), self.excludeFilterTop)
        s += "\tfilterSim: %s  exlude: %s\n" % (str(self.filterSim), self.excludefilterSim)
        s += "\tfilterFrame: %s\n" % (str(self.filterFrame))
        s += "\tsequenceLength: %s\n" % (str(self.sequenceLength))
        return s
19/17:
class DataTransforms(object):

    def __init__(self, normalizeMode="traMixed", simFields=["dens","pres"], simParams=["mach"]):
        self.simFields = simFields
        self.simParams = simParams

        # mean and std statistics from whole dataset for normalization
        if "tra" in normalizeMode.lower() and "mixed" in normalizeMode.lower():
            # ORDER (fields): velocity (x,y), density, pressure, ORDER (params): rey, mach
            self.normMean = np.array([0.560642, -0.000129, 0.903352, 0.637941, 10000.000000, 0.700000], dtype=np.float32)
            self.normStd =  np.array([0.216987, 0.216987, 0.145391, 0.119944, 1, 0.118322], dtype=np.float32)


    def __call__(self, sample:dict):
        data = sample["data"]
        simParameters = sample["simParameters"]
        allParameters = sample["allParameters"]
        obsMask = sample.get("obsMask", None)
        path = sample["path"]

        # normalization to std. normal distr. with zero mean and unit std via statistics from whole dataset
        # ORDER (fields): velocity (x,y), velocity z / density, pressure, ORDER (params): rey, mach
        filterList = [0, 1]
        if "dens" in self.simFields:
            filterList += [2]
        if "pres" in self.simFields:
            filterList += [3]
        if "rey" in self.simParams:
            filterList += [4]
        if "mach" in self.simParams:
            filterList += [5]
        filterArr = np.array(filterList)
        filterArrParam = filterArr[-len(self.simParams):]

        if self.simParams:
            meanParam = self.normMean[filterArrParam].reshape((1,-1))
            stdParam = self.normStd[filterArrParam].reshape((1,-1))
            simParameters = (simParameters - meanParam) / stdParam

        meanData = self.normMean[filterArr].reshape((1,-1,1,1))
        stdData = self.normStd[filterArr].reshape((1,-1,1,1))
        data = (data - meanData) / stdData

        # toTensor
        result = torch.from_numpy(data)
        if obsMask is not None:
            obsMask = torch.from_numpy(obsMask)

        outDict = {"data": result, "simParameters": simParameters, "allParameters": allParameters, "path": path}
        if obsMask is not None:
            outDict["obsMask"] = obsMask
        return outDict
19/18:
class Residual(nn.Module):
    def __init__(self, fn):
        super().__init__()
        self.fn = fn

    def forward(self, x, *args, **kwargs):
        return self.fn(x, *args, **kwargs) + x

def Upsample(dim):
    return nn.ConvTranspose2d(dim, dim, 4, 2, 1)

def Downsample(dim):
    return nn.Conv2d(dim, dim, 4, 2, 1)


class SinusoidalPositionEmbeddings(nn.Module):
    def __init__(self, dim):
        super().__init__()
        self.dim = dim

    def forward(self, time):
        device = time.device
        half_dim = self.dim // 2
        embeddings = math.log(10000) / (half_dim - 1)
        embeddings = torch.exp(torch.arange(half_dim, device=device) * -embeddings)
        embeddings = time[:, None] * embeddings[None, :]
        embeddings = torch.cat((embeddings.sin(), embeddings.cos()), dim=-1)
        return embeddings
19/19:
class ConvNextBlock(nn.Module):

    def __init__(self, dim, dim_out, *, time_emb_dim=None, mult=2, norm=True):
        super().__init__()
        self.mlp = (
            nn.Sequential(nn.GELU(), nn.Linear(time_emb_dim, dim))
            if time_emb_dim is not None else None
        )

        self.ds_conv = nn.Conv2d(dim, dim, 7, padding=3, groups=dim)

        self.net = nn.Sequential(
            nn.GroupNorm(1, dim) if norm else nn.Identity(),
            nn.Conv2d(dim, dim_out * mult, 3, padding=1),
            nn.GELU(),
            nn.GroupNorm(1, dim_out * mult),
            nn.Conv2d(dim_out * mult, dim_out, 3, padding=1),
        )

        self.res_conv = nn.Conv2d(dim, dim_out, 1) if dim != dim_out else nn.Identity()

    def forward(self, x, time_emb=None):
        h = self.ds_conv(x)

        if self.mlp is not None and time_emb is not None:
            assert time_emb is not None, "time embedding must be passed in"
            condition = self.mlp(time_emb)
            h = h + rearrange(condition, "b c -> b c 1 1")

        h = self.net(h)
        return h + self.res_conv(x)
19/20:
class Attention(nn.Module):
    def __init__(self, dim, heads=4, dim_head=32):
        super().__init__()
        self.scale = dim_head**-0.5
        self.heads = heads
        hidden_dim = dim_head * heads
        self.to_qkv = nn.Conv2d(dim, hidden_dim * 3, 1, bias=False)
        self.to_out = nn.Conv2d(hidden_dim, dim, 1)

    def forward(self, x):
        b, c, h, w = x.shape
        qkv = self.to_qkv(x).chunk(3, dim=1)
        q, k, v = map(
            lambda t: rearrange(t, "b (h c) x y -> b h c (x y)", h=self.heads), qkv
        )
        q = q * self.scale

        sim = torch.einsum("b h d i, b h d j -> b h i j", q, k)
        sim = sim - sim.amax(dim=-1, keepdim=True).detach()
        attn = sim.softmax(dim=-1)

        out = torch.einsum("b h i j, b h d j -> b h i d", attn, v)
        out = rearrange(out, "b h (x y) d -> b (h d) x y", x=h, y=w)
        return self.to_out(out)


class LinearAttention(nn.Module):
    def __init__(self, dim, heads=4, dim_head=32):
        super().__init__()
        self.scale = dim_head**-0.5
        self.heads = heads
        hidden_dim = dim_head * heads
        self.to_qkv = nn.Conv2d(dim, hidden_dim * 3, 1, bias=False)

        self.to_out = nn.Sequential(nn.Conv2d(hidden_dim, dim, 1),
                                    nn.GroupNorm(1, dim))

    def forward(self, x):
        b, c, h, w = x.shape
        qkv = self.to_qkv(x).chunk(3, dim=1)
        q, k, v = map(
            lambda t: rearrange(t, "b (h c) x y -> b h c (x y)", h=self.heads), qkv
        )

        q = q.softmax(dim=-2)
        k = k.softmax(dim=-1)

        q = q * self.scale
        context = torch.einsum("b h d n, b h e n -> b h d e", k, v)

        out = torch.einsum("b h d e, b h d n -> b h e n", context, q)
        out = rearrange(out, "b h c (x y) -> b (h c) x y", h=self.heads, x=h, y=w)
        return self.to_out(out)
19/21:
class PreNorm(nn.Module):
    def __init__(self, dim, fn):
        super().__init__()
        self.fn = fn
        self.norm = nn.GroupNorm(1, dim)

    def forward(self, x):
        x = self.norm(x)
        return self.fn(x)


class Unet(nn.Module):
    def __init__(
        self,
        dim,
        init_dim=None,
        out_dim=None,
        dim_mults=(1, 2, 4, 8),
        channels=3,
        with_time_emb=True,
        resnet_block_groups=8,
        use_convnext=True,
        convnext_mult=2,
    ):
        super().__init__()

        # determine dimensions
        self.channels = channels

        init_dim = init_dim if init_dim is not None else dim // 3 * 2
        self.init_conv = nn.Conv2d(channels, init_dim, 7, padding=3)

        dims = [init_dim, *map(lambda m: dim * m, dim_mults)]
        in_out = list(zip(dims[:-1], dims[1:]))

        if use_convnext:
            block_klass = partial(ConvNextBlock, mult=convnext_mult)
        else:
            raise NotImplementedError()

        # time embeddings
        if with_time_emb:
            time_dim = dim * 4
            self.time_mlp = nn.Sequential(
                SinusoidalPositionEmbeddings(dim),
                nn.Linear(dim, time_dim),
                nn.GELU(),
                nn.Linear(time_dim, time_dim),
            )

        else:
            time_dim = None
            self.time_mlp = None
            self.cond_mlp = None
            self.sim_mlp = None

        # layers
        self.downs = nn.ModuleList([])
        self.ups = nn.ModuleList([])
        num_resolutions = len(in_out)

        for ind, (dim_in, dim_out) in enumerate(in_out):
            is_last = ind >= (num_resolutions - 1)

            self.downs.append(
                nn.ModuleList(
                    [
                        block_klass(dim_in, dim_out, time_emb_dim=time_dim),
                        block_klass(dim_out, dim_out, time_emb_dim=time_dim),
                        Residual(PreNorm(dim_out, LinearAttention(dim_out))),
                        Downsample(dim_out) if not is_last else nn.Identity(),
                    ]
                )
            )

        mid_dim = dims[-1]
        self.mid_block1 = block_klass(mid_dim, mid_dim, time_emb_dim=time_dim)
        self.mid_attn = Residual(PreNorm(mid_dim, Attention(mid_dim)))
        self.mid_block2 = block_klass(mid_dim, mid_dim, time_emb_dim=time_dim)

        for ind, (dim_in, dim_out) in enumerate(reversed(in_out[1:])):
            is_last = ind >= (num_resolutions - 1)

            self.ups.append(
                nn.ModuleList(
                    [
                        block_klass(dim_out * 2, dim_in, time_emb_dim=time_dim),
                        block_klass(dim_in, dim_in, time_emb_dim=time_dim),
                        Residual(PreNorm(dim_in, LinearAttention(dim_in))),
                        Upsample(dim_in) if not is_last else nn.Identity(),
                    ]
                )
            )

        out_dim = out_dim if out_dim is not None else channels
        self.final_conv = nn.Sequential(
            block_klass(dim, dim), nn.Conv2d(dim, out_dim, 1)
        )

    def forward(self, x, time):
        x = self.init_conv(x)

        t = self.time_mlp(time) if self.time_mlp is not None else None

        h = []

        # downsample
        for block1, block2, attn, downsample in self.downs:
            x = block1(x, t)
            x = block2(x, t)
            x = attn(x)
            h.append(x)
            x = downsample(x)

        # bottleneck
        x = self.mid_block1(x, t)
        x = self.mid_attn(x)
        x = self.mid_block2(x, t)

        # upsample
        for block1, block2, attn, upsample in self.ups:
            x = torch.cat((x, h.pop()), dim=1)
            x = block1(x, t)
            x = block2(x, t)
            x = attn(x)
            x = upsample(x)

        return self.final_conv(x)
19/22:
def linear_beta_schedule(timesteps):
    if timesteps < 10:
        raise ValueError("Warning: Less than 10 timesteps require adjustments to this schedule!")

    beta_start = 0.0001 * (500/timesteps) # adjust reference values determined for 500 steps
    beta_end = 0.02 * (500/timesteps)
    betas = torch.linspace(beta_start, beta_end, timesteps)
    return torch.clip(betas, 0.0001, 0.9999)
19/23:
class DiffusionModel(nn.Module):
    def __init__(self, diffusionSteps:int, condChannels:int, dataChannels:int):
        super(DiffusionModel, self).__init__()

        self.timesteps = diffusionSteps
        betas = linear_beta_schedule(timesteps=self.timesteps)

        betas = betas.unsqueeze(1).unsqueeze(2).unsqueeze(3)
        alphas = 1.0 - betas
        alphasCumprod = torch.cumprod(alphas, axis=0)
        alphasCumprodPrev = F.pad(alphasCumprod[:-1], (0,0,0,0,0,0,1,0), value=1.0)
        sqrtRecipAlphas = torch.sqrt(1.0 / alphas)

        # calculations for diffusion q(x_t | x_{t-1}) and others
        sqrtAlphasCumprod = torch.sqrt(alphasCumprod)
        sqrtOneMinusAlphasCumprod = torch.sqrt(1. - alphasCumprod)

        # calculations for posterior q(x_{t-1} | x_t, x_0)
        posteriorVariance = betas * (1. - alphasCumprodPrev) / (1. - alphasCumprod)
        sqrtPosteriorVariance = torch.sqrt(posteriorVariance)

        self.register_buffer("betas", betas)
        self.register_buffer("sqrtRecipAlphas", sqrtRecipAlphas)
        self.register_buffer("sqrtAlphasCumprod", sqrtAlphasCumprod)
        self.register_buffer("sqrtOneMinusAlphasCumprod", sqrtOneMinusAlphasCumprod)
        self.register_buffer("sqrtPosteriorVariance", sqrtPosteriorVariance)

        # backbone model
        self.unet = Unet(
            dim=128,
            channels= condChannels + dataChannels,
            dim_mults=(1,1,1),
            use_convnext=True,
            convnext_mult=1,
        )


    # input shape (both inputs): B S C W H (D) -> output shape (both outputs): B S nC W H (D)
    def forward(self, conditioning:torch.Tensor, data:torch.Tensor) -> torch.Tensor:
        device = "cuda" if data.is_cuda else "cpu"
        seqLen = data.shape[1]

        # combine batch and sequence dimension for decoder processing
        d = torch.reshape(data, (-1, data.shape[2], data.shape[3], data.shape[4]))
        cond = torch.reshape(conditioning, (-1, conditioning.shape[2], conditioning.shape[3], conditioning.shape[4]))

        # TRAINING
        if self.training:

            # forward diffusion process that adds noise to data
            d = torch.concat((cond, d), dim=1)
            noise = torch.randn_like(d, device=device)
            t = torch.randint(0, self.timesteps, (d.shape[0],), device=device).long()
            dNoisy = self.sqrtAlphasCumprod[t] * d + self.sqrtOneMinusAlphasCumprod[t] * noise

            # noise prediction with network
            predictedNoise = self.unet(dNoisy, t)

            # unstack batch and sequence dimension again
            noise = torch.reshape(noise, (-1, seqLen, conditioning.shape[2] + data.shape[2], data.shape[3], data.shape[4]))
            predictedNoise = torch.reshape(predictedNoise, (-1, seqLen, conditioning.shape[2] + data.shape[2], data.shape[3], data.shape[4]))

            return noise, predictedNoise


        # INFERENCE
        else:
            # conditioned reverse diffusion process
            dNoise = torch.randn_like(d, device=device)
            cNoise = torch.randn_like(cond, device=device)

            for i in reversed(range(0, self.timesteps)):
                t = i * torch.ones(cond.shape[0], device=device).long()

                # compute conditioned part with normal forward diffusion
                condNoisy = self.sqrtAlphasCumprod[t] * cond + self.sqrtOneMinusAlphasCumprod[t] * cNoise

                dNoiseCond = torch.concat((condNoisy, dNoise), dim=1)

                # backward diffusion process that removes noise to create data
                predictedNoiseCond = self.unet(dNoiseCond, t)

                # use model (noise predictor) to predict mean
                modelMean = self.sqrtRecipAlphas[t] * (dNoiseCond - self.betas[t] * predictedNoiseCond / self.sqrtOneMinusAlphasCumprod[t])

                dNoise = modelMean[:, cond.shape[1]:modelMean.shape[1]] # discard prediction of conditioning
                if i != 0:
                    # sample randomly (only for non-final prediction), use mean directly for final prediction
                    dNoise = dNoise + self.sqrtPosteriorVariance[t] * torch.randn_like(dNoise)

            # unstack batch and sequence dimension again
            dNoise = torch.reshape(dNoise, (-1, seqLen, data.shape[2], data.shape[3], data.shape[4]))

            return dNoise
19/24:
device = "cuda" if torch.cuda.is_available() else "cpu"
print("Training device: %s" % device)

startFromCheckpoint = True

batch = 32 # training batch size
if startFromCheckpoint:
    epochs = 10 # finetune only for a small number of epochs
    lr = 0.00001 # since the model is already trained, a conservatively low learning rate
else:
    epochs = 10000 # train from scratch for large number of epochs
    lr = 0.0001 # larger learning rate for training from scratch

sequenceLength = [3,2] # three timesteps (two input steps and one target step) with a temporal stride of 2
simFields = ["dens", "pres"] # the provided data set contains velocity (implict), as well as density and pressure values
simParams = ["mach"] # scalar simulation parameters on which the model is conditioned only contain the Mach number here
diffusionSteps = 20 # the provided model checkpoint was pretrained on 20 diffusion steps

# data set and data loading
trainSet = TurbulenceDataset("Training", ["data"], filterTop=["128_small_tra"], filterSim=[[0]], excludefilterSim=False, filterFrame=[(250,1000)],
                sequenceLength=[sequenceLength], randSeqOffset=True, simFields=simFields, simParams=simParams, printLevel="sim")
trainSet.transform = DataTransforms(normalizeMode="traMixed", simFields=simFields, simParams=simParams)
trainSet.printDatasetInfo()
trainSampler = RandomSampler(trainSet)
#trainSampler = SequentialSampler(trainSet)
trainLoader = DataLoader(trainSet, sampler=trainSampler, batch_size=batch, drop_last=True, num_workers=2)

# model definition
condChannels = 2 * (2 + len(simFields) + len(simParams))
dataChannels = 2 + len(simFields) + len(simParams)
model = DiffusionModel(diffusionSteps, condChannels, dataChannels)

if startFromCheckpoint:
    # load weights from checkpoint
    # loaded = torch.load("models/models_tra/128_acdm-r20_02/Model.pth", map_location=torch.device('cpu'))
    # model.load_state_dict(loaded["stateDictDecoder"])
    loaded = torch.load("models/NEW.zip", map_location=torch.device('cpu'))
    model.load_state_dict()
    
model.train()
model.to(device)

# print model info and trainable weigths
paramsTrainable = sum([np.prod(p.size()) for p in filter(lambda p: p.requires_grad, model.parameters())])
params = sum([np.prod(p.size()) for p in model.parameters()])
#print(model)
print("Trainable Weights (All Weights): %d (%d)" % (paramsTrainable, params))

# training loop
print("\nStarting training...")
optimizer = torch.optim.Adam(model.parameters(), lr=lr)
for epoch in range(epochs):
    losses = []
    for s, sample in enumerate(trainLoader, 0):
        optimizer.zero_grad()

        d = sample["data"].to(device)

        inputSteps = 2
        cond = []
        for i in range(inputSteps):
            cond += [d[:,i:i+1]] # collect input steps
        conditioning = torch.concat(cond, dim=2) # combine along channel dimension
        data = d[:, inputSteps:inputSteps+1]

        noise, predictedNoise = model(conditioning=conditioning, data=data)

        loss = F.smooth_l1_loss(noise, predictedNoise)
        print("    [Epoch %2d, Batch %4d]: %1.7f" % (epoch, s, loss.detach().cpu().item()))
        loss.backward()

        losses += [loss.detach().cpu().item()]

        optimizer.step()
    print("[Epoch %2d, FULL]: %1.7f" % (epoch, sum(losses)/len(losses)))

print("Training complete!")
19/25:
!wget -nc "https://dataserv.ub.tum.de/s/m1734798.001/download?path=/&files=128_tra_small.zip" -O data/128_tra_small.zip --no-check-certificate 
!unzip -nq data/128_tra_small.zip -d data
!wget -nc "https://dataserv.ub.tum.de/s/m1734798.001/download?path=/&files=checkpoints_acdm_tra.zip" -O models/checkpoints_acdm_tra.zip --no-check-certificate 
!unzip -nq models/checkpoints_acdm_tra.zip -d models
19/26:
try:
    import google.colab  # only to ensure that we are inside colab
    !pip install einops
except ImportError:
    print("This notebook is running locally, please follow the ACDM installation instructions first, then continue with the cell below.")
    pass
19/27:
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader, SequentialSampler, RandomSampler

from einops import rearrange
from functools import partial

import matplotlib.pyplot as plt
import numpy as np

import math
import os, json
from typing import List,Tuple,Dict
19/28:
class TurbulenceDataset(Dataset):
    """Data set for turbulence and wavelet noise data

    Args:
        name: name of the dataset
        dataDirs: list of paths to data directories
        filterTop: filter for top level folder names (e.g. different types of data)
        excludeFilterTop: mode for filterTop (exclude or include)
        filterSim: filter simulations by min and max (min inclusive, max exclusive)
        excludefilterSim: mode for filterSim (exclude or include)
        filterFrame: mandatory filter for simulation frames by min and max (min inclusive, max exclusive)
        sequenceLength: number of frames to group into a sequence and number of frames to omit in between
        randSeqOffset: randomizes the starting frame of each sequence
        simFields: list of simulation fields to include (vel is always included) ["dens", "pres"]
        simParams: list of simulation parameters to include ["rey", "mach"]
        printLevel: print mode for contents of the dataset ["none", "top", "sim", "full"]
    """

    def __init__(self, name:str, dataDirs:List[str], filterTop:List[str], excludeFilterTop:bool=False, filterSim:List[Tuple[int, int]]=[],
                excludefilterSim:bool=False, filterFrame:List[Tuple[int, int]]=[], sequenceLength:List[Tuple[int, int]]=[],
                randSeqOffset:bool=False, simFields:List[str]=[], simParams:List[str]=[], printLevel:str="none"):

        self.transform = None
        self.name = name
        self.dataDirs = dataDirs
        self.filterTop = filterTop
        self.excludeFilterTop = excludeFilterTop
        self.filterSim = filterSim
        self.excludefilterSim = excludefilterSim
        self.filterFrame = filterFrame
        self.sequenceLength = sequenceLength
        self.randSeqOffset = randSeqOffset
        self.simFields = ["velocity"]
        if "dens" in simFields:
            self.simFields += ["density"]
        if "pres" in simFields:
            self.simFields += ["pressure"]

        self.simParams = simParams
        self.printLevel = printLevel

        self.summaryPrint = []
        self.summaryPrint += ["Dataset " + name + " at " + str(dataDirs)]
        self.summaryPrint += [self.getFilterInfoString()]

        # BUILD FULL FILE LIST
        self.dataPaths = []
        self.dataPathModes = []

        for dataDir in dataDirs:
            topDirs = os.listdir(dataDir)
            topDirs.sort()

            # top level folders
            for topDir in topDirs:
                if filterTop:
                    # continue when excluding or including according to filter
                    if excludeFilterTop == any( item in topDir for item in filterTop ):
                        continue

                match = -1
                # compute matching top filter for according sim or frame filtering
                if len(filterSim) > 1 or len(filterFrame) > 1:
                    for i in range(len(filterTop)):
                        if filterTop[i] in topDir:
                            match = i
                            break
                    assert (match >= 0), "Match computation error"

                simDir = os.path.join(dataDir, topDir)
                sims = os.listdir(simDir)
                sims.sort()

                if printLevel == "top":
                    self.summaryPrint += ["Top folder loaded: " + simDir.replace(dataDir + "/", "")]

                # sim_000001 folders
                for sim in sims:
                    currentDir = os.path.join(simDir, sim)
                    if not os.path.isdir(currentDir):
                        continue

                    if len(filterSim) > 0:
                        simNum = int(sim.split("_")[1])
                        if len(filterSim) == 1:
                            if type(filterSim[0]) is tuple:
                                inside = simNum >= filterSim[0][0] and simNum < filterSim[0][1]
                            elif type(filterSim[0]) is list:
                                inside = simNum in filterSim[0]
                        else:
                            if type(filterSim[match]) is tuple:
                                inside = simNum >= filterSim[match][0] and simNum < filterSim[match][1]
                            elif type(filterSim[match]) is list:
                                inside = simNum in filterSim[match]
                        # continue when excluding or including according to filter
                        if inside == excludefilterSim:
                            continue

                    if printLevel == "sim":
                        self.summaryPrint += ["Sim loaded: " + currentDir.replace(dataDir + "/", "")]

                    # individual simulation frames
                    minFrame = filterFrame[0][0] if len(filterFrame) == 1 else filterFrame[match][0]
                    maxFrame = filterFrame[0][1] if len(filterFrame) == 1 else filterFrame[match][1]
                    seqLength = sequenceLength[0][0] if len(sequenceLength) == 1 else sequenceLength[match][0]
                    seqSkip   = sequenceLength[0][1] if len(sequenceLength) == 1 else sequenceLength[match][1]
                    for seqStart in range(minFrame, maxFrame, seqLength*seqSkip):
                        validSeq = True
                        for frame in range(seqStart, seqStart+seqLength*seqSkip, seqSkip):
                            # discard incomplete sequences at simulation end
                            if seqStart+seqLength*seqSkip > maxFrame:
                                validSeq = False
                                break

                            for field in self.simFields:
                                currentField = os.path.join(currentDir, "%s_%06d.npz" % (field, frame))
                                if not os.path.isfile(currentField):
                                    raise FileNotFoundError("Could not load %s file: %s" % (field, currentField))

                        # imcomplete sequence means there are no more frames left
                        if not validSeq:
                            break

                        if printLevel == "full":
                            self.summaryPrint += ["Frames %s loaded: %s/%s_%06d-%06d(%03d).npz" % ("-".join(self.simFields),
                                        currentDir.replace(dataDir + "/", ""), "-".join(self.simFields), seqStart, seqStart + seqLength*(seqSkip-1), seqSkip)]

                        self.dataPaths.append((currentDir, seqStart, seqStart + seqLength*seqSkip, seqSkip))

        self.summaryPrint += ["Dataset Length: %d\n" % len(self.dataPaths)]


    def __len__(self) -> int:
        return len(self.dataPaths)


    def __getitem__(self, idx:int) -> dict:
        # sequence indexing
        basePath, seqStart, seqEnd, seqSkip = self.dataPaths[idx]
        seqLen = int((seqEnd - seqStart) / seqSkip)
        if self.randSeqOffset:
            halfSeq = int((seqEnd-seqStart) / 2)
            offset = torch.randint(-halfSeq, halfSeq+1, (1,)).item()
            if seqStart + offset >= self.filterFrame[0][0] and seqEnd + offset < self.filterFrame[0][1]:
                seqStart = seqStart + offset
                seqEnd = seqEnd + offset

        # loading simulation parameters
        with open(os.path.join(basePath, "src", "description.json")) as f:
            loadedJSON = json.load(f)

            loadNames = ["Reynolds Number", "Mach Number", "Drag Coefficient", "Lift Coefficient", "Z Slice"]
            loadedParams = {}
            for loadName in loadNames:
                loadedParam = np.zeros(seqLen, dtype=np.float32)
                if loadName in loadedJSON:
                    temp = loadedJSON[loadName]
                    if isinstance(temp, int) or isinstance(temp, float):
                        temp = np.array(temp, dtype=np.float32)
                        loadedParam[0:] = np.repeat(temp, seqLen)
                    elif isinstance(temp, list):
                        loadedParam[0:] = temp[seqStart:seqEnd:seqSkip]
                    else:
                        raise ValueError("Invalid simulation parameter data type")
                loadedParams[loadName] = loadedParam

            if "rey" in self.simParams and "mach" in self.simParams:
                simParameters = np.stack([loadedParams["Reynolds Number"], loadedParams["Mach Number"]], axis=1)
            elif "rey" in self.simParams:
                simParameters = np.reshape(loadedParams["Reynolds Number"], (-1,1))
            elif "mach" in self.simParams:
                simParameters = np.reshape(loadedParams["Mach Number"], (-1,1))
            elif "zslice" in self.simParams:
                simParameters = np.reshape(loadedParams["Z Slice"], (-1,1))
            elif not self.simParams:
                simParameters ={}
            else:
                raise ValueError("Invalid specification of simulation parameters")

        # loading obstacle mask
        if os.path.isfile(os.path.join(basePath, "obstacle_mask.npz")):
            obsMask = np.load(os.path.join(basePath, "obstacle_mask.npz"))['arr_0']
        else:
            obsMask = None

        # loading fields and combining them with simulation parameters
        loaded = {}
        for field in self.simFields:
            loaded[field] = []

        for frame in range(seqStart, seqEnd, seqSkip):
            for field in self.simFields:
                loadedArr = np.load(os.path.join(basePath, "%s_%06d.npz" % (field,frame)))['arr_0']
                loaded[field] += [loadedArr.astype(np.float32)]

        loadedFields = []
        for field in self.simFields:
            loadedFields += [np.stack(loaded[field], axis=0)]

        if type(simParameters) is not dict:
            vel = loadedFields[0]
            if vel.ndim == 4:
                simParExpanded = simParameters[:,:,np.newaxis,np.newaxis]
                simParExpanded = np.repeat(np.repeat(simParExpanded, vel.shape[2], axis=2), vel.shape[3], axis=3)
            elif vel.ndim == 5:
                simParExpanded = simParameters[:,:,np.newaxis,np.newaxis,np.newaxis]
                simParExpanded = np.repeat(np.repeat(np.repeat(simParExpanded, vel.shape[2], axis=2), vel.shape[3], axis=3), vel.shape[4], axis=4)
            else:
                raise ValueError("Invalid input shape when loading samples!")
            loadedFields += [simParExpanded]

        data = np.concatenate(loadedFields, axis=1) # ORDER (fields): velocity (x,y), velocity z / density, pressure, ORDER (params): rey, mach, zslice

        # output
        dataPath = "%s/%s_%06d-%06d(%03d).npz" % (basePath, "-".join(self.simFields), seqStart, seqEnd - seqSkip, seqSkip)
        sample = {"data" : data, "simParameters" : simParameters, "allParameters" : loadedParams, "path" : dataPath}
        if obsMask is not None:
            sample["obsMask"] = obsMask

        if self.transform:
            sample = self.transform(sample)
        else:
            print("WARNING: no data transformations are employed!")

        return sample


    def printDatasetInfo(self):
        if self.transform:
            s  = "%s - Data Normalization Transformation: ACTIVE\n" % (self.name)
            self.summaryPrint += [s]
        print('\n'.join(self.summaryPrint))

    def getFilterInfoString(self) -> str:
        s  = "%s - Data Filter Setup: \n" % (self.name)
        s += "\tdataDirs: %s\n" % (str(self.dataDirs))
        s += "\tfilterTop: %s  exlude: %s\n" % (str(self.filterTop), self.excludeFilterTop)
        s += "\tfilterSim: %s  exlude: %s\n" % (str(self.filterSim), self.excludefilterSim)
        s += "\tfilterFrame: %s\n" % (str(self.filterFrame))
        s += "\tsequenceLength: %s\n" % (str(self.sequenceLength))
        return s
19/29:
class DataTransforms(object):

    def __init__(self, normalizeMode="traMixed", simFields=["dens","pres"], simParams=["mach"]):
        self.simFields = simFields
        self.simParams = simParams

        # mean and std statistics from whole dataset for normalization
        if "tra" in normalizeMode.lower() and "mixed" in normalizeMode.lower():
            # ORDER (fields): velocity (x,y), density, pressure, ORDER (params): rey, mach
            self.normMean = np.array([0.560642, -0.000129, 0.903352, 0.637941, 10000.000000, 0.700000], dtype=np.float32)
            self.normStd =  np.array([0.216987, 0.216987, 0.145391, 0.119944, 1, 0.118322], dtype=np.float32)


    def __call__(self, sample:dict):
        data = sample["data"]
        simParameters = sample["simParameters"]
        allParameters = sample["allParameters"]
        obsMask = sample.get("obsMask", None)
        path = sample["path"]

        # normalization to std. normal distr. with zero mean and unit std via statistics from whole dataset
        # ORDER (fields): velocity (x,y), velocity z / density, pressure, ORDER (params): rey, mach
        filterList = [0, 1]
        if "dens" in self.simFields:
            filterList += [2]
        if "pres" in self.simFields:
            filterList += [3]
        if "rey" in self.simParams:
            filterList += [4]
        if "mach" in self.simParams:
            filterList += [5]
        filterArr = np.array(filterList)
        filterArrParam = filterArr[-len(self.simParams):]

        if self.simParams:
            meanParam = self.normMean[filterArrParam].reshape((1,-1))
            stdParam = self.normStd[filterArrParam].reshape((1,-1))
            simParameters = (simParameters - meanParam) / stdParam

        meanData = self.normMean[filterArr].reshape((1,-1,1,1))
        stdData = self.normStd[filterArr].reshape((1,-1,1,1))
        data = (data - meanData) / stdData

        # toTensor
        result = torch.from_numpy(data)
        if obsMask is not None:
            obsMask = torch.from_numpy(obsMask)

        outDict = {"data": result, "simParameters": simParameters, "allParameters": allParameters, "path": path}
        if obsMask is not None:
            outDict["obsMask"] = obsMask
        return outDict
19/30:
class Residual(nn.Module):
    def __init__(self, fn):
        super().__init__()
        self.fn = fn

    def forward(self, x, *args, **kwargs):
        return self.fn(x, *args, **kwargs) + x

def Upsample(dim):
    return nn.ConvTranspose2d(dim, dim, 4, 2, 1)

def Downsample(dim):
    return nn.Conv2d(dim, dim, 4, 2, 1)


class SinusoidalPositionEmbeddings(nn.Module):
    def __init__(self, dim):
        super().__init__()
        self.dim = dim

    def forward(self, time):
        device = time.device
        half_dim = self.dim // 2
        embeddings = math.log(10000) / (half_dim - 1)
        embeddings = torch.exp(torch.arange(half_dim, device=device) * -embeddings)
        embeddings = time[:, None] * embeddings[None, :]
        embeddings = torch.cat((embeddings.sin(), embeddings.cos()), dim=-1)
        return embeddings
19/31:
class ConvNextBlock(nn.Module):

    def __init__(self, dim, dim_out, *, time_emb_dim=None, mult=2, norm=True):
        super().__init__()
        self.mlp = (
            nn.Sequential(nn.GELU(), nn.Linear(time_emb_dim, dim))
            if time_emb_dim is not None else None
        )

        self.ds_conv = nn.Conv2d(dim, dim, 7, padding=3, groups=dim)

        self.net = nn.Sequential(
            nn.GroupNorm(1, dim) if norm else nn.Identity(),
            nn.Conv2d(dim, dim_out * mult, 3, padding=1),
            nn.GELU(),
            nn.GroupNorm(1, dim_out * mult),
            nn.Conv2d(dim_out * mult, dim_out, 3, padding=1),
        )

        self.res_conv = nn.Conv2d(dim, dim_out, 1) if dim != dim_out else nn.Identity()

    def forward(self, x, time_emb=None):
        h = self.ds_conv(x)

        if self.mlp is not None and time_emb is not None:
            assert time_emb is not None, "time embedding must be passed in"
            condition = self.mlp(time_emb)
            h = h + rearrange(condition, "b c -> b c 1 1")

        h = self.net(h)
        return h + self.res_conv(x)
19/32:
class Attention(nn.Module):
    def __init__(self, dim, heads=4, dim_head=32):
        super().__init__()
        self.scale = dim_head**-0.5
        self.heads = heads
        hidden_dim = dim_head * heads
        self.to_qkv = nn.Conv2d(dim, hidden_dim * 3, 1, bias=False)
        self.to_out = nn.Conv2d(hidden_dim, dim, 1)

    def forward(self, x):
        b, c, h, w = x.shape
        qkv = self.to_qkv(x).chunk(3, dim=1)
        q, k, v = map(
            lambda t: rearrange(t, "b (h c) x y -> b h c (x y)", h=self.heads), qkv
        )
        q = q * self.scale

        sim = torch.einsum("b h d i, b h d j -> b h i j", q, k)
        sim = sim - sim.amax(dim=-1, keepdim=True).detach()
        attn = sim.softmax(dim=-1)

        out = torch.einsum("b h i j, b h d j -> b h i d", attn, v)
        out = rearrange(out, "b h (x y) d -> b (h d) x y", x=h, y=w)
        return self.to_out(out)


class LinearAttention(nn.Module):
    def __init__(self, dim, heads=4, dim_head=32):
        super().__init__()
        self.scale = dim_head**-0.5
        self.heads = heads
        hidden_dim = dim_head * heads
        self.to_qkv = nn.Conv2d(dim, hidden_dim * 3, 1, bias=False)

        self.to_out = nn.Sequential(nn.Conv2d(hidden_dim, dim, 1),
                                    nn.GroupNorm(1, dim))

    def forward(self, x):
        b, c, h, w = x.shape
        qkv = self.to_qkv(x).chunk(3, dim=1)
        q, k, v = map(
            lambda t: rearrange(t, "b (h c) x y -> b h c (x y)", h=self.heads), qkv
        )

        q = q.softmax(dim=-2)
        k = k.softmax(dim=-1)

        q = q * self.scale
        context = torch.einsum("b h d n, b h e n -> b h d e", k, v)

        out = torch.einsum("b h d e, b h d n -> b h e n", context, q)
        out = rearrange(out, "b h c (x y) -> b (h c) x y", h=self.heads, x=h, y=w)
        return self.to_out(out)
19/33:
class PreNorm(nn.Module):
    def __init__(self, dim, fn):
        super().__init__()
        self.fn = fn
        self.norm = nn.GroupNorm(1, dim)

    def forward(self, x):
        x = self.norm(x)
        return self.fn(x)


class Unet(nn.Module):
    def __init__(
        self,
        dim,
        init_dim=None,
        out_dim=None,
        dim_mults=(1, 2, 4, 8),
        channels=3,
        with_time_emb=True,
        resnet_block_groups=8,
        use_convnext=True,
        convnext_mult=2,
    ):
        super().__init__()

        # determine dimensions
        self.channels = channels

        init_dim = init_dim if init_dim is not None else dim // 3 * 2
        self.init_conv = nn.Conv2d(channels, init_dim, 7, padding=3)

        dims = [init_dim, *map(lambda m: dim * m, dim_mults)]
        in_out = list(zip(dims[:-1], dims[1:]))

        if use_convnext:
            block_klass = partial(ConvNextBlock, mult=convnext_mult)
        else:
            raise NotImplementedError()

        # time embeddings
        if with_time_emb:
            time_dim = dim * 4
            self.time_mlp = nn.Sequential(
                SinusoidalPositionEmbeddings(dim),
                nn.Linear(dim, time_dim),
                nn.GELU(),
                nn.Linear(time_dim, time_dim),
            )

        else:
            time_dim = None
            self.time_mlp = None
            self.cond_mlp = None
            self.sim_mlp = None

        # layers
        self.downs = nn.ModuleList([])
        self.ups = nn.ModuleList([])
        num_resolutions = len(in_out)

        for ind, (dim_in, dim_out) in enumerate(in_out):
            is_last = ind >= (num_resolutions - 1)

            self.downs.append(
                nn.ModuleList(
                    [
                        block_klass(dim_in, dim_out, time_emb_dim=time_dim),
                        block_klass(dim_out, dim_out, time_emb_dim=time_dim),
                        Residual(PreNorm(dim_out, LinearAttention(dim_out))),
                        Downsample(dim_out) if not is_last else nn.Identity(),
                    ]
                )
            )

        mid_dim = dims[-1]
        self.mid_block1 = block_klass(mid_dim, mid_dim, time_emb_dim=time_dim)
        self.mid_attn = Residual(PreNorm(mid_dim, Attention(mid_dim)))
        self.mid_block2 = block_klass(mid_dim, mid_dim, time_emb_dim=time_dim)

        for ind, (dim_in, dim_out) in enumerate(reversed(in_out[1:])):
            is_last = ind >= (num_resolutions - 1)

            self.ups.append(
                nn.ModuleList(
                    [
                        block_klass(dim_out * 2, dim_in, time_emb_dim=time_dim),
                        block_klass(dim_in, dim_in, time_emb_dim=time_dim),
                        Residual(PreNorm(dim_in, LinearAttention(dim_in))),
                        Upsample(dim_in) if not is_last else nn.Identity(),
                    ]
                )
            )

        out_dim = out_dim if out_dim is not None else channels
        self.final_conv = nn.Sequential(
            block_klass(dim, dim), nn.Conv2d(dim, out_dim, 1)
        )

    def forward(self, x, time):
        x = self.init_conv(x)

        t = self.time_mlp(time) if self.time_mlp is not None else None

        h = []

        # downsample
        for block1, block2, attn, downsample in self.downs:
            x = block1(x, t)
            x = block2(x, t)
            x = attn(x)
            h.append(x)
            x = downsample(x)

        # bottleneck
        x = self.mid_block1(x, t)
        x = self.mid_attn(x)
        x = self.mid_block2(x, t)

        # upsample
        for block1, block2, attn, upsample in self.ups:
            x = torch.cat((x, h.pop()), dim=1)
            x = block1(x, t)
            x = block2(x, t)
            x = attn(x)
            x = upsample(x)

        return self.final_conv(x)
19/34:
def linear_beta_schedule(timesteps):
    if timesteps < 10:
        raise ValueError("Warning: Less than 10 timesteps require adjustments to this schedule!")

    beta_start = 0.0001 * (500/timesteps) # adjust reference values determined for 500 steps
    beta_end = 0.02 * (500/timesteps)
    betas = torch.linspace(beta_start, beta_end, timesteps)
    return torch.clip(betas, 0.0001, 0.9999)
19/35:
class DiffusionModel(nn.Module):
    def __init__(self, diffusionSteps:int, condChannels:int, dataChannels:int):
        super(DiffusionModel, self).__init__()

        self.timesteps = diffusionSteps
        betas = linear_beta_schedule(timesteps=self.timesteps)

        betas = betas.unsqueeze(1).unsqueeze(2).unsqueeze(3)
        alphas = 1.0 - betas
        alphasCumprod = torch.cumprod(alphas, axis=0)
        alphasCumprodPrev = F.pad(alphasCumprod[:-1], (0,0,0,0,0,0,1,0), value=1.0)
        sqrtRecipAlphas = torch.sqrt(1.0 / alphas)

        # calculations for diffusion q(x_t | x_{t-1}) and others
        sqrtAlphasCumprod = torch.sqrt(alphasCumprod)
        sqrtOneMinusAlphasCumprod = torch.sqrt(1. - alphasCumprod)

        # calculations for posterior q(x_{t-1} | x_t, x_0)
        posteriorVariance = betas * (1. - alphasCumprodPrev) / (1. - alphasCumprod)
        sqrtPosteriorVariance = torch.sqrt(posteriorVariance)

        self.register_buffer("betas", betas)
        self.register_buffer("sqrtRecipAlphas", sqrtRecipAlphas)
        self.register_buffer("sqrtAlphasCumprod", sqrtAlphasCumprod)
        self.register_buffer("sqrtOneMinusAlphasCumprod", sqrtOneMinusAlphasCumprod)
        self.register_buffer("sqrtPosteriorVariance", sqrtPosteriorVariance)

        # backbone model
        self.unet = Unet(
            dim=128,
            channels= condChannels + dataChannels,
            dim_mults=(1,1,1),
            use_convnext=True,
            convnext_mult=1,
        )


    # input shape (both inputs): B S C W H (D) -> output shape (both outputs): B S nC W H (D)
    def forward(self, conditioning:torch.Tensor, data:torch.Tensor) -> torch.Tensor:
        device = "cuda" if data.is_cuda else "cpu"
        seqLen = data.shape[1]

        # combine batch and sequence dimension for decoder processing
        d = torch.reshape(data, (-1, data.shape[2], data.shape[3], data.shape[4]))
        cond = torch.reshape(conditioning, (-1, conditioning.shape[2], conditioning.shape[3], conditioning.shape[4]))

        # TRAINING
        if self.training:

            # forward diffusion process that adds noise to data
            d = torch.concat((cond, d), dim=1)
            noise = torch.randn_like(d, device=device)
            t = torch.randint(0, self.timesteps, (d.shape[0],), device=device).long()
            dNoisy = self.sqrtAlphasCumprod[t] * d + self.sqrtOneMinusAlphasCumprod[t] * noise

            # noise prediction with network
            predictedNoise = self.unet(dNoisy, t)

            # unstack batch and sequence dimension again
            noise = torch.reshape(noise, (-1, seqLen, conditioning.shape[2] + data.shape[2], data.shape[3], data.shape[4]))
            predictedNoise = torch.reshape(predictedNoise, (-1, seqLen, conditioning.shape[2] + data.shape[2], data.shape[3], data.shape[4]))

            return noise, predictedNoise


        # INFERENCE
        else:
            # conditioned reverse diffusion process
            dNoise = torch.randn_like(d, device=device)
            cNoise = torch.randn_like(cond, device=device)

            for i in reversed(range(0, self.timesteps)):
                t = i * torch.ones(cond.shape[0], device=device).long()

                # compute conditioned part with normal forward diffusion
                condNoisy = self.sqrtAlphasCumprod[t] * cond + self.sqrtOneMinusAlphasCumprod[t] * cNoise

                dNoiseCond = torch.concat((condNoisy, dNoise), dim=1)

                # backward diffusion process that removes noise to create data
                predictedNoiseCond = self.unet(dNoiseCond, t)

                # use model (noise predictor) to predict mean
                modelMean = self.sqrtRecipAlphas[t] * (dNoiseCond - self.betas[t] * predictedNoiseCond / self.sqrtOneMinusAlphasCumprod[t])

                dNoise = modelMean[:, cond.shape[1]:modelMean.shape[1]] # discard prediction of conditioning
                if i != 0:
                    # sample randomly (only for non-final prediction), use mean directly for final prediction
                    dNoise = dNoise + self.sqrtPosteriorVariance[t] * torch.randn_like(dNoise)

            # unstack batch and sequence dimension again
            dNoise = torch.reshape(dNoise, (-1, seqLen, data.shape[2], data.shape[3], data.shape[4]))

            return dNoise
19/36:
device = "cuda" if torch.cuda.is_available() else "cpu"
print("Training device: %s" % device)

startFromCheckpoint = True

batch = 32 # training batch size
if startFromCheckpoint:
    epochs = 10 # finetune only for a small number of epochs
    lr = 0.00001 # since the model is already trained, a conservatively low learning rate
else:
    epochs = 10000 # train from scratch for large number of epochs
    lr = 0.0001 # larger learning rate for training from scratch

sequenceLength = [3,2] # three timesteps (two input steps and one target step) with a temporal stride of 2
simFields = ["dens", "pres"] # the provided data set contains velocity (implict), as well as density and pressure values
simParams = ["mach"] # scalar simulation parameters on which the model is conditioned only contain the Mach number here
diffusionSteps = 20 # the provided model checkpoint was pretrained on 20 diffusion steps

# data set and data loading
trainSet = TurbulenceDataset("Training", ["data"], filterTop=["128_small_tra"], filterSim=[[0]], excludefilterSim=False, filterFrame=[(250,1000)],
                sequenceLength=[sequenceLength], randSeqOffset=True, simFields=simFields, simParams=simParams, printLevel="sim")
trainSet.transform = DataTransforms(normalizeMode="traMixed", simFields=simFields, simParams=simParams)
trainSet.printDatasetInfo()
trainSampler = RandomSampler(trainSet)
#trainSampler = SequentialSampler(trainSet)
trainLoader = DataLoader(trainSet, sampler=trainSampler, batch_size=batch, drop_last=True, num_workers=2)

# model definition
condChannels = 2 * (2 + len(simFields) + len(simParams))
dataChannels = 2 + len(simFields) + len(simParams)
model = DiffusionModel(diffusionSteps, condChannels, dataChannels)

if startFromCheckpoint:
    # load weights from checkpoint
    # loaded = torch.load("models/models_tra/128_acdm-r20_02/Model.pth", map_location=torch.device('cpu'))
    # model.load_state_dict(loaded["stateDictDecoder"])
    loaded = torch.load("models/NEW.zip", map_location=torch.device('cpu'))
    model = loaded
    
model.train()
model.to(device)

# print model info and trainable weigths
paramsTrainable = sum([np.prod(p.size()) for p in filter(lambda p: p.requires_grad, model.parameters())])
params = sum([np.prod(p.size()) for p in model.parameters()])
#print(model)
print("Trainable Weights (All Weights): %d (%d)" % (paramsTrainable, params))

# training loop
print("\nStarting training...")
optimizer = torch.optim.Adam(model.parameters(), lr=lr)
for epoch in range(epochs):
    losses = []
    for s, sample in enumerate(trainLoader, 0):
        optimizer.zero_grad()

        d = sample["data"].to(device)

        inputSteps = 2
        cond = []
        for i in range(inputSteps):
            cond += [d[:,i:i+1]] # collect input steps
        conditioning = torch.concat(cond, dim=2) # combine along channel dimension
        data = d[:, inputSteps:inputSteps+1]

        noise, predictedNoise = model(conditioning=conditioning, data=data)

        loss = F.smooth_l1_loss(noise, predictedNoise)
        print("    [Epoch %2d, Batch %4d]: %1.7f" % (epoch, s, loss.detach().cpu().item()))
        loss.backward()

        losses += [loss.detach().cpu().item()]

        optimizer.step()
    print("[Epoch %2d, FULL]: %1.7f" % (epoch, sum(losses)/len(losses)))

print("Training complete!")
19/37:
device = "cuda" if torch.cuda.is_available() else "cpu"
print("Training device: %s" % device)

startFromCheckpoint = True

batch = 32 # training batch size
if startFromCheckpoint:
    epochs = 10 # finetune only for a small number of epochs
    lr = 0.00001 # since the model is already trained, a conservatively low learning rate
else:
    epochs = 10000 # train from scratch for large number of epochs
    lr = 0.0001 # larger learning rate for training from scratch

sequenceLength = [3,2] # three timesteps (two input steps and one target step) with a temporal stride of 2
simFields = ["dens", "pres"] # the provided data set contains velocity (implict), as well as density and pressure values
simParams = ["mach"] # scalar simulation parameters on which the model is conditioned only contain the Mach number here
diffusionSteps = 20 # the provided model checkpoint was pretrained on 20 diffusion steps

# data set and data loading
trainSet = TurbulenceDataset("Training", ["data"], filterTop=["128_small_tra"], filterSim=[[0]], excludefilterSim=False, filterFrame=[(250,1000)],
                sequenceLength=[sequenceLength], randSeqOffset=True, simFields=simFields, simParams=simParams, printLevel="sim")
trainSet.transform = DataTransforms(normalizeMode="traMixed", simFields=simFields, simParams=simParams)
trainSet.printDatasetInfo()
trainSampler = RandomSampler(trainSet)
#trainSampler = SequentialSampler(trainSet)
trainLoader = DataLoader(trainSet, sampler=trainSampler, batch_size=batch, drop_last=True, num_workers=2)

# model definition
condChannels = 2 * (2 + len(simFields) + len(simParams))
dataChannels = 2 + len(simFields) + len(simParams)
model = DiffusionModel(diffusionSteps, condChannels, dataChannels)

if startFromCheckpoint:
    # load weights from checkpoint
    # loaded = torch.load("models/models_tra/128_acdm-r20_02/Model.pth", map_location=torch.device('cpu'))
    # model.load_state_dict(loaded["stateDictDecoder"])
    loaded = torch.load("models/NEW.zip", map_location=torch.device('cpu'))
    model.load_state_dict(loaded)
    
model.train()
model.to(device)

# print model info and trainable weigths
paramsTrainable = sum([np.prod(p.size()) for p in filter(lambda p: p.requires_grad, model.parameters())])
params = sum([np.prod(p.size()) for p in model.parameters()])
#print(model)
print("Trainable Weights (All Weights): %d (%d)" % (paramsTrainable, params))

# training loop
print("\nStarting training...")
optimizer = torch.optim.Adam(model.parameters(), lr=lr)
for epoch in range(epochs):
    losses = []
    for s, sample in enumerate(trainLoader, 0):
        optimizer.zero_grad()

        d = sample["data"].to(device)

        inputSteps = 2
        cond = []
        for i in range(inputSteps):
            cond += [d[:,i:i+1]] # collect input steps
        conditioning = torch.concat(cond, dim=2) # combine along channel dimension
        data = d[:, inputSteps:inputSteps+1]

        noise, predictedNoise = model(conditioning=conditioning, data=data)

        loss = F.smooth_l1_loss(noise, predictedNoise)
        print("    [Epoch %2d, Batch %4d]: %1.7f" % (epoch, s, loss.detach().cpu().item()))
        loss.backward()

        losses += [loss.detach().cpu().item()]

        optimizer.step()
    print("[Epoch %2d, FULL]: %1.7f" % (epoch, sum(losses)/len(losses)))

print("Training complete!")
19/38:
device = "cuda" if torch.cuda.is_available() else "cpu"

numSamples = 5
sequenceLength = [60,2]
simFields = ["dens", "pres"]
simParams = ["mach"]
diffusionSteps = 20

try: # load model if not trained/finetuned above
    model
except NameError:
    condChannels = 2 * (2 + len(simFields) + len(simParams))
    dataChannels = 2 + len(simFields) + len(simParams)
    model = DiffusionModel(diffusionSteps, condChannels, dataChannels)

    # load weights from checkpoint
    loaded = torch.load("models/models_tra/128_acdm-r20_02/Model.pth", map_location=torch.device('cpu'))
    model.load_state_dict(loaded["stateDictDecoder"])
model.eval()
model.to(device)

testSet = TurbulenceDataset("Test", ["data"], filterTop=["128_small_tra"], filterSim=[[0]], excludefilterSim=False, filterFrame=[(0,250)],
                sequenceLength=[sequenceLength], randSeqOffset=False, simFields=simFields, simParams=simParams, printLevel="sim")
testSet.transform = DataTransforms(normalizeMode="traMixed", simFields=simFields, simParams=simParams)
testSet.printDatasetInfo()
testSampler = SequentialSampler(testSet)
testLoader = DataLoader(testSet, sampler=testSampler, batch_size=1, drop_last=False)

# sampling loop
print("\nStarting sampling...")
gt = []
pred = []
with torch.no_grad():
    for s, sample in enumerate(testLoader, 0):
        gt += [sample["data"].unsqueeze(0).cpu().numpy()]
        d = sample["data"].to(device).repeat(numSamples,1,1,1,1) # reuse batch dim for samples

        prediction = torch.zeros_like(d, device=device)
        inputSteps = 2

        for i in range(inputSteps): # no prediction of first steps
            prediction[:,i] = d[:,i]

        for i in range(inputSteps, d.shape[1]):
            cond = []
            for j in range(inputSteps,0,-1):
                cond += [prediction[:, i-j : i-(j-1)]] # collect input steps
            cond = torch.concat(cond, dim=2) # combine along channel dimension

            result = model(conditioning=cond, data=d[:,i-1:i]) # auto-regressive inference
            result[:,:,-len(simParams):] = d[:,i:i+1,-len(simParams):] # replace simparam prediction with true values
            prediction[:,i:i+1] = result

        prediction = torch.reshape(prediction, (numSamples, -1, d.shape[1], d.shape[2], d.shape[3], d.shape[4]))
        pred += [prediction.cpu().numpy()]
        print("  Sequence %d finished" % s)


print("Sampling complete!\n")

gt = np.concatenate(gt, axis=1)
pred = np.concatenate(pred, axis=1)

# undo data normalization
normMean = testSet.transform.normMean[[0,1,2,3,5]]
normStd = testSet.transform.normStd[[0,1,2,3,5]]
normMean = np.expand_dims(normMean, axis=(0,1,2,4,5))
normStd = np.expand_dims(normStd, axis=(0,1,2,4,5))
gt = (gt * normStd) + normMean
pred = (pred * normStd) + normMean

print("Ground truth and prediction tensor with shape:")
print("(samples, sequences, sequenceLength, channels, sizeX, sizeY)")
print("GT: %s" % str(gt.shape))
print("Prediction: %s" % str(pred.shape))
19/39:
sequence = 0
samples = [0,4]
timeSteps = [0,19,39,59]
field = 3 # velocity_x (0), velocity_y (1), density (2), or pressure (3)

predPart = pred[samples]
gtPred = np.concatenate([gt[:,sequence,timeSteps,field], predPart[:,sequence,timeSteps,field]])

fig, axs = plt.subplots(nrows=gtPred.shape[0], ncols=gtPred.shape[1], figsize=(gtPred.shape[1]*1.9, gtPred.shape[0]), dpi=150, squeeze=False)

for i in range(gtPred.shape[0]):
    for j in range(gtPred.shape[1]):
        if i == gtPred.shape[0]-1:
            axs[i,j].set_xlabel("$t=%s$" % (timeSteps[j]+1), fontsize=10)
        if j == 0:
            if i == 0:
              axs[i,j].set_ylabel("Ground\nTruth", fontsize=10)
            else:
              axs[i,j].set_ylabel("ACDM\nSample %d" % i, fontsize=10)
        axs[i,j].set_xticks([])
        axs[i,j].set_yticks([])
        im = axs[i,j].imshow(gtPred[i][j].transpose(), interpolation="catrom", cmap="viridis")

plt.show()
19/40:
gtTemp = gt[:,:,:,0:4] # ignore scalar Mach number here
predTemp = pred[:,:,:,0:4]

diffGt = np.abs( gtTemp[:,:,1:gtTemp.shape[2]-1] - gtTemp[:,:,2:gtTemp.shape[2]])
diffGt = np.mean(diffGt, axis=(3,4,5)) # channel-wise and spatial mean
minGt = np.min(diffGt, axis=(0,1)) # lower bound over sequences
maxGt = np.max(diffGt, axis=(0,1)) # upper bound over sequences
meanGt = np.mean(diffGt, axis=(0,1)) # sample- and sequence mean

diffPred = np.abs( predTemp[:,:,1:predTemp.shape[2]-1] - predTemp[:,:,2:predTemp.shape[2]])
diffPred = np.mean(diffPred, axis=(3,4,5)) # channel-wise and spatial mean
minPred = np.min(diffPred, axis=(0,1)) # lower bound over samples and sequences
maxPred = np.max(diffPred, axis=(0,1)) # upper bound over samples and sequences
meanPred = np.mean(diffPred, axis=(0,1)) # sample- and sequence mean


fig, ax = plt.subplots(1, figsize=(5,2), dpi=150)
ax.set_title("Temporal Stability")
ax.set_ylabel("$\Vert \, (s^{t} - s^{t-1}) / \Delta t \, \Vert_1$")
ax.yaxis.grid(True)
ax.set_xlabel("Time step $t$")

ax.plot(np.arange(meanGt.shape[0]), meanGt, color="k", label="Simulation", linestyle="dashed")
ax.fill_between(np.arange(meanGt.shape[0]), minGt, maxGt, facecolor="k", alpha=0.15)

ax.plot(np.arange(meanPred.shape[0]), meanPred, color="tab:orange", label="ACDM")
ax.fill_between(np.arange(meanPred.shape[0]), minPred, maxPred, facecolor="tab:orange", alpha=0.15)

fig.legend()
plt.show()
19/41:
sequence = 0
fracX = 0.25 # closely behing the cylinder
fracY = 0.5 # vertically centered
field = 1 # velocity_x (0), velocity_y (1), density (2), or pressure (3)

posX = int(fracX * gt.shape[4])
posY = int(fracY * gt.shape[5])

gtPred = np.concatenate([gt[:,sequence,:,field, posX, posY], pred[:,sequence,:,field, posX, posY]])

fft = np.fft.fft(gtPred, axis=1)
fft = np.real(fft * np.conj(fft))
n = fft.shape[1]
gridSpacing = 0.002 # delta t between frames from simulation
freq = np.fft.fftfreq(n, d=gridSpacing)[1:int(n/2)]
fft = fft[:,1:int(n/2)] # only use positive fourier frequencies

gtFFT = fft[0]
minPredFFT = np.min(fft[1:], axis=0) # lower bound over samples
maxPredFFT = np.max(fft[1:], axis=0) # upper bound over samples
meanPredFFT = np.mean(fft[1:], axis=0) # sample mean


# plot eval point
fig, ax = plt.subplots(1, figsize=(5,2), dpi=150)
ax.set_title("Evaluation Point")
ax.imshow(gt[0,sequence,0,field].transpose(), interpolation="catrom", cmap="viridis")
ax.scatter(posX, posY, s=200, color="red", marker="x", linewidth=2)
ax.set_xticks([])
ax.set_yticks([])
plt.show()


# plot spectral analysis
fig, ax = plt.subplots(1, figsize=(5,2), dpi=150)
ax.set_title("Spectral Analysis")
ax.set_xlabel("Temporal frequency $f$ (at point downstream)")
ax.set_ylabel("Amplitude $*f^2$")
ax.set_xscale("log", base=2)
ax.set_yscale("log", base=10)
ax.yaxis.grid(True)

ax.plot(freq, gtFFT * (freq**2), color="k", label="Simulation", linestyle="dashed")

ax.plot(freq, meanPredFFT * (freq**2), color="tab:orange", label="ACDM")
ax.fill_between(freq, minPredFFT * (freq**2), maxPredFFT * (freq**2), facecolor="tab:orange", alpha=0.15)

fig.legend()
plt.show()
18/18:
from phi.torch.flow import *
from tqdm.notebook import trange
import torch
import matplotlib.pyplot as plt
18/19: import warp
18/20:
# fluid specification & initialization
RES = 128
BOUND = 100
NUM_TIME_STEPS = 200
DT = 0.5
domain = Box(x=BOUND, y=BOUND)
INFLOW_RATE = 0.5
BUOYANCY = 0.1
inflow = Sphere(x=50, y=9.5, radius=8)

v0 = StaggeredGrid(0, 0, domain, x=RES, y=RES)
smoke0 = CenteredGrid(0, math.extrapolation.BOUNDARY, domain, x=RES, y=RES)
18/21:
# noise specification & initialization
batch_size = 2
num_channel = 2
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
up_level = 2 # noise upsampling level
res_up = RES * (2 ** up_level)
18/22:
# conditional noise upsampling & visualization
x = math.random_normal(batch(b=batch_size),math.channel(vec=num_channel),spatial(x=RES, y=RES))
x_up = warp.upsample_noise_cond(x, up_level)
vis.plot({'noise':x.b[0].vec[0],'conditional upsampled noise':x_up.b[0].vec[0]})
18/23:
# fluid step function with smoke inflow
@jit_compile
def step(v, s, p, dt):
    s = advect.mac_cormack(s, v, dt) + INFLOW_RATE * resample(inflow, to=s, soft=True)
    buoyancy = resample(s * (0, BUOYANCY), to=v)
    v = advect.semi_lagrangian(v, v, dt) + buoyancy * dt
    v, p = fluid.make_incompressible(v, (), Solve('CG', 1e-3, x0=p))
    return v, s, p
18/24: v_trj, s_trj, p_trj = iterate(step, batch(time=NUM_TIME_STEPS), v0, smoke0, None, dt=DT, range=trange, substeps=3)
18/25:
# resampling the grid to a finer grid for noise transport
part_level = 2 # partition level for triangulation
tris_per_pix_dim = 2 ** (part_level-1) # triangles per pixel per dimension
tris_per_dim = tris_per_pix_dim * RES # triangles per dimension
vtx_per_dim = tris_per_pix_dim * RES + 1 # vertices per dimention
domain1=Box(x=(-BOUND/RES/tris_per_pix_dim/2, BOUND+BOUND/RES/tris_per_pix_dim/2),y=(-BOUND/RES/tris_per_pix_dim/2,BOUND+BOUND/RES/tris_per_pix_dim/2))
grid1 = CenteredGrid(0, math.extrapolation.BOUNDARY, domain1, x=vtx_per_dim, y=vtx_per_dim)
v_trj_rs = field.resample(value=v_trj, to=grid1)

vis.plot({'velocity': v_trj.time[-1], 'velocity resampled': v_trj_rs.time[-1]})
18/26:
# vertices & triangles (represented by vertex indices) generation
_, vertices = warp.vertices_gen(RES, RES, part_level)
reshaped_mesh_idxs = warp.mesh_idx_gen(RES, RES, part_level)
18/27: x
18/28: x.native(['b','vec','y','x'])
18/29: x.native(['b','vec','y','x']).shape
18/30:
from phi.torch.flow import *
from tqdm.notebook import trange
import torch
import matplotlib.pyplot as plt
18/31: import warp
18/32:
# fluid specification & initialization
RES = 128
BOUND = 100
NUM_TIME_STEPS = 200
DT = 0.5
domain = Box(x=BOUND, y=BOUND)
INFLOW_RATE = 0.5
BUOYANCY = 0.1
inflow = Sphere(x=50, y=9.5, radius=8)

v0 = StaggeredGrid(0, 0, domain, x=RES, y=RES)
smoke0 = CenteredGrid(0, math.extrapolation.BOUNDARY, domain, x=RES, y=RES)
18/33:
# noise specification & initialization
batch_size = 2
num_channel = 2
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
up_level = 2 # noise upsampling level
res_up = RES * (2 ** up_level)
18/34:
# conditional noise upsampling & visualization
x = math.random_normal(batch(b=batch_size),math.channel(vec=num_channel),spatial(x=RES, y=RES))
x_up = warp.upsample_noise_cond(x, up_level)
vis.plot({'noise':x.b[0].vec[0],'conditional upsampled noise':x_up.b[0].vec[0]})
18/35:
# fluid step function with smoke inflow
@jit_compile
def step(v, s, p, dt):
    s = advect.mac_cormack(s, v, dt) + INFLOW_RATE * resample(inflow, to=s, soft=True)
    buoyancy = resample(s * (0, BUOYANCY), to=v)
    v = advect.semi_lagrangian(v, v, dt) + buoyancy * dt
    v, p = fluid.make_incompressible(v, (), Solve('CG', 1e-3, x0=p))
    return v, s, p
18/36: v_trj, s_trj, p_trj = iterate(step, batch(time=NUM_TIME_STEPS), v0, smoke0, None, dt=DT, range=trange, substeps=3)
18/37:
# resampling the grid to a finer grid for noise transport
part_level = 2 # partition level for triangulation
tris_per_pix_dim = 2 ** (part_level-1) # triangles per pixel per dimension
tris_per_dim = tris_per_pix_dim * RES # triangles per dimension
vtx_per_dim = tris_per_pix_dim * RES + 1 # vertices per dimention
domain1=Box(x=(-BOUND/RES/tris_per_pix_dim/2, BOUND+BOUND/RES/tris_per_pix_dim/2),y=(-BOUND/RES/tris_per_pix_dim/2,BOUND+BOUND/RES/tris_per_pix_dim/2))
grid1 = CenteredGrid(0, math.extrapolation.BOUNDARY, domain1, x=vtx_per_dim, y=vtx_per_dim)
v_trj_rs = field.resample(value=v_trj, to=grid1)

vis.plot({'velocity': v_trj.time[-1], 'velocity resampled': v_trj_rs.time[-1]})
18/38:
# vertices & triangles (represented by vertex indices) generation
_, vertices = warp.vertices_gen(RES, RES, part_level)
reshaped_mesh_idxs = warp.mesh_idx_gen(RES, RES, part_level)
18/39: x.native(['b','vec','y','x']).shape
18/40:
# complete noise warping step function
def noise_step(vtx_pos, noise, up_level,mesh_idxs,vertices):
    res, _ = math.spatial(noise).sizes

    part_level = up_level
    resolution = res * (2 ** up_level)
    tris_per_row = 2 ** (part_level-1)

    noise_up = warp.upsample_noise_cond(noise, up_level)

    idx_y = mesh_idxs[:,0].int()
    idx_x = mesh_idxs[:,1].int()
    warped_coords = vtx_pos.native(['x','y','vector'])[idx_y, idx_x].fliplr()
    rast_out = warp.rasterize(warped_coords, vertices, res * tris_per_row, resolution, device)

    noise_warped = warp.transport_noise(noise_up, res, rast_out, part_level)

    return noise_warped

def noise_step_torch(vtx_pos, noise, up_level,mesh_idxs,vertices):
    batch_size, num_channel, res, _ = noise.shape

    part_level = up_level
    resolution = res * (2 ** up_level)
    tris_per_row = 2 ** (part_level-1)

    noise_up = warp.upsample_noise_cond(noise, up_level)

    idx_y = mesh_idxs[:,0].int()
    idx_x = mesh_idxs[:,1].int()
    warped_coords = vtx_pos.native(['x','y','vector'])[idx_y, idx_x].fliplr()
    rast_out = warp.rasterize(warped_coords, vertices, res * tris_per_row, resolution, device)

    noise_warped = warp.transport_noise_torch(noise_up, res, rast_out, part_level)

    return noise_warped
18/41:
# normalize the grid and corresponding vertex velocities for warping
grid_nmlzd = grid1.center * tris_per_dim / BOUND
v_trj_nmlzd = v_trj_rs * tris_per_dim / BOUND
18/42:
def calc_grid_pos(grid, vel, dt):
    grid_warp = grid - vel.values*dt
    return grid_warp

def gen_grids_warped(grid, vels, dt):
    # maps = []
    maps = [grid]
    for i in range(vels.time.size-1):
        grid_warp = calc_grid_pos(grid,vels.time[i+1],dt)
        maps.append(grid_warp)
    maps = math.stack(maps, batch('time'))
    return maps
18/43:
# generate the warped grid positions
grids_warped = gen_grids_warped(grid_nmlzd,v_trj_nmlzd,.5)
18/44:
# noise warping by the proposed method, no disclusion fix
noise_trj = [x]
x_in = x
for i in range(NUM_TIME_STEPS):
    # x_warped = noise_step(grids_warped.time[i+1], x_in, up_level, reshaped_mesh_idxs, vertices)

    x_warped = noise_step_torch(grids_warped.time[i+1], x_in, up_level, reshaped_mesh_idxs, vertices)
    x_warped = math.tensor(x_warped, batch(b=batch_size),math.channel(vec=num_channel),spatial(x=RES, y=RES))
    noise_trj.append(x_warped)
    x_in = x_warped
noise_trj = math.stack(noise_trj, batch('time'))
18/45:
# noise warping by the proposed method, no disclusion fix
noise_trj = [x]
x_in = x
for i in range(NUM_TIME_STEPS):
    # x_warped = noise_step(grids_warped.time[i+1], x_in, up_level, reshaped_mesh_idxs, vertices)

    x_warped = noise_step_torch(grids_warped.time[i+1], x_in, up_level, reshaped_mesh_idxs, vertices)
    x_warped = math.tensor(x_warped, batch(b=batch_size),math.channel(vec=num_channel),spatial(x=RES, y=RES))
    noise_trj.append(x_warped)
    x_in = x_warped
noise_trj = math.stack(noise_trj, batch('time'))
18/46:
# noise warping by the proposed method, no disclusion fix
noise_trj = [x]
x_in = x
for i in range(NUM_TIME_STEPS):
    # x_warped = noise_step(grids_warped.time[i+1], x_in, up_level, reshaped_mesh_idxs, vertices)

    x_warped = noise_step_torch(grids_warped.time[i+1], x_in, up_level, reshaped_mesh_idxs, vertices)
    x_warped = math.tensor(x_warped, batch(b=batch_size),math.channel(vec=num_channel),spatial(x=RES, y=RES))
    noise_trj.append(x_warped)
    x_in = x_warped
noise_trj = math.stack(noise_trj, batch('time'))
20/1:
from phi.torch.flow import *
from tqdm.notebook import trange
import torch
import matplotlib.pyplot as plt
20/2: import warp
20/3:
# fluid specification & initialization
RES = 128
BOUND = 100
NUM_TIME_STEPS = 200
DT = 0.5
domain = Box(x=BOUND, y=BOUND)
INFLOW_RATE = 0.5
BUOYANCY = 0.1
inflow = Sphere(x=50, y=9.5, radius=8)

v0 = StaggeredGrid(0, 0, domain, x=RES, y=RES)
smoke0 = CenteredGrid(0, math.extrapolation.BOUNDARY, domain, x=RES, y=RES)
22/1:
from phi.torch.flow import *
from tqdm.notebook import trange
import torch
import matplotlib.pyplot as plt
22/2: import warp
22/3:
# fluid specification & initialization
RES = 32
BOUND = 100
NUM_TIME_STEPS = 50
DT = 0.5
domain = Box(x=BOUND, y=BOUND)
INFLOW_RATE = 0.5
BUOYANCY = 0.1
inflow = Sphere(x=50, y=9.5, radius=8)

v0 = StaggeredGrid(0, 0, domain, x=RES, y=RES)
smoke0 = CenteredGrid(0, math.extrapolation.BOUNDARY, domain, x=RES, y=RES)
22/4:
# noise specification & initialization
batch_size = 2
num_channel = 2
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
up_level = 2 # noise upsampling level
res_up = RES * (2 ** up_level)
22/5:
# conditional noise upsampling & visualization
x = math.random_normal(batch(b=batch_size),math.channel(vec=num_channel),spatial(x=RES, y=RES))
x_up = warp.upsample_noise_cond(x, up_level)
vis.plot({'noise':x.b[0].vec[0],'conditional upsampled noise':x_up.b[0].vec[0]})
22/6:
# fluid step function with smoke inflow
@jit_compile
def step(v, s, p, dt):
    s = advect.mac_cormack(s, v, dt) + INFLOW_RATE * resample(inflow, to=s, soft=True)
    buoyancy = resample(s * (0, BUOYANCY), to=v)
    v = advect.semi_lagrangian(v, v, dt) + buoyancy * dt
    v, p = fluid.make_incompressible(v, (), Solve('CG', 1e-3, x0=p))
    return v, s, p
22/7: v_trj, s_trj, p_trj = iterate(step, batch(time=NUM_TIME_STEPS), v0, smoke0, None, dt=DT, range=trange, substeps=3)
22/8:
# resampling the grid to a finer grid for noise transport
part_level = 2 # partition level for triangulation
tris_per_pix_dim = 2 ** (part_level-1) # triangles per pixel per dimension
tris_per_dim = tris_per_pix_dim * RES # triangles per dimension
vtx_per_dim = tris_per_pix_dim * RES + 1 # vertices per dimention
domain1=Box(x=(-BOUND/RES/tris_per_pix_dim/2, BOUND+BOUND/RES/tris_per_pix_dim/2),y=(-BOUND/RES/tris_per_pix_dim/2,BOUND+BOUND/RES/tris_per_pix_dim/2))
grid1 = CenteredGrid(0, math.extrapolation.BOUNDARY, domain1, x=vtx_per_dim, y=vtx_per_dim)
v_trj_rs = field.resample(value=v_trj, to=grid1)

vis.plot({'velocity': v_trj.time[-1], 'velocity resampled': v_trj_rs.time[-1]})
22/9:
# vertices & triangles (represented by vertex indices) generation
_, vertices = warp.vertices_gen(RES, RES, part_level)
reshaped_mesh_idxs = warp.mesh_idx_gen(RES, RES, part_level)
22/10: x.native(['b','vec','y','x']).shape
22/11:
# complete noise warping step function
def noise_step(vtx_pos, noise, up_level,mesh_idxs,vertices):
    res, _ = math.spatial(noise).sizes

    part_level = up_level
    resolution = res * (2 ** up_level)
    tris_per_row = 2 ** (part_level-1)

    noise_up = warp.upsample_noise_cond(noise, up_level)

    idx_y = mesh_idxs[:,0].int()
    idx_x = mesh_idxs[:,1].int()
    warped_coords = vtx_pos.native(['x','y','vector'])[idx_y, idx_x].fliplr()
    rast_out = warp.rasterize(warped_coords, vertices, res * tris_per_row, resolution, device)

    noise_warped = warp.transport_noise(noise_up, res, rast_out, part_level)

    return noise_warped

def noise_step_torch(vtx_pos, noise, up_level,mesh_idxs,vertices):
    batch_size, num_channel, res, _ = noise.shape

    part_level = up_level
    resolution = res * (2 ** up_level)
    tris_per_row = 2 ** (part_level-1)

    noise_up = warp.upsample_noise_cond(noise, up_level)

    idx_y = mesh_idxs[:,0].int()
    idx_x = mesh_idxs[:,1].int()
    warped_coords = vtx_pos.native(['x','y','vector'])[idx_y, idx_x].fliplr()
    rast_out = warp.rasterize(warped_coords, vertices, res * tris_per_row, resolution, device)

    noise_warped = warp.transport_noise_torch(noise_up, res, rast_out, part_level)

    return noise_warped
22/12:
# normalize the grid and corresponding vertex velocities for warping
grid_nmlzd = grid1.center * tris_per_dim / BOUND
v_trj_nmlzd = v_trj_rs * tris_per_dim / BOUND
22/13:
def calc_grid_pos(grid, vel, dt):
    grid_warp = grid - vel.values*dt
    return grid_warp

def gen_grids_warped(grid, vels, dt):
    # maps = []
    maps = [grid]
    for i in range(vels.time.size-1):
        grid_warp = calc_grid_pos(grid,vels.time[i+1],dt)
        maps.append(grid_warp)
    maps = math.stack(maps, batch('time'))
    return maps
22/14:
# generate the warped grid positions
grids_warped = gen_grids_warped(grid_nmlzd,v_trj_nmlzd,.5)
22/15:
from phi.torch.flow import *
from tqdm.notebook import trange
import torch
import matplotlib.pyplot as plt
22/16: import warp
22/17:
# fluid specification & initialization
RES = 32
BOUND = 100
NUM_TIME_STEPS = 50
DT = 0.5
domain = Box(x=BOUND, y=BOUND)
INFLOW_RATE = 0.5
BUOYANCY = 0.1
inflow = Sphere(x=50, y=9.5, radius=8)

v0 = StaggeredGrid(0, 0, domain, x=RES, y=RES)
smoke0 = CenteredGrid(0, math.extrapolation.BOUNDARY, domain, x=RES, y=RES)
22/18:
# noise specification & initialization
batch_size = 2
num_channel = 2
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
up_level = 2 # noise upsampling level
res_up = RES * (2 ** up_level)
22/19:
# conditional noise upsampling & visualization
x = math.random_normal(batch(b=batch_size),math.channel(vec=num_channel),spatial(x=RES, y=RES))
x_up = warp.upsample_noise_cond(x, up_level)
vis.plot({'noise':x.b[0].vec[0],'conditional upsampled noise':x_up.b[0].vec[0]})
22/20:
# fluid step function with smoke inflow
@jit_compile
def step(v, s, p, dt):
    s = advect.mac_cormack(s, v, dt) + INFLOW_RATE * resample(inflow, to=s, soft=True)
    buoyancy = resample(s * (0, BUOYANCY), to=v)
    v = advect.semi_lagrangian(v, v, dt) + buoyancy * dt
    v, p = fluid.make_incompressible(v, (), Solve('CG', 1e-3, x0=p))
    return v, s, p
22/21: v_trj, s_trj, p_trj = iterate(step, batch(time=NUM_TIME_STEPS), v0, smoke0, None, dt=DT, range=trange, substeps=3)
22/22:
# resampling the grid to a finer grid for noise transport
part_level = 2 # partition level for triangulation
tris_per_pix_dim = 2 ** (part_level-1) # triangles per pixel per dimension
tris_per_dim = tris_per_pix_dim * RES # triangles per dimension
vtx_per_dim = tris_per_pix_dim * RES + 1 # vertices per dimention
domain1=Box(x=(-BOUND/RES/tris_per_pix_dim/2, BOUND+BOUND/RES/tris_per_pix_dim/2),y=(-BOUND/RES/tris_per_pix_dim/2,BOUND+BOUND/RES/tris_per_pix_dim/2))
grid1 = CenteredGrid(0, math.extrapolation.BOUNDARY, domain1, x=vtx_per_dim, y=vtx_per_dim)
v_trj_rs = field.resample(value=v_trj, to=grid1)

vis.plot({'velocity': v_trj.time[-1], 'velocity resampled': v_trj_rs.time[-1]})
22/23:
# vertices & triangles (represented by vertex indices) generation
_, vertices = warp.vertices_gen(RES, RES, part_level)
reshaped_mesh_idxs = warp.mesh_idx_gen(RES, RES, part_level)
22/24: x.native(['b','vec','y','x']).shape
22/25:
# complete noise warping step function
def noise_step(vtx_pos, noise, up_level,mesh_idxs,vertices):
    res, _ = math.spatial(noise).sizes

    part_level = up_level
    resolution = res * (2 ** up_level)
    tris_per_row = 2 ** (part_level-1)

    noise_up = warp.upsample_noise_cond(noise, up_level)

    idx_y = mesh_idxs[:,0].int()
    idx_x = mesh_idxs[:,1].int()
    warped_coords = vtx_pos.native(['x','y','vector'])[idx_y, idx_x].fliplr()
    rast_out = warp.rasterize(warped_coords, vertices, res * tris_per_row, resolution, device)

    noise_warped = warp.transport_noise(noise_up, res, rast_out, part_level)

    return noise_warped

def noise_step_torch(vtx_pos, noise, up_level,mesh_idxs,vertices):
    batch_size, num_channel, res, _ = noise.shape

    part_level = up_level
    resolution = res * (2 ** up_level)
    tris_per_row = 2 ** (part_level-1)

    noise_up = warp.upsample_noise_cond(noise, up_level)

    idx_y = mesh_idxs[:,0].int()
    idx_x = mesh_idxs[:,1].int()
    warped_coords = vtx_pos.native(['x','y','vector'])[idx_y, idx_x].fliplr()
    rast_out = warp.rasterize(warped_coords, vertices, res * tris_per_row, resolution, device)

    noise_warped = warp.transport_noise_torch(noise_up, res, rast_out, part_level)

    return noise_warped
22/26:
# normalize the grid and corresponding vertex velocities for warping
grid_nmlzd = grid1.center * tris_per_dim / BOUND
v_trj_nmlzd = v_trj_rs * tris_per_dim / BOUND
22/27:
def calc_grid_pos(grid, vel, dt):
    grid_warp = grid - vel.values*dt
    return grid_warp

def gen_grids_warped(grid, vels, dt):
    # maps = []
    maps = [grid]
    for i in range(vels.time.size-1):
        grid_warp = calc_grid_pos(grid,vels.time[i+1],dt)
        maps.append(grid_warp)
    maps = math.stack(maps, batch('time'))
    return maps
22/28:
# generate the warped grid positions
grids_warped = gen_grids_warped(grid_nmlzd,v_trj_nmlzd,.5)
22/29:
# noise warping by the proposed method, no disclusion fix
noise_trj = [x]
x_in = x
for i in range(NUM_TIME_STEPS):
    # x_warped = noise_step(grids_warped.time[i+1], x_in, up_level, reshaped_mesh_idxs, vertices)

    x_warped = noise_step_torch(grids_warped.time[i+1], x_in, up_level, reshaped_mesh_idxs, vertices)
    x_warped = math.tensor(x_warped, batch(b=batch_size),math.channel(vec=num_channel),spatial(x=RES, y=RES))
    noise_trj.append(x_warped)
    x_in = x_warped
noise_trj = math.stack(noise_trj, batch('time'))
23/1:
# noise warping by the proposed method, no disclusion fix
noise_trj = [x]
x_in = x
for i in range(NUM_TIME_STEPS):
    # x_warped = noise_step(grids_warped.time[i+1], x_in, up_level, reshaped_mesh_idxs, vertices)

    x_warped = noise_step_torch(grids_warped.time[i+1], x_in, up_level, reshaped_mesh_idxs, vertices)
    x_warped = math.tensor(x_warped, batch(b=batch_size),math.channel(vec=num_channel),spatial(x=RES, y=RES))
    noise_trj.append(x_warped)
    x_in = x_warped
noise_trj = math.stack(noise_trj, batch('time'))
23/2:
from phi.torch.flow import *
from tqdm.notebook import trange
import torch
import matplotlib.pyplot as plt
23/3: import warp
23/4:
# fluid specification & initialization
RES = 32
BOUND = 100
NUM_TIME_STEPS = 50
DT = 0.5
domain = Box(x=BOUND, y=BOUND)
INFLOW_RATE = 0.5
BUOYANCY = 0.1
inflow = Sphere(x=50, y=9.5, radius=8)

v0 = StaggeredGrid(0, 0, domain, x=RES, y=RES)
smoke0 = CenteredGrid(0, math.extrapolation.BOUNDARY, domain, x=RES, y=RES)
23/5:
# noise specification & initialization
batch_size = 2
num_channel = 2
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
up_level = 2 # noise upsampling level
res_up = RES * (2 ** up_level)
23/6:
# conditional noise upsampling & visualization
x = math.random_normal(batch(b=batch_size),math.channel(vec=num_channel),spatial(x=RES, y=RES))
x_up = warp.upsample_noise_cond(x, up_level)
vis.plot({'noise':x.b[0].vec[0],'conditional upsampled noise':x_up.b[0].vec[0]})
23/7:
# fluid step function with smoke inflow
@jit_compile
def step(v, s, p, dt):
    s = advect.mac_cormack(s, v, dt) + INFLOW_RATE * resample(inflow, to=s, soft=True)
    buoyancy = resample(s * (0, BUOYANCY), to=v)
    v = advect.semi_lagrangian(v, v, dt) + buoyancy * dt
    v, p = fluid.make_incompressible(v, (), Solve('CG', 1e-3, x0=p))
    return v, s, p
23/8: v_trj, s_trj, p_trj = iterate(step, batch(time=NUM_TIME_STEPS), v0, smoke0, None, dt=DT, range=trange, substeps=3)
23/9:
# resampling the grid to a finer grid for noise transport
part_level = 2 # partition level for triangulation
tris_per_pix_dim = 2 ** (part_level-1) # triangles per pixel per dimension
tris_per_dim = tris_per_pix_dim * RES # triangles per dimension
vtx_per_dim = tris_per_pix_dim * RES + 1 # vertices per dimention
domain1=Box(x=(-BOUND/RES/tris_per_pix_dim/2, BOUND+BOUND/RES/tris_per_pix_dim/2),y=(-BOUND/RES/tris_per_pix_dim/2,BOUND+BOUND/RES/tris_per_pix_dim/2))
grid1 = CenteredGrid(0, math.extrapolation.BOUNDARY, domain1, x=vtx_per_dim, y=vtx_per_dim)
v_trj_rs = field.resample(value=v_trj, to=grid1)

vis.plot({'velocity': v_trj.time[-1], 'velocity resampled': v_trj_rs.time[-1]})
23/10:
# vertices & triangles (represented by vertex indices) generation
_, vertices = warp.vertices_gen(RES, RES, part_level)
reshaped_mesh_idxs = warp.mesh_idx_gen(RES, RES, part_level)
23/11: x.native(['b','vec','y','x']).shape
23/12:
# complete noise warping step function
def noise_step(vtx_pos, noise, up_level,mesh_idxs,vertices):
    res, _ = math.spatial(noise).sizes

    part_level = up_level
    resolution = res * (2 ** up_level)
    tris_per_row = 2 ** (part_level-1)

    noise_up = warp.upsample_noise_cond(noise, up_level)

    idx_y = mesh_idxs[:,0].int()
    idx_x = mesh_idxs[:,1].int()
    warped_coords = vtx_pos.native(['x','y','vector'])[idx_y, idx_x].fliplr()
    rast_out = warp.rasterize(warped_coords, vertices, res * tris_per_row, resolution, device)

    noise_warped = warp.transport_noise(noise_up, res, rast_out, part_level)

    return noise_warped

def noise_step_torch(vtx_pos, noise, up_level,mesh_idxs,vertices):
    batch_size, num_channel, res, _ = noise.shape

    part_level = up_level
    resolution = res * (2 ** up_level)
    tris_per_row = 2 ** (part_level-1)

    noise_up = warp.upsample_noise_cond(noise, up_level)

    idx_y = mesh_idxs[:,0].int()
    idx_x = mesh_idxs[:,1].int()
    warped_coords = vtx_pos.native(['x','y','vector'])[idx_y, idx_x].fliplr()
    rast_out = warp.rasterize(warped_coords, vertices, res * tris_per_row, resolution, device)

    noise_warped = warp.transport_noise_torch(noise_up, res, rast_out, part_level)

    return noise_warped
23/13:
# normalize the grid and corresponding vertex velocities for warping
grid_nmlzd = grid1.center * tris_per_dim / BOUND
v_trj_nmlzd = v_trj_rs * tris_per_dim / BOUND
23/14:
def calc_grid_pos(grid, vel, dt):
    grid_warp = grid - vel.values*dt
    return grid_warp

def gen_grids_warped(grid, vels, dt):
    # maps = []
    maps = [grid]
    for i in range(vels.time.size-1):
        grid_warp = calc_grid_pos(grid,vels.time[i+1],dt)
        maps.append(grid_warp)
    maps = math.stack(maps, batch('time'))
    return maps
23/15:
# generate the warped grid positions
grids_warped = gen_grids_warped(grid_nmlzd,v_trj_nmlzd,.5)
23/16:
# noise warping by the proposed method, no disclusion fix
noise_trj = [x]
x_in = x
for i in range(NUM_TIME_STEPS):
    # x_warped = noise_step(grids_warped.time[i+1], x_in, up_level, reshaped_mesh_idxs, vertices)

    x_warped = noise_step_torch(grids_warped.time[i+1], x_in, up_level, reshaped_mesh_idxs, vertices)
    x_warped = math.tensor(x_warped, batch(b=batch_size),math.channel(vec=num_channel),spatial(x=RES, y=RES))
    noise_trj.append(x_warped)
    x_in = x_warped
noise_trj = math.stack(noise_trj, batch('time'))
24/1:
from phi.torch.flow import *
from tqdm.notebook import trange
import torch
import matplotlib.pyplot as plt
24/2: import warp
24/3:
# fluid specification & initialization
RES = 32
BOUND = 100
NUM_TIME_STEPS = 50
DT = 0.5
domain = Box(x=BOUND, y=BOUND)
INFLOW_RATE = 0.5
BUOYANCY = 0.1
inflow = Sphere(x=50, y=9.5, radius=8)

v0 = StaggeredGrid(0, 0, domain, x=RES, y=RES)
smoke0 = CenteredGrid(0, math.extrapolation.BOUNDARY, domain, x=RES, y=RES)
24/4:
# noise specification & initialization
batch_size = 2
num_channel = 2
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
up_level = 2 # noise upsampling level
res_up = RES * (2 ** up_level)
24/5:
# conditional noise upsampling & visualization
x = math.random_normal(batch(b=batch_size),math.channel(vec=num_channel),spatial(x=RES, y=RES))
x_up = warp.upsample_noise_cond(x, up_level)
vis.plot({'noise':x.b[0].vec[0],'conditional upsampled noise':x_up.b[0].vec[0]})
24/6:
# fluid step function with smoke inflow
@jit_compile
def step(v, s, p, dt):
    s = advect.mac_cormack(s, v, dt) + INFLOW_RATE * resample(inflow, to=s, soft=True)
    buoyancy = resample(s * (0, BUOYANCY), to=v)
    v = advect.semi_lagrangian(v, v, dt) + buoyancy * dt
    v, p = fluid.make_incompressible(v, (), Solve('CG', 1e-3, x0=p))
    return v, s, p
24/7: v_trj, s_trj, p_trj = iterate(step, batch(time=NUM_TIME_STEPS), v0, smoke0, None, dt=DT, range=trange, substeps=3)
24/8:
# resampling the grid to a finer grid for noise transport
part_level = 2 # partition level for triangulation
tris_per_pix_dim = 2 ** (part_level-1) # triangles per pixel per dimension
tris_per_dim = tris_per_pix_dim * RES # triangles per dimension
vtx_per_dim = tris_per_pix_dim * RES + 1 # vertices per dimention
domain1=Box(x=(-BOUND/RES/tris_per_pix_dim/2, BOUND+BOUND/RES/tris_per_pix_dim/2),y=(-BOUND/RES/tris_per_pix_dim/2,BOUND+BOUND/RES/tris_per_pix_dim/2))
grid1 = CenteredGrid(0, math.extrapolation.BOUNDARY, domain1, x=vtx_per_dim, y=vtx_per_dim)
v_trj_rs = field.resample(value=v_trj, to=grid1)

vis.plot({'velocity': v_trj.time[-1], 'velocity resampled': v_trj_rs.time[-1]})
24/9:
# vertices & triangles (represented by vertex indices) generation
_, vertices = warp.vertices_gen(RES, RES, part_level)
reshaped_mesh_idxs = warp.mesh_idx_gen(RES, RES, part_level)
24/10: x.native(['b','vec','y','x']).shape
24/11:
# complete noise warping step function
def noise_step(vtx_pos, noise, up_level,mesh_idxs,vertices):
    res, _ = math.spatial(noise).sizes

    part_level = up_level
    resolution = res * (2 ** up_level)
    tris_per_row = 2 ** (part_level-1)

    noise_up = warp.upsample_noise_cond(noise, up_level)

    idx_y = mesh_idxs[:,0].int()
    idx_x = mesh_idxs[:,1].int()
    warped_coords = vtx_pos.native(['x','y','vector'])[idx_y, idx_x].fliplr()
    rast_out = warp.rasterize(warped_coords, vertices, res * tris_per_row, resolution, device)

    noise_warped = warp.transport_noise(noise_up, res, rast_out, part_level)

    return noise_warped

def noise_step_torch(vtx_pos, noise, up_level,mesh_idxs,vertices):
    batch_size, num_channel, res, _ = noise.shape

    part_level = up_level
    resolution = res * (2 ** up_level)
    tris_per_row = 2 ** (part_level-1)

    noise_up = warp.upsample_noise_cond(noise, up_level)

    idx_y = mesh_idxs[:,0].int()
    idx_x = mesh_idxs[:,1].int()
    warped_coords = vtx_pos.native(['x','y','vector'])[idx_y, idx_x].fliplr()
    rast_out = warp.rasterize(warped_coords, vertices, res * tris_per_row, resolution, device)

    noise_warped = warp.transport_noise_torch(noise_up, res, rast_out, part_level)

    return noise_warped
24/12:
# normalize the grid and corresponding vertex velocities for warping
grid_nmlzd = grid1.center * tris_per_dim / BOUND
v_trj_nmlzd = v_trj_rs * tris_per_dim / BOUND
24/13:
def calc_grid_pos(grid, vel, dt):
    grid_warp = grid - vel.values*dt
    return grid_warp

def gen_grids_warped(grid, vels, dt):
    # maps = []
    maps = [grid]
    for i in range(vels.time.size-1):
        grid_warp = calc_grid_pos(grid,vels.time[i+1],dt)
        maps.append(grid_warp)
    maps = math.stack(maps, batch('time'))
    return maps
24/14:
# generate the warped grid positions
grids_warped = gen_grids_warped(grid_nmlzd,v_trj_nmlzd,.5)
24/15:
# noise warping by the proposed method, no disclusion fix
noise_trj = [x]
x_in = x
for i in range(NUM_TIME_STEPS):
    # x_warped = noise_step(grids_warped.time[i+1], x_in, up_level, reshaped_mesh_idxs, vertices)

    x_warped = noise_step_torch(grids_warped.time[i+1], x_in, up_level, reshaped_mesh_idxs, vertices)
    x_warped = math.tensor(x_warped, batch(b=batch_size),math.channel(vec=num_channel),spatial(x=RES, y=RES))
    noise_trj.append(x_warped)
    x_in = x_warped
noise_trj = math.stack(noise_trj, batch('time'))
24/16:
# noise warping by the proposed method, no disclusion fix
noise_trj = [x]
x_in = x
for i in range(NUM_TIME_STEPS):
    # x_warped = noise_step(grids_warped.time[i+1], x_in, up_level, reshaped_mesh_idxs, vertices)

    x_warped = noise_step_torch(grids_warped.time[i+1], x_in, up_level, reshaped_mesh_idxs, vertices)
    x_warped = math.tensor(x_warped, batch(b=batch_size),math.channel(vec=num_channel),spatial(x=RES, y=RES))
    noise_trj.append(x_warped)
    x_in = x_warped
noise_trj = math.stack(noise_trj, batch('time'))
25/1:
from phi.torch.flow import *
from tqdm.notebook import trange
import torch
import matplotlib.pyplot as plt
25/2: import warp
25/3:
# fluid specification & initialization
RES = 32
BOUND = 100
NUM_TIME_STEPS = 50
DT = 0.5
domain = Box(x=BOUND, y=BOUND)
INFLOW_RATE = 0.5
BUOYANCY = 0.1
inflow = Sphere(x=50, y=9.5, radius=8)

v0 = StaggeredGrid(0, 0, domain, x=RES, y=RES)
smoke0 = CenteredGrid(0, math.extrapolation.BOUNDARY, domain, x=RES, y=RES)
25/4:
# noise specification & initialization
batch_size = 2
num_channel = 2
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
up_level = 2 # noise upsampling level
res_up = RES * (2 ** up_level)
25/5:
# conditional noise upsampling & visualization
x = math.random_normal(batch(b=batch_size),math.channel(vec=num_channel),spatial(x=RES, y=RES))
x_up = warp.upsample_noise_cond(x, up_level)
vis.plot({'noise':x.b[0].vec[0],'conditional upsampled noise':x_up.b[0].vec[0]})
25/6:
# fluid step function with smoke inflow
@jit_compile
def step(v, s, p, dt):
    s = advect.mac_cormack(s, v, dt) + INFLOW_RATE * resample(inflow, to=s, soft=True)
    buoyancy = resample(s * (0, BUOYANCY), to=v)
    v = advect.semi_lagrangian(v, v, dt) + buoyancy * dt
    v, p = fluid.make_incompressible(v, (), Solve('CG', 1e-3, x0=p))
    return v, s, p
25/7: v_trj, s_trj, p_trj = iterate(step, batch(time=NUM_TIME_STEPS), v0, smoke0, None, dt=DT, range=trange, substeps=3)
25/8:
# resampling the grid to a finer grid for noise transport
part_level = 2 # partition level for triangulation
tris_per_pix_dim = 2 ** (part_level-1) # triangles per pixel per dimension
tris_per_dim = tris_per_pix_dim * RES # triangles per dimension
vtx_per_dim = tris_per_pix_dim * RES + 1 # vertices per dimention
domain1=Box(x=(-BOUND/RES/tris_per_pix_dim/2, BOUND+BOUND/RES/tris_per_pix_dim/2),y=(-BOUND/RES/tris_per_pix_dim/2,BOUND+BOUND/RES/tris_per_pix_dim/2))
grid1 = CenteredGrid(0, math.extrapolation.BOUNDARY, domain1, x=vtx_per_dim, y=vtx_per_dim)
v_trj_rs = field.resample(value=v_trj, to=grid1)

vis.plot({'velocity': v_trj.time[-1], 'velocity resampled': v_trj_rs.time[-1]})
25/9:
# vertices & triangles (represented by vertex indices) generation
_, vertices = warp.vertices_gen(RES, RES, part_level)
reshaped_mesh_idxs = warp.mesh_idx_gen(RES, RES, part_level)
25/10: x.native(['b','vec','y','x']).shape
25/11:
# complete noise warping step function
def noise_step(vtx_pos, noise, up_level,mesh_idxs,vertices):
    res, _ = math.spatial(noise).sizes

    part_level = up_level
    resolution = res * (2 ** up_level)
    tris_per_row = 2 ** (part_level-1)

    noise_up = warp.upsample_noise_cond(noise, up_level)

    idx_y = mesh_idxs[:,0].int()
    idx_x = mesh_idxs[:,1].int()
    warped_coords = vtx_pos.native(['x','y','vector'])[idx_y, idx_x].fliplr()
    rast_out = warp.rasterize(warped_coords, vertices, res * tris_per_row, resolution, device)

    noise_warped = warp.transport_noise(noise_up, res, rast_out, part_level)

    return noise_warped

def noise_step_torch(vtx_pos, noise, up_level,mesh_idxs,vertices):
    batch_size, num_channel, res, _ = noise.shape

    part_level = up_level
    resolution = res * (2 ** up_level)
    tris_per_row = 2 ** (part_level-1)

    noise_up = warp.upsample_noise_cond(noise, up_level)

    idx_y = mesh_idxs[:,0].int()
    idx_x = mesh_idxs[:,1].int()
    warped_coords = vtx_pos.native(['x','y','vector'])[idx_y, idx_x].fliplr()
    rast_out = warp.rasterize(warped_coords, vertices, res * tris_per_row, resolution, device)

    noise_warped = warp.transport_noise_torch(noise_up, res, rast_out, part_level)

    return noise_warped
25/12:
# normalize the grid and corresponding vertex velocities for warping
grid_nmlzd = grid1.center * tris_per_dim / BOUND
v_trj_nmlzd = v_trj_rs * tris_per_dim / BOUND
25/13:
def calc_grid_pos(grid, vel, dt):
    grid_warp = grid - vel.values*dt
    return grid_warp

def gen_grids_warped(grid, vels, dt):
    # maps = []
    maps = [grid]
    for i in range(vels.time.size-1):
        grid_warp = calc_grid_pos(grid,vels.time[i+1],dt)
        maps.append(grid_warp)
    maps = math.stack(maps, batch('time'))
    return maps
25/14:
# generate the warped grid positions
grids_warped = gen_grids_warped(grid_nmlzd,v_trj_nmlzd,.5)
25/15:
# noise warping by the proposed method, no disclusion fix
noise_trj = [x]
x_in = x
for i in range(NUM_TIME_STEPS):
    # x_warped = noise_step(grids_warped.time[i+1], x_in, up_level, reshaped_mesh_idxs, vertices)

    x_warped = noise_step_torch(grids_warped.time[i+1], x_in, up_level, reshaped_mesh_idxs, vertices)
    x_warped = math.tensor(x_warped, batch(b=batch_size),math.channel(vec=num_channel),spatial(x=RES, y=RES))
    noise_trj.append(x_warped)
    x_in = x_warped
noise_trj = math.stack(noise_trj, batch('time'))
25/16:
# noise warping by the proposed method, no disclusion fix
noise_trj = [x]
x_in = x
for i in range(NUM_TIME_STEPS):
    # x_warped = noise_step(grids_warped.time[i+1], x_in, up_level, reshaped_mesh_idxs, vertices)

    x_warped = noise_step_torch(grids_warped.time[i+1], x_in, up_level, reshaped_mesh_idxs, vertices)
    x_warped = math.tensor(x_warped, batch(b=batch_size),math.channel(vec=num_channel),spatial(x=RES, y=RES))
    noise_trj.append(x_warped)
    x_in = x_warped
noise_trj = math.stack(noise_trj, batch('time'))
26/1:
from phi.torch.flow import *
from tqdm.notebook import trange
import torch
import matplotlib.pyplot as plt
26/2: import warp
26/3:
# fluid specification & initialization
RES = 32
BOUND = 100
NUM_TIME_STEPS = 50
DT = 0.5
domain = Box(x=BOUND, y=BOUND)
INFLOW_RATE = 0.5
BUOYANCY = 0.1
inflow = Sphere(x=50, y=9.5, radius=8)

v0 = StaggeredGrid(0, 0, domain, x=RES, y=RES)
smoke0 = CenteredGrid(0, math.extrapolation.BOUNDARY, domain, x=RES, y=RES)
26/4:
# noise specification & initialization
batch_size = 2
num_channel = 2
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
up_level = 2 # noise upsampling level
res_up = RES * (2 ** up_level)
26/5:
# conditional noise upsampling & visualization
x = math.random_normal(batch(b=batch_size),math.channel(vec=num_channel),spatial(x=RES, y=RES))
x_up = warp.upsample_noise_cond(x, up_level)
vis.plot({'noise':x.b[0].vec[0],'conditional upsampled noise':x_up.b[0].vec[0]})
26/6:
# fluid step function with smoke inflow
@jit_compile
def step(v, s, p, dt):
    s = advect.mac_cormack(s, v, dt) + INFLOW_RATE * resample(inflow, to=s, soft=True)
    buoyancy = resample(s * (0, BUOYANCY), to=v)
    v = advect.semi_lagrangian(v, v, dt) + buoyancy * dt
    v, p = fluid.make_incompressible(v, (), Solve('CG', 1e-3, x0=p))
    return v, s, p
26/7: v_trj, s_trj, p_trj = iterate(step, batch(time=NUM_TIME_STEPS), v0, smoke0, None, dt=DT, range=trange, substeps=3)
26/8:
# resampling the grid to a finer grid for noise transport
part_level = 2 # partition level for triangulation
tris_per_pix_dim = 2 ** (part_level-1) # triangles per pixel per dimension
tris_per_dim = tris_per_pix_dim * RES # triangles per dimension
vtx_per_dim = tris_per_pix_dim * RES + 1 # vertices per dimention
domain1=Box(x=(-BOUND/RES/tris_per_pix_dim/2, BOUND+BOUND/RES/tris_per_pix_dim/2),y=(-BOUND/RES/tris_per_pix_dim/2,BOUND+BOUND/RES/tris_per_pix_dim/2))
grid1 = CenteredGrid(0, math.extrapolation.BOUNDARY, domain1, x=vtx_per_dim, y=vtx_per_dim)
v_trj_rs = field.resample(value=v_trj, to=grid1)

vis.plot({'velocity': v_trj.time[-1], 'velocity resampled': v_trj_rs.time[-1]})
26/9:
# vertices & triangles (represented by vertex indices) generation
_, vertices = warp.vertices_gen(RES, RES, part_level)
reshaped_mesh_idxs = warp.mesh_idx_gen(RES, RES, part_level)
26/10: x.native(['b','vec','y','x']).shape
26/11:
# complete noise warping step function
def noise_step(vtx_pos, noise, up_level,mesh_idxs,vertices):
    res, _ = math.spatial(noise).sizes

    part_level = up_level
    resolution = res * (2 ** up_level)
    tris_per_row = 2 ** (part_level-1)

    noise_up = warp.upsample_noise_cond(noise, up_level)

    idx_y = mesh_idxs[:,0].int()
    idx_x = mesh_idxs[:,1].int()
    warped_coords = vtx_pos.native(['x','y','vector'])[idx_y, idx_x].fliplr()
    rast_out = warp.rasterize(warped_coords, vertices, res * tris_per_row, resolution, device)

    noise_warped = warp.transport_noise(noise_up, res, rast_out, part_level)

    return noise_warped

def noise_step_torch(vtx_pos, noise, up_level,mesh_idxs,vertices):
    batch_size, num_channel, res, _ = noise.shape

    part_level = up_level
    resolution = res * (2 ** up_level)
    tris_per_row = 2 ** (part_level-1)

    noise_up = warp.upsample_noise_cond(noise, up_level)

    idx_y = mesh_idxs[:,0].int()
    idx_x = mesh_idxs[:,1].int()
    warped_coords = vtx_pos.native(['x','y','vector'])[idx_y, idx_x].fliplr()
    rast_out = warp.rasterize(warped_coords, vertices, res * tris_per_row, resolution, device)

    noise_warped = warp.transport_noise_torch(noise_up, res, rast_out, part_level)

    return noise_warped
26/12:
# normalize the grid and corresponding vertex velocities for warping
grid_nmlzd = grid1.center * tris_per_dim / BOUND
v_trj_nmlzd = v_trj_rs * tris_per_dim / BOUND
26/13:
def calc_grid_pos(grid, vel, dt):
    grid_warp = grid - vel.values*dt
    return grid_warp

def gen_grids_warped(grid, vels, dt):
    # maps = []
    maps = [grid]
    for i in range(vels.time.size-1):
        grid_warp = calc_grid_pos(grid,vels.time[i+1],dt)
        maps.append(grid_warp)
    maps = math.stack(maps, batch('time'))
    return maps
26/14:
# generate the warped grid positions
grids_warped = gen_grids_warped(grid_nmlzd,v_trj_nmlzd,.5)
26/15:
# noise warping by the proposed method, no disclusion fix
noise_trj = [x]
x_in = x
for i in range(NUM_TIME_STEPS):
    # x_warped = noise_step(grids_warped.time[i+1], x_in, up_level, reshaped_mesh_idxs, vertices)

    x_warped = noise_step_torch(grids_warped.time[i+1], x_in, up_level, reshaped_mesh_idxs, vertices)
    x_warped = math.tensor(x_warped, batch(b=batch_size),math.channel(vec=num_channel),spatial(x=RES, y=RES))
    noise_trj.append(x_warped)
    x_in = x_warped
noise_trj = math.stack(noise_trj, batch('time'))
26/16:
from phi.torch.flow import *
from tqdm.notebook import trange
import torch
import matplotlib.pyplot as plt
26/17: import warp
26/18:
# fluid specification & initialization
RES = 32
BOUND = 100
NUM_TIME_STEPS = 50
DT = 0.5
domain = Box(x=BOUND, y=BOUND)
INFLOW_RATE = 0.5
BUOYANCY = 0.1
inflow = Sphere(x=50, y=9.5, radius=8)

v0 = StaggeredGrid(0, 0, domain, x=RES, y=RES)
smoke0 = CenteredGrid(0, math.extrapolation.BOUNDARY, domain, x=RES, y=RES)
26/19:
# noise specification & initialization
batch_size = 2
num_channel = 2
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
up_level = 2 # noise upsampling level
res_up = RES * (2 ** up_level)
26/20:
# conditional noise upsampling & visualization
x = math.random_normal(batch(b=batch_size),math.channel(vec=num_channel),spatial(x=RES, y=RES))
x_up = warp.upsample_noise_cond(x, up_level)
vis.plot({'noise':x.b[0].vec[0],'conditional upsampled noise':x_up.b[0].vec[0]})
26/21:
# fluid step function with smoke inflow
@jit_compile
def step(v, s, p, dt):
    s = advect.mac_cormack(s, v, dt) + INFLOW_RATE * resample(inflow, to=s, soft=True)
    buoyancy = resample(s * (0, BUOYANCY), to=v)
    v = advect.semi_lagrangian(v, v, dt) + buoyancy * dt
    v, p = fluid.make_incompressible(v, (), Solve('CG', 1e-3, x0=p))
    return v, s, p
26/22: v_trj, s_trj, p_trj = iterate(step, batch(time=NUM_TIME_STEPS), v0, smoke0, None, dt=DT, range=trange, substeps=3)
26/23:
from phi.torch.flow import *
from tqdm.notebook import trange
import torch
import matplotlib.pyplot as plt
26/24: import warp
26/25:
# fluid specification & initialization
RES = 32
BOUND = 100
NUM_TIME_STEPS = 50
DT = 0.5
domain = Box(x=BOUND, y=BOUND)
INFLOW_RATE = 0.5
BUOYANCY = 0.1
inflow = Sphere(x=50, y=9.5, radius=8)

v0 = StaggeredGrid(0, 0, domain, x=RES, y=RES)
smoke0 = CenteredGrid(0, math.extrapolation.BOUNDARY, domain, x=RES, y=RES)
26/26:
# noise specification & initialization
batch_size = 2
num_channel = 2
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
up_level = 2 # noise upsampling level
res_up = RES * (2 ** up_level)
26/27:
# conditional noise upsampling & visualization
x = math.random_normal(batch(b=batch_size),math.channel(vec=num_channel),spatial(x=RES, y=RES))
x_up = warp.upsample_noise_cond(x, up_level)
vis.plot({'noise':x.b[0].vec[0],'conditional upsampled noise':x_up.b[0].vec[0]})
26/28:
# fluid step function with smoke inflow
@jit_compile
def step(v, s, p, dt):
    s = advect.mac_cormack(s, v, dt) + INFLOW_RATE * resample(inflow, to=s, soft=True)
    buoyancy = resample(s * (0, BUOYANCY), to=v)
    v = advect.semi_lagrangian(v, v, dt) + buoyancy * dt
    v, p = fluid.make_incompressible(v, (), Solve('CG', 1e-3, x0=p))
    return v, s, p
26/29: v_trj, s_trj, p_trj = iterate(step, batch(time=NUM_TIME_STEPS), v0, smoke0, None, dt=DT, range=trange, substeps=3)
26/30:
# resampling the grid to a finer grid for noise transport
part_level = 2 # partition level for triangulation
tris_per_pix_dim = 2 ** (part_level-1) # triangles per pixel per dimension
tris_per_dim = tris_per_pix_dim * RES # triangles per dimension
vtx_per_dim = tris_per_pix_dim * RES + 1 # vertices per dimention
domain1=Box(x=(-BOUND/RES/tris_per_pix_dim/2, BOUND+BOUND/RES/tris_per_pix_dim/2),y=(-BOUND/RES/tris_per_pix_dim/2,BOUND+BOUND/RES/tris_per_pix_dim/2))
grid1 = CenteredGrid(0, math.extrapolation.BOUNDARY, domain1, x=vtx_per_dim, y=vtx_per_dim)
v_trj_rs = field.resample(value=v_trj, to=grid1)

vis.plot({'velocity': v_trj.time[-1], 'velocity resampled': v_trj_rs.time[-1]})
26/31:
# vertices & triangles (represented by vertex indices) generation
_, vertices = warp.vertices_gen(RES, RES, part_level)
reshaped_mesh_idxs = warp.mesh_idx_gen(RES, RES, part_level)
26/32: x.native(['b','vec','y','x']).shape
26/33:
# complete noise warping step function
def noise_step(vtx_pos, noise, up_level,mesh_idxs,vertices):
    res, _ = math.spatial(noise).sizes

    part_level = up_level
    resolution = res * (2 ** up_level)
    tris_per_row = 2 ** (part_level-1)

    noise_up = warp.upsample_noise_cond(noise, up_level)

    idx_y = mesh_idxs[:,0].int()
    idx_x = mesh_idxs[:,1].int()
    warped_coords = vtx_pos.native(['x','y','vector'])[idx_y, idx_x].fliplr()
    rast_out = warp.rasterize(warped_coords, vertices, res * tris_per_row, resolution, device)

    noise_warped = warp.transport_noise(noise_up, res, rast_out, part_level)

    return noise_warped

def noise_step_torch(vtx_pos, noise, up_level,mesh_idxs,vertices):
    batch_size, num_channel, res, _ = noise.shape

    part_level = up_level
    resolution = res * (2 ** up_level)
    tris_per_row = 2 ** (part_level-1)

    noise_up = warp.upsample_noise_cond(noise, up_level)

    idx_y = mesh_idxs[:,0].int()
    idx_x = mesh_idxs[:,1].int()
    warped_coords = vtx_pos.native(['x','y','vector'])[idx_y, idx_x].fliplr()
    rast_out = warp.rasterize(warped_coords, vertices, res * tris_per_row, resolution, device)

    noise_warped = warp.transport_noise_torch(noise_up, res, rast_out, part_level)

    return noise_warped
26/34:
# normalize the grid and corresponding vertex velocities for warping
grid_nmlzd = grid1.center * tris_per_dim / BOUND
v_trj_nmlzd = v_trj_rs * tris_per_dim / BOUND
26/35:
def calc_grid_pos(grid, vel, dt):
    grid_warp = grid - vel.values*dt
    return grid_warp

def gen_grids_warped(grid, vels, dt):
    # maps = []
    maps = [grid]
    for i in range(vels.time.size-1):
        grid_warp = calc_grid_pos(grid,vels.time[i+1],dt)
        maps.append(grid_warp)
    maps = math.stack(maps, batch('time'))
    return maps
26/36:
# generate the warped grid positions
grids_warped = gen_grids_warped(grid_nmlzd,v_trj_nmlzd,.5)
26/37:
# noise warping by the proposed method, no disclusion fix
noise_trj = [x]
x_in = x
for i in range(NUM_TIME_STEPS):
    # x_warped = noise_step(grids_warped.time[i+1], x_in, up_level, reshaped_mesh_idxs, vertices)

    x_warped = noise_step_torch(grids_warped.time[i+1], x_in, up_level, reshaped_mesh_idxs, vertices)
    x_warped = math.tensor(x_warped, batch(b=batch_size),math.channel(vec=num_channel),spatial(x=RES, y=RES))
    noise_trj.append(x_warped)
    x_in = x_warped
noise_trj = math.stack(noise_trj, batch('time'))
26/38:
# noise warping by the proposed method, no disclusion fix
noise_trj = [x]
x_in = x
for i in range(NUM_TIME_STEPS):
    # x_warped = noise_step(grids_warped.time[i+1], x_in, up_level, reshaped_mesh_idxs, vertices)

    x_warped = noise_step_torch(grids_warped.time[i+1], x_in, up_level, reshaped_mesh_idxs, vertices)
    x_warped = math.tensor(x_warped, batch(b=batch_size),math.channel(vec=num_channel),spatial(x=RES, y=RES))
    noise_trj.append(x_warped)
    x_in = x_warped
noise_trj = math.stack(noise_trj, batch('time'))
26/39: x
26/40: x.device
26/41: x_xin
26/42: x_in
26/43: x_in.device
26/44: math.tensor(x_warped, batch(b=batch_size),math.channel(vec=num_channel),spatial(x=RES, y=RES))
26/45: math.tensor(x_warped, batch(b=batch_size),math.channel(vec=num_channel),spatial(x=RES, y=RES)).device
26/46: math.tensor(x_warped, batch(b=batch_size),math.channel(vec=num_channel),spatial(x=RES, y=RES)).to(device).device
26/47: math.tensor(x_warped, batch(b=batch_size),math.channel(vec=num_channel),spatial(x=RES, y=RES)).device
26/48: math.to_device(math.tensor(x_warped, batch(b=batch_size),math.channel(vec=num_channel),spatial(x=RES, y=RES)))
26/49: math.to_device(math.tensor(x_warped, batch(b=batch_size),math.channel(vec=num_channel),spatial(x=RES, y=RES)),'cuda')
26/50: math.to_device(math.tensor(x_warped, batch(b=batch_size),math.channel(vec=num_channel),spatial(x=RES, y=RES)),device)
26/51: math.to_device(math.tensor(x_warped, batch(b=batch_size),math.channel(vec=num_channel),spatial(x=RES, y=RES)),'gpu')
26/52: math.to_device(math.tensor(x_warped, batch(b=batch_size),math.channel(vec=num_channel),spatial(x=RES, y=RES)),'GPU')
26/53: math.to_device(math.tensor(x_warped, batch(b=batch_size),math.channel(vec=num_channel),spatial(x=RES, y=RES)),'GPU').device
26/54: math.tensor(x_warped, batch(b=batch_size),math.channel(vec=num_channel),spatial(x=RES, y=RES)).default_backend
26/55: math.tensor(x_warped, batch(b=batch_size),math.channel(vec=num_channel),spatial(x=RES, y=RES)).device
26/56: torch.cuda.is_available()
26/57: device
26/58: x.device
26/59: math.to_device(math.tensor(x_warped, batch(b=batch_size),math.channel(vec=num_channel),spatial(x=RES, y=RES)),'GPU')
26/60: math.to_device(math.tensor(x_warped, batch(b=batch_size),math.channel(vec=num_channel),spatial(x=RES, y=RES)),'GPU').device
26/61: math.to_device(math.tensor(x_warped, batch(b=batch_size),math.channel(vec=num_channel),spatial(x=RES, y=RES)),'GPU').device
26/62: x.device
26/63: math.to_device(math.tensor(x_warped, batch(b=batch_size),math.channel(vec=num_channel),spatial(x=RES, y=RES)),'GPU').device
26/64: math.to_device(math.tensor(x_warped, batch(b=batch_size),math.channel(vec=num_channel),spatial(x=RES, y=RES)),'GPU').device
26/65: phi.detect_backends()
26/66: backend.default_backend().list_devices('GPU')
26/67: backend.default_backend().list_devices('CPU')
26/68: backend.default_backend().list_devices('GPU')
26/69: backend.default_backend().list_devices('GPU')
26/70: backend.default_backend().list_devices('CPU')
26/71: backend.default_backend().list_devices('GPU')
26/72: backend.default_backend().set_default_device('CPU')
26/73: backend.default_backend().set_default_device('GPU')
26/74: phi.detect_backends()
26/75: math.to_device(math.tensor(x_warped, batch(b=batch_size),math.channel(vec=num_channel),spatial(x=RES, y=RES)),'GPU').device
26/76: math.to_device(math.tensor(x_warped, batch(b=batch_size),math.channel(vec=num_channel),spatial(x=RES, y=RES)),'GPU').device
27/1:
from phi.torch.flow import *
from tqdm.notebook import trange
import torch
import matplotlib.pyplot as plt
27/2:
import warp
backend.default_backend().set_default_device('GPU')
27/3:
# fluid specification & initialization
RES = 32
BOUND = 100
NUM_TIME_STEPS = 50
DT = 0.5
domain = Box(x=BOUND, y=BOUND)
INFLOW_RATE = 0.5
BUOYANCY = 0.1
inflow = Sphere(x=50, y=9.5, radius=8)

v0 = StaggeredGrid(0, 0, domain, x=RES, y=RES)
smoke0 = CenteredGrid(0, math.extrapolation.BOUNDARY, domain, x=RES, y=RES)
27/4:
# noise specification & initialization
batch_size = 2
num_channel = 2
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
up_level = 2 # noise upsampling level
res_up = RES * (2 ** up_level)
27/5:
# conditional noise upsampling & visualization
x = math.random_normal(batch(b=batch_size),math.channel(vec=num_channel),spatial(x=RES, y=RES))
x_up = warp.upsample_noise_cond(x, up_level)
vis.plot({'noise':x.b[0].vec[0],'conditional upsampled noise':x_up.b[0].vec[0]})
27/6:
# fluid step function with smoke inflow
@jit_compile
def step(v, s, p, dt):
    s = advect.mac_cormack(s, v, dt) + INFLOW_RATE * resample(inflow, to=s, soft=True)
    buoyancy = resample(s * (0, BUOYANCY), to=v)
    v = advect.semi_lagrangian(v, v, dt) + buoyancy * dt
    v, p = fluid.make_incompressible(v, (), Solve('CG', 1e-3, x0=p))
    return v, s, p
27/7: v_trj, s_trj, p_trj = iterate(step, batch(time=NUM_TIME_STEPS), v0, smoke0, None, dt=DT, range=trange, substeps=3)
27/8:
# resampling the grid to a finer grid for noise transport
part_level = 2 # partition level for triangulation
tris_per_pix_dim = 2 ** (part_level-1) # triangles per pixel per dimension
tris_per_dim = tris_per_pix_dim * RES # triangles per dimension
vtx_per_dim = tris_per_pix_dim * RES + 1 # vertices per dimention
domain1=Box(x=(-BOUND/RES/tris_per_pix_dim/2, BOUND+BOUND/RES/tris_per_pix_dim/2),y=(-BOUND/RES/tris_per_pix_dim/2,BOUND+BOUND/RES/tris_per_pix_dim/2))
grid1 = CenteredGrid(0, math.extrapolation.BOUNDARY, domain1, x=vtx_per_dim, y=vtx_per_dim)
v_trj_rs = field.resample(value=v_trj, to=grid1)

vis.plot({'velocity': v_trj.time[-1], 'velocity resampled': v_trj_rs.time[-1]})
27/9:
# vertices & triangles (represented by vertex indices) generation
_, vertices = warp.vertices_gen(RES, RES, part_level)
reshaped_mesh_idxs = warp.mesh_idx_gen(RES, RES, part_level)
27/10: x.native(['b','vec','y','x']).shape
27/11:
# complete noise warping step function
def noise_step(vtx_pos, noise, up_level,mesh_idxs,vertices):
    res, _ = math.spatial(noise).sizes

    part_level = up_level
    resolution = res * (2 ** up_level)
    tris_per_row = 2 ** (part_level-1)

    noise_up = warp.upsample_noise_cond(noise, up_level)

    idx_y = mesh_idxs[:,0].int()
    idx_x = mesh_idxs[:,1].int()
    warped_coords = vtx_pos.native(['x','y','vector'])[idx_y, idx_x].fliplr()
    rast_out = warp.rasterize(warped_coords, vertices, res * tris_per_row, resolution, device)

    noise_warped = warp.transport_noise(noise_up, res, rast_out, part_level)

    return noise_warped

def noise_step_torch(vtx_pos, noise, up_level,mesh_idxs,vertices):
    batch_size, num_channel, res, _ = noise.shape

    part_level = up_level
    resolution = res * (2 ** up_level)
    tris_per_row = 2 ** (part_level-1)

    noise_up = warp.upsample_noise_cond(noise, up_level)

    idx_y = mesh_idxs[:,0].int()
    idx_x = mesh_idxs[:,1].int()
    warped_coords = vtx_pos.native(['x','y','vector'])[idx_y, idx_x].fliplr()
    rast_out = warp.rasterize(warped_coords, vertices, res * tris_per_row, resolution, device)

    noise_warped = warp.transport_noise_torch(noise_up, res, rast_out, part_level)

    return noise_warped
27/12:
# normalize the grid and corresponding vertex velocities for warping
grid_nmlzd = grid1.center * tris_per_dim / BOUND
v_trj_nmlzd = v_trj_rs * tris_per_dim / BOUND
27/13:
def calc_grid_pos(grid, vel, dt):
    grid_warp = grid - vel.values*dt
    return grid_warp

def gen_grids_warped(grid, vels, dt):
    # maps = []
    maps = [grid]
    for i in range(vels.time.size-1):
        grid_warp = calc_grid_pos(grid,vels.time[i+1],dt)
        maps.append(grid_warp)
    maps = math.stack(maps, batch('time'))
    return maps
27/14:
# generate the warped grid positions
grids_warped = gen_grids_warped(grid_nmlzd,v_trj_nmlzd,.5)
27/15: x.device
27/16: math.to_device(math.tensor(x_warped, batch(b=batch_size),math.channel(vec=num_channel),spatial(x=RES, y=RES)),'GPU').device
27/17:
# noise warping by the proposed method, no disclusion fix
noise_trj = [x]
x_in = x
for i in range(NUM_TIME_STEPS):
    # x_warped = noise_step(grids_warped.time[i+1], x_in, up_level, reshaped_mesh_idxs, vertices)

    x_warped = noise_step_torch(grids_warped.time[i+1], x_in, up_level, reshaped_mesh_idxs, vertices)
    x_warped = math.tensor(x_warped, batch(b=batch_size),math.channel(vec=num_channel),spatial(x=RES, y=RES))
    noise_trj.append(x_warped)
    x_in = x_warped
noise_trj = math.stack(noise_trj, batch('time'))
27/18:
# noise warping by the proposed method, no disclusion fix
noise_trj = [x]
x_in = x
for i in range(NUM_TIME_STEPS):
    # x_warped = noise_step(grids_warped.time[i+1], x_in, up_level, reshaped_mesh_idxs, vertices)

    x_warped = noise_step_torch(grids_warped.time[i+1], x_in, up_level, reshaped_mesh_idxs, vertices)
    x_warped = math.tensor(x_warped, batch(b=batch_size),math.channel(vec=num_channel),spatial(x=RES, y=RES))
    noise_trj.append(x_warped)
    x_in = x_warped
noise_trj = math.stack(noise_trj, batch('time'))
27/19:
# noise warping by the proposed method, no disclusion fix
noise_trj = [x]
x_in = x
for i in range(NUM_TIME_STEPS):
    # x_warped = noise_step(grids_warped.time[i+1], x_in, up_level, reshaped_mesh_idxs, vertices)

    x_warped = noise_step_torch(grids_warped.time[i+1], x_in, up_level, reshaped_mesh_idxs, vertices)
    x_warped = math.tensor(x_warped, batch(b=batch_size),math.channel(vec=num_channel),spatial(x=RES, y=RES))
    noise_trj.append(x_warped)
    x_in = x_warped
noise_trj = math.stack(noise_trj, batch('time'))
28/1:
from phi.torch.flow import *
from tqdm.notebook import trange
import torch
import matplotlib.pyplot as plt
28/2:
import warp
backend.default_backend().set_default_device('GPU')
torch.set_default_device('cuda')
28/3:
# fluid specification & initialization
RES = 32
BOUND = 100
NUM_TIME_STEPS = 50
DT = 0.5
domain = Box(x=BOUND, y=BOUND)
INFLOW_RATE = 0.5
BUOYANCY = 0.1
inflow = Sphere(x=50, y=9.5, radius=8)

v0 = StaggeredGrid(0, 0, domain, x=RES, y=RES)
smoke0 = CenteredGrid(0, math.extrapolation.BOUNDARY, domain, x=RES, y=RES)
28/4:
# noise specification & initialization
batch_size = 2
num_channel = 2
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
up_level = 2 # noise upsampling level
res_up = RES * (2 ** up_level)
28/5:
# conditional noise upsampling & visualization
x = math.random_normal(batch(b=batch_size),math.channel(vec=num_channel),spatial(x=RES, y=RES))
x_up = warp.upsample_noise_cond(x, up_level)
vis.plot({'noise':x.b[0].vec[0],'conditional upsampled noise':x_up.b[0].vec[0]})
28/6:
# fluid step function with smoke inflow
@jit_compile
def step(v, s, p, dt):
    s = advect.mac_cormack(s, v, dt) + INFLOW_RATE * resample(inflow, to=s, soft=True)
    buoyancy = resample(s * (0, BUOYANCY), to=v)
    v = advect.semi_lagrangian(v, v, dt) + buoyancy * dt
    v, p = fluid.make_incompressible(v, (), Solve('CG', 1e-3, x0=p))
    return v, s, p
28/7: v_trj, s_trj, p_trj = iterate(step, batch(time=NUM_TIME_STEPS), v0, smoke0, None, dt=DT, range=trange, substeps=3)
28/8:
# resampling the grid to a finer grid for noise transport
part_level = 2 # partition level for triangulation
tris_per_pix_dim = 2 ** (part_level-1) # triangles per pixel per dimension
tris_per_dim = tris_per_pix_dim * RES # triangles per dimension
vtx_per_dim = tris_per_pix_dim * RES + 1 # vertices per dimention
domain1=Box(x=(-BOUND/RES/tris_per_pix_dim/2, BOUND+BOUND/RES/tris_per_pix_dim/2),y=(-BOUND/RES/tris_per_pix_dim/2,BOUND+BOUND/RES/tris_per_pix_dim/2))
grid1 = CenteredGrid(0, math.extrapolation.BOUNDARY, domain1, x=vtx_per_dim, y=vtx_per_dim)
v_trj_rs = field.resample(value=v_trj, to=grid1)

vis.plot({'velocity': v_trj.time[-1], 'velocity resampled': v_trj_rs.time[-1]})
28/9:
# vertices & triangles (represented by vertex indices) generation
_, vertices = warp.vertices_gen(RES, RES, part_level)
reshaped_mesh_idxs = warp.mesh_idx_gen(RES, RES, part_level)
28/10: x.native(['b','vec','y','x']).shape
28/11:
# complete noise warping step function
def noise_step(vtx_pos, noise, up_level,mesh_idxs,vertices):
    res, _ = math.spatial(noise).sizes

    part_level = up_level
    resolution = res * (2 ** up_level)
    tris_per_row = 2 ** (part_level-1)

    noise_up = warp.upsample_noise_cond(noise, up_level)

    idx_y = mesh_idxs[:,0].int()
    idx_x = mesh_idxs[:,1].int()
    warped_coords = vtx_pos.native(['x','y','vector'])[idx_y, idx_x].fliplr()
    rast_out = warp.rasterize(warped_coords, vertices, res * tris_per_row, resolution, device)

    noise_warped = warp.transport_noise(noise_up, res, rast_out, part_level)

    return noise_warped

def noise_step_torch(vtx_pos, noise, up_level,mesh_idxs,vertices):
    batch_size, num_channel, res, _ = noise.shape

    part_level = up_level
    resolution = res * (2 ** up_level)
    tris_per_row = 2 ** (part_level-1)

    noise_up = warp.upsample_noise_cond(noise, up_level)

    idx_y = mesh_idxs[:,0].int()
    idx_x = mesh_idxs[:,1].int()
    warped_coords = vtx_pos.native(['x','y','vector'])[idx_y, idx_x].fliplr()
    rast_out = warp.rasterize(warped_coords, vertices, res * tris_per_row, resolution, device)

    noise_warped = warp.transport_noise_torch(noise_up, res, rast_out, part_level)

    return noise_warped
28/12:
from phi.torch.flow import *
from tqdm.notebook import trange
import torch
import matplotlib.pyplot as plt
28/13:
import warp
backend.default_backend().set_default_device('GPU')
torch.set_default_device('cuda')
28/14:
# fluid specification & initialization
RES = 32
BOUND = 100
NUM_TIME_STEPS = 50
DT = 0.5
domain = Box(x=BOUND, y=BOUND)
INFLOW_RATE = 0.5
BUOYANCY = 0.1
inflow = Sphere(x=50, y=9.5, radius=8)

v0 = StaggeredGrid(0, 0, domain, x=RES, y=RES)
smoke0 = CenteredGrid(0, math.extrapolation.BOUNDARY, domain, x=RES, y=RES)
28/15:
# noise specification & initialization
batch_size = 2
num_channel = 2
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
up_level = 2 # noise upsampling level
res_up = RES * (2 ** up_level)
28/16:
# conditional noise upsampling & visualization
x = math.random_normal(batch(b=batch_size),math.channel(vec=num_channel),spatial(x=RES, y=RES))
x_up = warp.upsample_noise_cond(x, up_level)
vis.plot({'noise':x.b[0].vec[0],'conditional upsampled noise':x_up.b[0].vec[0]})
28/17:
# fluid step function with smoke inflow
@jit_compile
def step(v, s, p, dt):
    s = advect.mac_cormack(s, v, dt) + INFLOW_RATE * resample(inflow, to=s, soft=True)
    buoyancy = resample(s * (0, BUOYANCY), to=v)
    v = advect.semi_lagrangian(v, v, dt) + buoyancy * dt
    v, p = fluid.make_incompressible(v, (), Solve('CG', 1e-3, x0=p))
    return v, s, p
28/18:
# normalize the grid and corresponding vertex velocities for warping
grid_nmlzd = grid1.center * tris_per_dim / BOUND
v_trj_nmlzd = v_trj_rs * tris_per_dim / BOUND
28/19:
def calc_grid_pos(grid, vel, dt):
    grid_warp = grid - vel.values*dt
    return grid_warp

def gen_grids_warped(grid, vels, dt):
    # maps = []
    maps = [grid]
    for i in range(vels.time.size-1):
        grid_warp = calc_grid_pos(grid,vels.time[i+1],dt)
        maps.append(grid_warp)
    maps = math.stack(maps, batch('time'))
    return maps
28/20:
# generate the warped grid positions
grids_warped = gen_grids_warped(grid_nmlzd,v_trj_nmlzd,.5)
28/21:
# noise warping by the proposed method, no disclusion fix
noise_trj = [x]
x_in = x
for i in range(NUM_TIME_STEPS):
    # x_warped = noise_step(grids_warped.time[i+1], x_in, up_level, reshaped_mesh_idxs, vertices)

    x_warped = noise_step_torch(grids_warped.time[i+1], x_in, up_level, reshaped_mesh_idxs, vertices)
    x_warped = math.tensor(x_warped, batch(b=batch_size),math.channel(vec=num_channel),spatial(x=RES, y=RES))
    noise_trj.append(x_warped)
    x_in = x_warped
noise_trj = math.stack(noise_trj, batch('time'))
28/22:
# noise warping by the proposed method, filling empty cell with warping from previous frame
noise_trj_prev = [x]
x_in = x
for i in range(NUM_TIME_STEPS):
    x_warped = noise_step(grids_warped.time[i+1], x_in, up_level, reshaped_mesh_idxs, vertices)
    x_warped_prev = noise_step(grids_warped.time[i], x_in, up_level, reshaped_mesh_idxs, vertices)
    x_warped = math.where(math.is_nan(x_warped),x_warped_prev,x_warped)
    noise_trj_prev.append(x_warped)
    x_in = x_warped
noise_trj_prev = math.stack(noise_trj_prev, batch('time'))
28/23:
# noise warping by the proposed method, filling empty cell with warping from previous frame
noise_trj_prev = [x]
x_in = x
for i in range(NUM_TIME_STEPS):
    # x_warped = noise_step(grids_warped.time[i+1], x_in, up_level, reshaped_mesh_idxs, vertices)
    # x_warped_prev = noise_step(grids_warped.time[i], x_in, up_level, reshaped_mesh_idxs, vertices)

    x_warped = noise_step_torch(grids_warped.time[i+1], x_in, up_level, reshaped_mesh_idxs, vertices)
    x_warped_prev = noise_step_torch(grids_warped.time[i], x_in, up_level, reshaped_mesh_idxs, vertices)
    x_warped = math.where(math.is_nan(x_warped),x_warped_prev,x_warped)
    noise_trj_prev.append(x_warped)
    x_in = x_warped
noise_trj_prev = math.stack(noise_trj_prev, batch('time'))
28/24:
# noise warping by the proposed method, filling empty cell with warping from previous frame
noise_trj_prev = [x]
x_in = x
for i in range(NUM_TIME_STEPS):
    # x_warped = noise_step(grids_warped.time[i+1], x_in, up_level, reshaped_mesh_idxs, vertices)
    # x_warped_prev = noise_step(grids_warped.time[i], x_in, up_level, reshaped_mesh_idxs, vertices)

    x_warped = noise_step_torch(grids_warped.time[i+1], x_in, up_level, reshaped_mesh_idxs, vertices)
    x_warped_prev = noise_step_torch(grids_warped.time[i], x_in, up_level, reshaped_mesh_idxs, vertices)
    x_warped = math.where(math.is_nan(x_warped),x_warped_prev,x_warped)
    noise_trj_prev.append(x_warped)
    x_in = x_warped
noise_trj_prev = math.stack(noise_trj_prev, batch('time'))
28/25:
# noise warping by the proposed method, filling empty cell with warping from previous frame
noise_trj_prev = [x]
x_in = x
for i in range(NUM_TIME_STEPS):
    # x_warped = noise_step(grids_warped.time[i+1], x_in, up_level, reshaped_mesh_idxs, vertices)
    # x_warped_prev = noise_step(grids_warped.time[i], x_in, up_level, reshaped_mesh_idxs, vertices)

    x_warped = noise_step_torch(grids_warped.time[i+1], x_in, up_level, reshaped_mesh_idxs, vertices)
    x_warped = math.tensor(x_warped, batch(b=batch_size),math.channel(vec=num_channel),spatial(x=RES, y=RES))
    x_warped_prev = noise_step_torch(grids_warped.time[i], x_in, up_level, reshaped_mesh_idxs, vertices)
    x_warped_prev = math.tensor(x_warped, batch(b=batch_size),math.channel(vec=num_channel),spatial(x=RES, y=RES))
    x_warped = math.where(math.is_nan(x_warped),x_warped_prev,x_warped)
    noise_trj_prev.append(x_warped)
    x_in = x_warped
noise_trj_prev = math.stack(noise_trj_prev, batch('time'))
28/26:
# noise warping by the proposed method, filling empty cell with warping from last frame + random noise
noise_trj_prev_rand = [x]
x_in = x
for i in range(NUM_TIME_STEPS):
    # x_warped = noise_step(grids_warped.time[i+1], x_in, up_level, reshaped_mesh_idxs, vertices)
    # x_warped_prev = noise_step(grids_warped.time[i], x_in, up_level, reshaped_mesh_idxs, vertices)

    x_warped = noise_step(grids_warped.time[i+1], x_in, up_level, reshaped_mesh_idxs, vertices)
    x_warped = math.tensor(x_warped, batch(b=batch_size),math.channel(vec=num_channel),spatial(x=RES, y=RES))
    x_warped_prev = noise_step(grids_warped.time[i], x_in, up_level, reshaped_mesh_idxs, vertices)
    x_warped_prev = math.tensor(x_warped, batch(b=batch_size),math.channel(vec=num_channel),spatial(x=RES, y=RES))

    x_warped = math.where(math.is_nan(x_warped),x_warped_prev,x_warped)
    x_warped = math.where(math.is_nan(x_warped), math.random_normal(x_warped.shape), x_warped)
    noise_trj_prev_rand.append(x_warped)
    x_in = x_warped
noise_trj_prev_rand = math.stack(noise_trj_prev_rand, batch('time'))
28/27:
# noise warping by the proposed method, filling empty cell with warping from last frame + random noise
noise_trj_prev_rand = [x]
x_in = x
for i in range(NUM_TIME_STEPS):
    # x_warped = noise_step(grids_warped.time[i+1], x_in, up_level, reshaped_mesh_idxs, vertices)
    # x_warped_prev = noise_step(grids_warped.time[i], x_in, up_level, reshaped_mesh_idxs, vertices)

    x_warped = noise_step(grids_warped.time[i+1], x_in, up_level, reshaped_mesh_idxs, vertices)
    x_warped = math.tensor(x_warped, batch(b=batch_size),math.channel(vec=num_channel),spatial(x=RES, y=RES))
    x_warped_prev = noise_step(grids_warped.time[i], x_in, up_level, reshaped_mesh_idxs, vertices)
    x_warped_prev = math.tensor(x_warped_prev, batch(b=batch_size),math.channel(vec=num_channel),spatial(x=RES, y=RES))

    x_warped = math.where(math.is_nan(x_warped),x_warped_prev,x_warped)
    x_warped = math.where(math.is_nan(x_warped), math.random_normal(x_warped.shape), x_warped)
    noise_trj_prev_rand.append(x_warped)
    x_in = x_warped
noise_trj_prev_rand = math.stack(noise_trj_prev_rand, batch('time'))
28/28:
# noise warping by the proposed method, filling empty cell with warping from last frame + random noise
noise_trj_prev_rand = [x]
x_in = x
for i in range(NUM_TIME_STEPS):
    # x_warped = noise_step(grids_warped.time[i+1], x_in, up_level, reshaped_mesh_idxs, vertices)
    # x_warped_prev = noise_step(grids_warped.time[i], x_in, up_level, reshaped_mesh_idxs, vertices)

    x_warped = noise_step_torch(grids_warped.time[i+1], x_in, up_level, reshaped_mesh_idxs, vertices)
    x_warped = math.tensor(x_warped, batch(b=batch_size),math.channel(vec=num_channel),spatial(x=RES, y=RES))
    x_warped_prev = noise_step(grids_warped.time[i], x_in, up_level, reshaped_mesh_idxs, vertices)
    x_warped_prev = math.tensor_torch(x_warped_prev, batch(b=batch_size),math.channel(vec=num_channel),spatial(x=RES, y=RES))

    x_warped = math.where(math.is_nan(x_warped),x_warped_prev,x_warped)
    x_warped = math.where(math.is_nan(x_warped), math.random_normal(x_warped.shape), x_warped)
    noise_trj_prev_rand.append(x_warped)
    x_in = x_warped
noise_trj_prev_rand = math.stack(noise_trj_prev_rand, batch('time'))
28/29:
# noise warping by the proposed method, filling empty cell with warping from last frame + random noise
noise_trj_prev_rand = [x]
x_in = x
for i in range(NUM_TIME_STEPS):
    # x_warped = noise_step(grids_warped.time[i+1], x_in, up_level, reshaped_mesh_idxs, vertices)
    # x_warped_prev = noise_step(grids_warped.time[i], x_in, up_level, reshaped_mesh_idxs, vertices)

    x_warped = noise_step_torch(grids_warped.time[i+1], x_in, up_level, reshaped_mesh_idxs, vertices)
    x_warped = math.tensor(x_warped, batch(b=batch_size),math.channel(vec=num_channel),spatial(x=RES, y=RES))
    x_warped_prev = noise_step_torch(grids_warped.time[i], x_in, up_level, reshaped_mesh_idxs, vertices)
    x_warped_prev = math.tensor(x_warped_prev, batch(b=batch_size),math.channel(vec=num_channel),spatial(x=RES, y=RES))

    x_warped = math.where(math.is_nan(x_warped),x_warped_prev,x_warped)
    x_warped = math.where(math.is_nan(x_warped), math.random_normal(x_warped.shape), x_warped)
    noise_trj_prev_rand.append(x_warped)
    x_in = x_warped
noise_trj_prev_rand = math.stack(noise_trj_prev_rand, batch('time'))
28/30:
# noise warping comparison
row1 = math.stack([noise_trj.b[0].vec[0],noise_trj_prev.b[0].vec[0]],batch('row'))
row2 = math.stack([noise_trj_prev_rand.b[0].vec[0],s_trj.values / s_trj.values.max],batch('row'))
ani = math.stack([row1,row2],batch('col'))
t1 = math.stack(['original dubbed noise','with previous frame'],batch('row'))
t2 = math.stack(['with previous frame + random noise', 'density'],batch('row'))
ttl = math.stack([t1,t2],batch('col'))

vis.plot(ani,row_dims='row',col_dims='col', frame_time=40,animate='time',size=(10,6),title=ttl)
29/1:
from phi.torch.flow import *
from tqdm.notebook import trange
import torch
import matplotlib.pyplot as plt
29/2:
import warp
backend.default_backend().set_default_device('GPU')
torch.set_default_device('cuda')
29/3:
# fluid specification & initialization
RES = 32
BOUND = 100
NUM_TIME_STEPS = 50
DT = 0.5
domain = Box(x=BOUND, y=BOUND)
INFLOW_RATE = 0.5
BUOYANCY = 0.1
inflow = Sphere(x=50, y=9.5, radius=8)

v0 = StaggeredGrid(0, 0, domain, x=RES, y=RES)
smoke0 = CenteredGrid(0, math.extrapolation.BOUNDARY, domain, x=RES, y=RES)
29/4:
# noise specification & initialization
batch_size = 2
num_channel = 2
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
up_level = 2 # noise upsampling level
res_up = RES * (2 ** up_level)
29/5:
# conditional noise upsampling & visualization
x = math.random_normal(batch(b=batch_size),math.channel(vec=num_channel),spatial(x=RES, y=RES))
x_up = warp.upsample_noise_cond(x, up_level)
vis.plot({'noise':x.b[0].vec[0],'conditional upsampled noise':x_up.b[0].vec[0]})
29/6:
# fluid step function with smoke inflow
@jit_compile
def step(v, s, p, dt):
    s = advect.mac_cormack(s, v, dt) + INFLOW_RATE * resample(inflow, to=s, soft=True)
    buoyancy = resample(s * (0, BUOYANCY), to=v)
    v = advect.semi_lagrangian(v, v, dt) + buoyancy * dt
    v, p = fluid.make_incompressible(v, (), Solve('CG', 1e-3, x0=p))
    return v, s, p
29/7: v_trj, s_trj, p_trj = iterate(step, batch(time=NUM_TIME_STEPS), v0, smoke0, None, dt=DT, range=trange, substeps=3)
29/8:
# resampling the grid to a finer grid for noise transport
part_level = 2 # partition level for triangulation
tris_per_pix_dim = 2 ** (part_level-1) # triangles per pixel per dimension
tris_per_dim = tris_per_pix_dim * RES # triangles per dimension
vtx_per_dim = tris_per_pix_dim * RES + 1 # vertices per dimention
domain1=Box(x=(-BOUND/RES/tris_per_pix_dim/2, BOUND+BOUND/RES/tris_per_pix_dim/2),y=(-BOUND/RES/tris_per_pix_dim/2,BOUND+BOUND/RES/tris_per_pix_dim/2))
grid1 = CenteredGrid(0, math.extrapolation.BOUNDARY, domain1, x=vtx_per_dim, y=vtx_per_dim)
v_trj_rs = field.resample(value=v_trj, to=grid1)

vis.plot({'velocity': v_trj.time[-1], 'velocity resampled': v_trj_rs.time[-1]})
29/9:
# vertices & triangles (represented by vertex indices) generation
_, vertices = warp.vertices_gen(RES, RES, part_level)
reshaped_mesh_idxs = warp.mesh_idx_gen(RES, RES, part_level)
29/10: x.native(['b','vec','y','x']).shape
29/11:
# complete noise warping step function
def noise_step(vtx_pos, noise, up_level,mesh_idxs,vertices):
    res, _ = math.spatial(noise).sizes

    part_level = up_level
    resolution = res * (2 ** up_level)
    tris_per_row = 2 ** (part_level-1)

    noise_up = warp.upsample_noise_cond(noise, up_level)

    idx_y = mesh_idxs[:,0].int()
    idx_x = mesh_idxs[:,1].int()
    warped_coords = vtx_pos.native(['x','y','vector'])[idx_y, idx_x].fliplr()
    rast_out = warp.rasterize(warped_coords, vertices, res * tris_per_row, resolution, device)

    noise_warped = warp.transport_noise(noise_up, res, rast_out, part_level)

    return noise_warped

def noise_step_torch(vtx_pos, noise, up_level,mesh_idxs,vertices):
    batch_size, num_channel, res, _ = noise.shape

    part_level = up_level
    resolution = res * (2 ** up_level)
    tris_per_row = 2 ** (part_level-1)

    noise_up = warp.upsample_noise_cond(noise, up_level)

    idx_y = mesh_idxs[:,0].int()
    idx_x = mesh_idxs[:,1].int()
    warped_coords = vtx_pos.native(['x','y','vector'])[idx_y, idx_x].fliplr()
    rast_out = warp.rasterize(warped_coords, vertices, res * tris_per_row, resolution, device)

    noise_warped = warp.transport_noise_torch(noise_up, res, rast_out, part_level)

    return noise_warped
29/12:
# normalize the grid and corresponding vertex velocities for warping
grid_nmlzd = grid1.center * tris_per_dim / BOUND
v_trj_nmlzd = v_trj_rs * tris_per_dim / BOUND
29/13:
def calc_grid_pos(grid, vel, dt):
    grid_warp = grid - vel.values*dt
    return grid_warp

def gen_grids_warped(grid, vels, dt):
    # maps = []
    maps = [grid]
    for i in range(vels.time.size-1):
        grid_warp = calc_grid_pos(grid,vels.time[i+1],dt)
        maps.append(grid_warp)
    maps = math.stack(maps, batch('time'))
    return maps
29/14:
# generate the warped grid positions
grids_warped = gen_grids_warped(grid_nmlzd,v_trj_nmlzd,.5)
29/15:
# noise warping by the proposed method, no disclusion fix
noise_trj = [x]
x_in = x
for i in range(NUM_TIME_STEPS):
    # x_warped = noise_step(grids_warped.time[i+1], x_in, up_level, reshaped_mesh_idxs, vertices)

    x_warped = noise_step_torch(grids_warped.time[i+1], x_in, up_level, reshaped_mesh_idxs, vertices)
    x_warped = math.tensor(x_warped, batch(b=batch_size),math.channel(vec=num_channel),spatial(x=RES, y=RES))
    noise_trj.append(x_warped)
    x_in = x_warped
noise_trj = math.stack(noise_trj, batch('time'))
29/16:
# noise warping by the proposed method, no disclusion fix
noise_trj = [x]
x_in = x
for i in range(NUM_TIME_STEPS):
    # x_warped = noise_step(grids_warped.time[i+1], x_in, up_level, reshaped_mesh_idxs, vertices)

    x_warped = noise_step_torch(grids_warped.time[i+1], x_in, up_level, reshaped_mesh_idxs, vertices)
    x_warped = math.tensor(x_warped, batch(b=batch_size),math.channel(vec=num_channel),spatial(x=RES, y=RES))
    noise_trj.append(x_warped)
    x_in = x_warped
noise_trj = math.stack(noise_trj, batch('time'))
30/1:
from phi.torch.flow import *
from tqdm.notebook import trange
import torch
import matplotlib.pyplot as plt
30/2:
import warp
backend.default_backend().set_default_device('GPU')
torch.set_default_device('cuda')
30/3:
# fluid specification & initialization
RES = 32
BOUND = 100
NUM_TIME_STEPS = 50
DT = 0.5
domain = Box(x=BOUND, y=BOUND)
INFLOW_RATE = 0.5
BUOYANCY = 0.1
inflow = Sphere(x=50, y=9.5, radius=8)

v0 = StaggeredGrid(0, 0, domain, x=RES, y=RES)
smoke0 = CenteredGrid(0, math.extrapolation.BOUNDARY, domain, x=RES, y=RES)
30/4:
# noise specification & initialization
batch_size = 2
num_channel = 2
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
up_level = 2 # noise upsampling level
res_up = RES * (2 ** up_level)
30/5:
# conditional noise upsampling & visualization
x = math.random_normal(batch(b=batch_size),math.channel(vec=num_channel),spatial(x=RES, y=RES))
x_up = warp.upsample_noise_cond(x, up_level)
vis.plot({'noise':x.b[0].vec[0],'conditional upsampled noise':x_up.b[0].vec[0]})
30/6:
# fluid step function with smoke inflow
@jit_compile
def step(v, s, p, dt):
    s = advect.mac_cormack(s, v, dt) + INFLOW_RATE * resample(inflow, to=s, soft=True)
    buoyancy = resample(s * (0, BUOYANCY), to=v)
    v = advect.semi_lagrangian(v, v, dt) + buoyancy * dt
    v, p = fluid.make_incompressible(v, (), Solve('CG', 1e-3, x0=p))
    return v, s, p
30/7: v_trj, s_trj, p_trj = iterate(step, batch(time=NUM_TIME_STEPS), v0, smoke0, None, dt=DT, range=trange, substeps=3)
30/8:
# resampling the grid to a finer grid for noise transport
part_level = 2 # partition level for triangulation
tris_per_pix_dim = 2 ** (part_level-1) # triangles per pixel per dimension
tris_per_dim = tris_per_pix_dim * RES # triangles per dimension
vtx_per_dim = tris_per_pix_dim * RES + 1 # vertices per dimention
domain1=Box(x=(-BOUND/RES/tris_per_pix_dim/2, BOUND+BOUND/RES/tris_per_pix_dim/2),y=(-BOUND/RES/tris_per_pix_dim/2,BOUND+BOUND/RES/tris_per_pix_dim/2))
grid1 = CenteredGrid(0, math.extrapolation.BOUNDARY, domain1, x=vtx_per_dim, y=vtx_per_dim)
v_trj_rs = field.resample(value=v_trj, to=grid1)

vis.plot({'velocity': v_trj.time[-1], 'velocity resampled': v_trj_rs.time[-1]})
30/9:
# vertices & triangles (represented by vertex indices) generation
_, vertices = warp.vertices_gen(RES, RES, part_level)
reshaped_mesh_idxs = warp.mesh_idx_gen(RES, RES, part_level)
30/10: x.native(['b','vec','y','x']).shape
30/11:
# complete noise warping step function
def noise_step(vtx_pos, noise, up_level,mesh_idxs,vertices):
    res, _ = math.spatial(noise).sizes

    part_level = up_level
    resolution = res * (2 ** up_level)
    tris_per_row = 2 ** (part_level-1)

    noise_up = warp.upsample_noise_cond(noise, up_level)

    idx_y = mesh_idxs[:,0].int()
    idx_x = mesh_idxs[:,1].int()
    warped_coords = vtx_pos.native(['x','y','vector'])[idx_y, idx_x].fliplr()
    rast_out = warp.rasterize(warped_coords, vertices, res * tris_per_row, resolution, device)

    noise_warped = warp.transport_noise(noise_up, res, rast_out, part_level)

    return noise_warped

def noise_step_torch(vtx_pos, noise, up_level,mesh_idxs,vertices):
    batch_size, num_channel, res, _ = noise.shape

    part_level = up_level
    resolution = res * (2 ** up_level)
    tris_per_row = 2 ** (part_level-1)

    noise_up = warp.upsample_noise_cond(noise, up_level)

    idx_y = mesh_idxs[:,0].int()
    idx_x = mesh_idxs[:,1].int()
    warped_coords = vtx_pos.native(['x','y','vector'])[idx_y, idx_x].fliplr()
    rast_out = warp.rasterize(warped_coords, vertices, res * tris_per_row, resolution, device)

    noise_warped = warp.transport_noise_torch(noise_up, res, rast_out, part_level)

    return noise_warped
30/12:
# normalize the grid and corresponding vertex velocities for warping
grid_nmlzd = grid1.center * tris_per_dim / BOUND
v_trj_nmlzd = v_trj_rs * tris_per_dim / BOUND
30/13:
def calc_grid_pos(grid, vel, dt):
    grid_warp = grid - vel.values*dt
    return grid_warp

def gen_grids_warped(grid, vels, dt):
    # maps = []
    maps = [grid]
    for i in range(vels.time.size-1):
        grid_warp = calc_grid_pos(grid,vels.time[i+1],dt)
        maps.append(grid_warp)
    maps = math.stack(maps, batch('time'))
    return maps
30/14:
# generate the warped grid positions
grids_warped = gen_grids_warped(grid_nmlzd,v_trj_nmlzd,.5)
30/15:
# noise warping by the proposed method, no disclusion fix
noise_trj = [x]
x_in = x
for i in range(NUM_TIME_STEPS):
    # x_warped = noise_step(grids_warped.time[i+1], x_in, up_level, reshaped_mesh_idxs, vertices)

    x_warped = noise_step_torch(grids_warped.time[i+1], x_in, up_level, reshaped_mesh_idxs, vertices)
    x_warped = math.tensor(x_warped, batch(b=batch_size),math.channel(vec=num_channel),spatial(x=RES, y=RES))
    noise_trj.append(x_warped)
    x_in = x_warped
noise_trj = math.stack(noise_trj, batch('time'))
30/16:
# noise warping by the proposed method, no disclusion fix
noise_trj = [x]
x_in = x
for i in range(NUM_TIME_STEPS):
    # x_warped = noise_step(grids_warped.time[i+1], x_in, up_level, reshaped_mesh_idxs, vertices)

    x_warped = noise_step_torch(grids_warped.time[i+1], x_in, up_level, reshaped_mesh_idxs, vertices)
    x_warped = math.tensor(x_warped, batch(b=batch_size),math.channel(vec=num_channel),spatial(x=RES, y=RES))
    noise_trj.append(x_warped)
    x_in = x_warped
noise_trj = math.stack(noise_trj, batch('time'))
30/17:
# noise warping by the proposed method, filling empty cell with warping from previous frame
noise_trj_prev = [x]
x_in = x
for i in range(NUM_TIME_STEPS):
    # x_warped = noise_step(grids_warped.time[i+1], x_in, up_level, reshaped_mesh_idxs, vertices)
    # x_warped_prev = noise_step(grids_warped.time[i], x_in, up_level, reshaped_mesh_idxs, vertices)

    x_warped = noise_step_torch(grids_warped.time[i+1], x_in, up_level, reshaped_mesh_idxs, vertices)
    x_warped = math.tensor(x_warped, batch(b=batch_size),math.channel(vec=num_channel),spatial(x=RES, y=RES))
    x_warped_prev = noise_step_torch(grids_warped.time[i], x_in, up_level, reshaped_mesh_idxs, vertices)
    x_warped_prev = math.tensor(x_warped_prev, batch(b=batch_size),math.channel(vec=num_channel),spatial(x=RES, y=RES))
    
    x_warped = math.where(math.is_nan(x_warped),x_warped_prev,x_warped)
    noise_trj_prev.append(x_warped)
    x_in = x_warped
noise_trj_prev = math.stack(noise_trj_prev, batch('time'))
30/18:
# noise warping by the proposed method, filling empty cell with warping from last frame + random noise
noise_trj_prev_rand = [x]
x_in = x
for i in range(NUM_TIME_STEPS):
    # x_warped = noise_step(grids_warped.time[i+1], x_in, up_level, reshaped_mesh_idxs, vertices)
    # x_warped_prev = noise_step(grids_warped.time[i], x_in, up_level, reshaped_mesh_idxs, vertices)

    x_warped = noise_step_torch(grids_warped.time[i+1], x_in, up_level, reshaped_mesh_idxs, vertices)
    x_warped = math.tensor(x_warped, batch(b=batch_size),math.channel(vec=num_channel),spatial(x=RES, y=RES))
    x_warped_prev = noise_step_torch(grids_warped.time[i], x_in, up_level, reshaped_mesh_idxs, vertices)
    x_warped_prev = math.tensor(x_warped_prev, batch(b=batch_size),math.channel(vec=num_channel),spatial(x=RES, y=RES))

    x_warped = math.where(math.is_nan(x_warped),x_warped_prev,x_warped)
    x_warped = math.where(math.is_nan(x_warped), math.random_normal(x_warped.shape), x_warped)
    noise_trj_prev_rand.append(x_warped)
    x_in = x_warped
noise_trj_prev_rand = math.stack(noise_trj_prev_rand, batch('time'))
30/19:
# noise warping comparison
row1 = math.stack([noise_trj.b[0].vec[0],noise_trj_prev.b[0].vec[0]],batch('row'))
row2 = math.stack([noise_trj_prev_rand.b[0].vec[0],s_trj.values / s_trj.values.max],batch('row'))
ani = math.stack([row1,row2],batch('col'))
t1 = math.stack(['original dubbed noise','with previous frame'],batch('row'))
t2 = math.stack(['with previous frame + random noise', 'density'],batch('row'))
ttl = math.stack([t1,t2],batch('col'))

vis.plot(ani,row_dims='row',col_dims='col', frame_time=40,animate='time',size=(10,6),title=ttl)
30/20:
# complete noise warping step function
def noise_step(vtx_pos, noise, up_level,mesh_idxs,vertices):
    res, _ = math.spatial(noise).sizes

    part_level = up_level
    resolution = res * (2 ** up_level)
    tris_per_row = 2 ** (part_level-1)

    noise_up = warp.upsample_noise_cond(noise, up_level)

    idx_y = mesh_idxs[:,0].int()
    idx_x = mesh_idxs[:,1].int()
    warped_coords = vtx_pos.native(['x','y','vector'])[idx_y, idx_x].fliplr()
    rast_out = warp.rasterize(warped_coords, vertices, res * tris_per_row, resolution, device)

    noise_warped = warp.transport_noise(noise_up, res, rast_out, part_level)

    return noise_warped

def noise_step_torch(vtx_pos, noise, up_level,mesh_idxs,vertices):
    batch_size, num_channel, res, _ = noise.shape

    part_level = up_level
    resolution = res * (2 ** up_level)
    tris_per_row = 2 ** (part_level-1)

    noise_up = warp.upsample_noise_cond_torch(noise, up_level)

    idx_y = mesh_idxs[:,0].int()
    idx_x = mesh_idxs[:,1].int()
    warped_coords = vtx_pos.native(['x','y','vector'])[idx_y, idx_x].fliplr()
    rast_out = warp.rasterize(warped_coords, vertices, res * tris_per_row, resolution, device)

    noise_warped = warp.transport_noise_torch(noise_up, res, rast_out, part_level)

    return noise_warped
30/21:
# noise warping by the proposed method, no disclusion fix
noise_trj = [x]
x_in = x
for i in range(NUM_TIME_STEPS):
    # x_warped = noise_step(grids_warped.time[i+1], x_in, up_level, reshaped_mesh_idxs, vertices)

    x_warped = noise_step_torch(grids_warped.time[i+1], x_in, up_level, reshaped_mesh_idxs, vertices)
    x_warped = math.tensor(x_warped, batch(b=batch_size),math.channel(vec=num_channel),spatial(x=RES, y=RES))
    noise_trj.append(x_warped)
    x_in = x_warped
noise_trj = math.stack(noise_trj, batch('time'))
30/22:
# complete noise warping step function
def noise_step(vtx_pos, noise, up_level,mesh_idxs,vertices):
    res, _ = math.spatial(noise).sizes

    part_level = up_level
    resolution = res * (2 ** up_level)
    tris_per_row = 2 ** (part_level-1)

    noise_up = warp.upsample_noise_cond(noise, up_level)

    idx_y = mesh_idxs[:,0].int()
    idx_x = mesh_idxs[:,1].int()
    warped_coords = vtx_pos.native(['x','y','vector'])[idx_y, idx_x].fliplr()
    rast_out = warp.rasterize(warped_coords, vertices, res * tris_per_row, resolution, device)

    noise_warped = warp.transport_noise(noise_up, res, rast_out, part_level)

    return noise_warped

def noise_step_torch(vtx_pos, noise, up_level,mesh_idxs,vertices):
    batch_size, num_channel, res, _ = noise.shape

    part_level = up_level
    resolution = res * (2 ** up_level)
    tris_per_row = 2 ** (part_level-1)

    noise_up = warp.upsample_noise_cond_torch(noise.native(['b','vec','y','x']), up_level)

    idx_y = mesh_idxs[:,0].int()
    idx_x = mesh_idxs[:,1].int()
    warped_coords = vtx_pos.native(['x','y','vector'])[idx_y, idx_x].fliplr()
    rast_out = warp.rasterize(warped_coords, vertices, res * tris_per_row, resolution, device)

    noise_warped = warp.transport_noise_torch(noise_up, res, rast_out, part_level)

    return noise_warped
30/23:
# noise warping by the proposed method, no disclusion fix
noise_trj = [x]
x_in = x
for i in range(NUM_TIME_STEPS):
    # x_warped = noise_step(grids_warped.time[i+1], x_in, up_level, reshaped_mesh_idxs, vertices)

    x_warped = noise_step_torch(grids_warped.time[i+1], x_in, up_level, reshaped_mesh_idxs, vertices)
    x_warped = math.tensor(x_warped, batch(b=batch_size),math.channel(vec=num_channel),spatial(x=RES, y=RES))
    noise_trj.append(x_warped)
    x_in = x_warped
noise_trj = math.stack(noise_trj, batch('time'))
31/1:
# noise warping by the proposed method, filling empty cell with warping from previous frame
noise_trj_prev = [x]
x_in = x
for i in range(NUM_TIME_STEPS):
    # x_warped = noise_step(grids_warped.time[i+1], x_in, up_level, reshaped_mesh_idxs, vertices)
    # x_warped_prev = noise_step(grids_warped.time[i], x_in, up_level, reshaped_mesh_idxs, vertices)

    x_warped = noise_step_torch(grids_warped.time[i+1], x_in, up_level, reshaped_mesh_idxs, vertices)
    x_warped = math.tensor(x_warped, batch(b=batch_size),math.channel(vec=num_channel),spatial(x=RES, y=RES))
    x_warped_prev = noise_step_torch(grids_warped.time[i], x_in, up_level, reshaped_mesh_idxs, vertices)
    x_warped_prev = math.tensor(x_warped_prev, batch(b=batch_size),math.channel(vec=num_channel),spatial(x=RES, y=RES))
    
    x_warped = math.where(math.is_nan(x_warped),x_warped_prev,x_warped)
    noise_trj_prev.append(x_warped)
    x_in = x_warped
noise_trj_prev = math.stack(noise_trj_prev, batch('time'))
31/2:
# noise warping by the proposed method, no disclusion fix
noise_trj = [x]
x_in = x
for i in range(NUM_TIME_STEPS):
    # x_warped = noise_step(grids_warped.time[i+1], x_in, up_level, reshaped_mesh_idxs, vertices)

    x_warped = noise_step_torch(grids_warped.time[i+1], x_in, up_level, reshaped_mesh_idxs, vertices)
    x_warped = math.tensor(x_warped, batch(b=batch_size),math.channel(vec=num_channel),spatial(x=RES, y=RES))
    noise_trj.append(x_warped)
    x_in = x_warped
noise_trj = math.stack(noise_trj, batch('time'))
31/3:
from phi.torch.flow import *
from tqdm.notebook import trange
import torch
import matplotlib.pyplot as plt
31/4:
import warp
backend.default_backend().set_default_device('GPU')
torch.set_default_device('cuda')
31/5:
# fluid specification & initialization
RES = 32
BOUND = 100
NUM_TIME_STEPS = 50
DT = 0.5
domain = Box(x=BOUND, y=BOUND)
INFLOW_RATE = 0.5
BUOYANCY = 0.1
inflow = Sphere(x=50, y=9.5, radius=8)

v0 = StaggeredGrid(0, 0, domain, x=RES, y=RES)
smoke0 = CenteredGrid(0, math.extrapolation.BOUNDARY, domain, x=RES, y=RES)
31/6:
# noise specification & initialization
batch_size = 2
num_channel = 2
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
up_level = 2 # noise upsampling level
res_up = RES * (2 ** up_level)
31/7:
# conditional noise upsampling & visualization
x = math.random_normal(batch(b=batch_size),math.channel(vec=num_channel),spatial(x=RES, y=RES))
x_up = warp.upsample_noise_cond(x, up_level)
vis.plot({'noise':x.b[0].vec[0],'conditional upsampled noise':x_up.b[0].vec[0]})
31/8:
# fluid step function with smoke inflow
@jit_compile
def step(v, s, p, dt):
    s = advect.mac_cormack(s, v, dt) + INFLOW_RATE * resample(inflow, to=s, soft=True)
    buoyancy = resample(s * (0, BUOYANCY), to=v)
    v = advect.semi_lagrangian(v, v, dt) + buoyancy * dt
    v, p = fluid.make_incompressible(v, (), Solve('CG', 1e-3, x0=p))
    return v, s, p
31/9: v_trj, s_trj, p_trj = iterate(step, batch(time=NUM_TIME_STEPS), v0, smoke0, None, dt=DT, range=trange, substeps=3)
31/10:
# resampling the grid to a finer grid for noise transport
part_level = 2 # partition level for triangulation
tris_per_pix_dim = 2 ** (part_level-1) # triangles per pixel per dimension
tris_per_dim = tris_per_pix_dim * RES # triangles per dimension
vtx_per_dim = tris_per_pix_dim * RES + 1 # vertices per dimention
domain1=Box(x=(-BOUND/RES/tris_per_pix_dim/2, BOUND+BOUND/RES/tris_per_pix_dim/2),y=(-BOUND/RES/tris_per_pix_dim/2,BOUND+BOUND/RES/tris_per_pix_dim/2))
grid1 = CenteredGrid(0, math.extrapolation.BOUNDARY, domain1, x=vtx_per_dim, y=vtx_per_dim)
v_trj_rs = field.resample(value=v_trj, to=grid1)

vis.plot({'velocity': v_trj.time[-1], 'velocity resampled': v_trj_rs.time[-1]})
31/11:
# vertices & triangles (represented by vertex indices) generation
_, vertices = warp.vertices_gen(RES, RES, part_level)
reshaped_mesh_idxs = warp.mesh_idx_gen(RES, RES, part_level)
31/12:
# complete noise warping step function
def noise_step(vtx_pos, noise, up_level,mesh_idxs,vertices):
    res, _ = math.spatial(noise).sizes

    part_level = up_level
    resolution = res * (2 ** up_level)
    tris_per_row = 2 ** (part_level-1)

    noise_up = warp.upsample_noise_cond(noise, up_level)

    idx_y = mesh_idxs[:,0].int()
    idx_x = mesh_idxs[:,1].int()
    warped_coords = vtx_pos.native(['x','y','vector'])[idx_y, idx_x].fliplr()
    rast_out = warp.rasterize(warped_coords, vertices, res * tris_per_row, resolution, device)

    noise_warped = warp.transport_noise(noise_up, res, rast_out, part_level)

    return noise_warped

def noise_step_torch(vtx_pos, noise, up_level,mesh_idxs,vertices):
    batch_size, num_channel, res, _ = noise.shape

    part_level = up_level
    resolution = res * (2 ** up_level)
    tris_per_row = 2 ** (part_level-1)

    noise_up = warp.upsample_noise_cond_torch(noise, up_level)

    idx_y = mesh_idxs[:,0].int()
    idx_x = mesh_idxs[:,1].int()
    warped_coords = vtx_pos.native(['x','y','vector'])[idx_y, idx_x].fliplr()
    rast_out = warp.rasterize(warped_coords, vertices, res * tris_per_row, resolution, device)

    noise_warped = warp.transport_noise_torch(noise_up, res, rast_out, part_level)

    return noise_warped
31/13:
# normalize the grid and corresponding vertex velocities for warping
grid_nmlzd = grid1.center * tris_per_dim / BOUND
v_trj_nmlzd = v_trj_rs * tris_per_dim / BOUND
31/14:
def calc_grid_pos(grid, vel, dt):
    grid_warp = grid - vel.values*dt
    return grid_warp

def gen_grids_warped(grid, vels, dt):
    # maps = []
    maps = [grid]
    for i in range(vels.time.size-1):
        grid_warp = calc_grid_pos(grid,vels.time[i+1],dt)
        maps.append(grid_warp)
    maps = math.stack(maps, batch('time'))
    return maps
31/15:
# generate the warped grid positions
grids_warped = gen_grids_warped(grid_nmlzd,v_trj_nmlzd,.5)
31/16:
# noise warping by the proposed method, no disclusion fix
noise_trj = [x]
x_in = x
for i in range(NUM_TIME_STEPS):
    # x_warped = noise_step(grids_warped.time[i+1], x_in, up_level, reshaped_mesh_idxs, vertices)

    x_warped = noise_step_torch(grids_warped.time[i+1], x_in, up_level, reshaped_mesh_idxs, vertices)
    x_warped = math.tensor(x_warped, batch(b=batch_size),math.channel(vec=num_channel),spatial(x=RES, y=RES))
    noise_trj.append(x_warped)
    x_in = x_warped
noise_trj = math.stack(noise_trj, batch('time'))
31/17:
# noise warping by the proposed method, no disclusion fix
noise_trj = [x]
x_in = x
for i in range(NUM_TIME_STEPS):
    # x_warped = noise_step(grids_warped.time[i+1], x_in, up_level, reshaped_mesh_idxs, vertices)

    x_warped = noise_step_torch(grids_warped.time[i+1], x_in, up_level, reshaped_mesh_idxs, vertices)
    x_warped = math.tensor(x_warped, batch(b=batch_size),math.channel(vec=num_channel),spatial(x=RES, y=RES))
    noise_trj.append(x_warped)
    x_in = x_warped
noise_trj = math.stack(noise_trj, batch('time'))
31/18:
# noise warping by the proposed method, no disclusion fix
noise_trj = [x]
x_in = x
for i in range(NUM_TIME_STEPS):
    # x_warped = noise_step(grids_warped.time[i+1], x_in, up_level, reshaped_mesh_idxs, vertices)

    x_warped = noise_step_torch(grids_warped.time[i+1], x_in.native('b','vec','y','x'), up_level, reshaped_mesh_idxs, vertices)
    x_warped = math.tensor(x_warped, batch(b=batch_size),math.channel(vec=num_channel),spatial(x=RES, y=RES))
    noise_trj.append(x_warped)
    x_in = x_warped
noise_trj = math.stack(noise_trj, batch('time'))
31/19:
# noise warping by the proposed method, no disclusion fix
noise_trj = [x]
x_in = x
for i in range(NUM_TIME_STEPS):
    # x_warped = noise_step(grids_warped.time[i+1], x_in, up_level, reshaped_mesh_idxs, vertices)

    x_warped = noise_step_torch(grids_warped.time[i+1], x_in.native(['b','vec','y','x']), up_level, reshaped_mesh_idxs, vertices)
    x_warped = math.tensor(x_warped, batch(b=batch_size),math.channel(vec=num_channel),spatial(x=RES, y=RES))
    noise_trj.append(x_warped)
    x_in = x_warped
noise_trj = math.stack(noise_trj, batch('time'))
32/1:
from phi.torch.flow import *
from tqdm.notebook import trange
import torch
import matplotlib.pyplot as plt
32/2:
import warp
backend.default_backend().set_default_device('GPU')
torch.set_default_device('cuda')
32/3:
# fluid specification & initialization
RES = 32
BOUND = 100
NUM_TIME_STEPS = 50
DT = 0.5
domain = Box(x=BOUND, y=BOUND)
INFLOW_RATE = 0.5
BUOYANCY = 0.1
inflow = Sphere(x=50, y=9.5, radius=8)

v0 = StaggeredGrid(0, 0, domain, x=RES, y=RES)
smoke0 = CenteredGrid(0, math.extrapolation.BOUNDARY, domain, x=RES, y=RES)
32/4:
# noise specification & initialization
batch_size = 2
num_channel = 2
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
up_level = 2 # noise upsampling level
res_up = RES * (2 ** up_level)
32/5:
# conditional noise upsampling & visualization
x = math.random_normal(batch(b=batch_size),math.channel(vec=num_channel),spatial(x=RES, y=RES))
x_up = warp.upsample_noise_cond(x, up_level)
vis.plot({'noise':x.b[0].vec[0],'conditional upsampled noise':x_up.b[0].vec[0]})
32/6:
# fluid step function with smoke inflow
@jit_compile
def step(v, s, p, dt):
    s = advect.mac_cormack(s, v, dt) + INFLOW_RATE * resample(inflow, to=s, soft=True)
    buoyancy = resample(s * (0, BUOYANCY), to=v)
    v = advect.semi_lagrangian(v, v, dt) + buoyancy * dt
    v, p = fluid.make_incompressible(v, (), Solve('CG', 1e-3, x0=p))
    return v, s, p
32/7: v_trj, s_trj, p_trj = iterate(step, batch(time=NUM_TIME_STEPS), v0, smoke0, None, dt=DT, range=trange, substeps=3)
32/8:
# resampling the grid to a finer grid for noise transport
part_level = 2 # partition level for triangulation
tris_per_pix_dim = 2 ** (part_level-1) # triangles per pixel per dimension
tris_per_dim = tris_per_pix_dim * RES # triangles per dimension
vtx_per_dim = tris_per_pix_dim * RES + 1 # vertices per dimention
domain1=Box(x=(-BOUND/RES/tris_per_pix_dim/2, BOUND+BOUND/RES/tris_per_pix_dim/2),y=(-BOUND/RES/tris_per_pix_dim/2,BOUND+BOUND/RES/tris_per_pix_dim/2))
grid1 = CenteredGrid(0, math.extrapolation.BOUNDARY, domain1, x=vtx_per_dim, y=vtx_per_dim)
v_trj_rs = field.resample(value=v_trj, to=grid1)

vis.plot({'velocity': v_trj.time[-1], 'velocity resampled': v_trj_rs.time[-1]})
32/9:
# vertices & triangles (represented by vertex indices) generation
_, vertices = warp.vertices_gen(RES, RES, part_level)
reshaped_mesh_idxs = warp.mesh_idx_gen(RES, RES, part_level)
32/10:
# complete noise warping step function
def noise_step(vtx_pos, noise, up_level,mesh_idxs,vertices):
    res, _ = math.spatial(noise).sizes

    part_level = up_level
    resolution = res * (2 ** up_level)
    tris_per_row = 2 ** (part_level-1)

    noise_up = warp.upsample_noise_cond(noise, up_level)

    idx_y = mesh_idxs[:,0].int()
    idx_x = mesh_idxs[:,1].int()
    warped_coords = vtx_pos.native(['x','y','vector'])[idx_y, idx_x].fliplr()
    rast_out = warp.rasterize(warped_coords, vertices, res * tris_per_row, resolution, device)

    noise_warped = warp.transport_noise(noise_up, res, rast_out, part_level)

    return noise_warped

def noise_step_torch(vtx_pos, noise, up_level,mesh_idxs,vertices):
    batch_size, num_channel, res, _ = noise.shape

    part_level = up_level
    resolution = res * (2 ** up_level)
    tris_per_row = 2 ** (part_level-1)

    noise_up = warp.upsample_noise_cond_torch(noise, up_level)

    idx_y = mesh_idxs[:,0].int()
    idx_x = mesh_idxs[:,1].int()
    warped_coords = vtx_pos.native(['x','y','vector'])[idx_y, idx_x].fliplr()
    rast_out = warp.rasterize(warped_coords, vertices, res * tris_per_row, resolution, device)

    noise_warped = warp.transport_noise_torch(noise_up, res, rast_out, part_level)

    return noise_warped
32/11:
# normalize the grid and corresponding vertex velocities for warping
grid_nmlzd = grid1.center * tris_per_dim / BOUND
v_trj_nmlzd = v_trj_rs * tris_per_dim / BOUND
32/12:
def calc_grid_pos(grid, vel, dt):
    grid_warp = grid - vel.values*dt
    return grid_warp

def gen_grids_warped(grid, vels, dt):
    # maps = []
    maps = [grid]
    for i in range(vels.time.size-1):
        grid_warp = calc_grid_pos(grid,vels.time[i+1],dt)
        maps.append(grid_warp)
    maps = math.stack(maps, batch('time'))
    return maps
32/13:
# generate the warped grid positions
grids_warped = gen_grids_warped(grid_nmlzd,v_trj_nmlzd,.5)
32/14:
# noise warping by the proposed method, no disclusion fix
noise_trj = [x]
x_in = x
for i in range(NUM_TIME_STEPS):
    # x_warped = noise_step(grids_warped.time[i+1], x_in, up_level, reshaped_mesh_idxs, vertices)

    x_warped = noise_step_torch(grids_warped.time[i+1], x_in.native(['b','vec','y','x']), up_level, reshaped_mesh_idxs, vertices)
    x_warped = math.tensor(x_warped, batch(b=batch_size),math.channel(vec=num_channel),spatial(x=RES, y=RES))
    noise_trj.append(x_warped)
    x_in = x_warped
noise_trj = math.stack(noise_trj, batch('time'))
33/1:
from phi.torch.flow import *
from tqdm.notebook import trange
import torch
import matplotlib.pyplot as plt
33/2:
import warp
backend.default_backend().set_default_device('GPU')
torch.set_default_device('cuda')
33/3:
# fluid specification & initialization
RES = 32
BOUND = 100
NUM_TIME_STEPS = 25
DT = 0.5
domain = Box(x=BOUND, y=BOUND)
INFLOW_RATE = 0.5
BUOYANCY = 0.1
inflow = Sphere(x=50, y=9.5, radius=8)

v0 = StaggeredGrid(0, 0, domain, x=RES, y=RES)
smoke0 = CenteredGrid(0, math.extrapolation.BOUNDARY, domain, x=RES, y=RES)
33/4:
# noise specification & initialization
batch_size = 2
num_channel = 2
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
up_level = 2 # noise upsampling level
res_up = RES * (2 ** up_level)
33/5:
# conditional noise upsampling & visualization
x = math.random_normal(batch(b=batch_size),math.channel(vec=num_channel),spatial(x=RES, y=RES))
x_up = warp.upsample_noise_cond(x, up_level)
vis.plot({'noise':x.b[0].vec[0],'conditional upsampled noise':x_up.b[0].vec[0]})
33/6:
# fluid step function with smoke inflow
@jit_compile
def step(v, s, p, dt):
    s = advect.mac_cormack(s, v, dt) + INFLOW_RATE * resample(inflow, to=s, soft=True)
    buoyancy = resample(s * (0, BUOYANCY), to=v)
    v = advect.semi_lagrangian(v, v, dt) + buoyancy * dt
    v, p = fluid.make_incompressible(v, (), Solve('CG', 1e-3, x0=p))
    return v, s, p
33/7: v_trj, s_trj, p_trj = iterate(step, batch(time=NUM_TIME_STEPS), v0, smoke0, None, dt=DT, range=trange, substeps=3)
33/8:
# resampling the grid to a finer grid for noise transport
part_level = 2 # partition level for triangulation
tris_per_pix_dim = 2 ** (part_level-1) # triangles per pixel per dimension
tris_per_dim = tris_per_pix_dim * RES # triangles per dimension
vtx_per_dim = tris_per_pix_dim * RES + 1 # vertices per dimention
domain1=Box(x=(-BOUND/RES/tris_per_pix_dim/2, BOUND+BOUND/RES/tris_per_pix_dim/2),y=(-BOUND/RES/tris_per_pix_dim/2,BOUND+BOUND/RES/tris_per_pix_dim/2))
grid1 = CenteredGrid(0, math.extrapolation.BOUNDARY, domain1, x=vtx_per_dim, y=vtx_per_dim)
v_trj_rs = field.resample(value=v_trj, to=grid1)

vis.plot({'velocity': v_trj.time[-1], 'velocity resampled': v_trj_rs.time[-1]})
33/9:
# vertices & triangles (represented by vertex indices) generation
_, vertices = warp.vertices_gen(RES, RES, part_level)
reshaped_mesh_idxs = warp.mesh_idx_gen(RES, RES, part_level)
33/10:
# complete noise warping step function
def noise_step(vtx_pos, noise, up_level,mesh_idxs,vertices):
    res, _ = math.spatial(noise).sizes

    part_level = up_level
    resolution = res * (2 ** up_level)
    tris_per_row = 2 ** (part_level-1)

    noise_up = warp.upsample_noise_cond(noise, up_level)

    idx_y = mesh_idxs[:,0].int()
    idx_x = mesh_idxs[:,1].int()
    warped_coords = vtx_pos.native(['x','y','vector'])[idx_y, idx_x].fliplr()
    rast_out = warp.rasterize(warped_coords, vertices, res * tris_per_row, resolution, device)

    noise_warped = warp.transport_noise(noise_up, res, rast_out, part_level)

    return noise_warped

def noise_step_torch(vtx_pos, noise, up_level,mesh_idxs,vertices):
    batch_size, num_channel, res, _ = noise.shape

    part_level = up_level
    resolution = res * (2 ** up_level)
    tris_per_row = 2 ** (part_level-1)

    noise_up = warp.upsample_noise_cond_torch(noise, up_level)

    idx_y = mesh_idxs[:,0].int()
    idx_x = mesh_idxs[:,1].int()
    warped_coords = vtx_pos.native(['x','y','vector'])[idx_y, idx_x].fliplr()
    rast_out = warp.rasterize(warped_coords, vertices, res * tris_per_row, resolution, device)

    noise_warped = warp.transport_noise_torch(noise_up, res, rast_out, part_level)

    return noise_warped
33/11:
# normalize the grid and corresponding vertex velocities for warping
grid_nmlzd = grid1.center * tris_per_dim / BOUND
v_trj_nmlzd = v_trj_rs * tris_per_dim / BOUND
33/12:
def calc_grid_pos(grid, vel, dt):
    grid_warp = grid - vel.values*dt
    return grid_warp

def gen_grids_warped(grid, vels, dt):
    # maps = []
    maps = [grid]
    for i in range(vels.time.size-1):
        grid_warp = calc_grid_pos(grid,vels.time[i+1],dt)
        maps.append(grid_warp)
    maps = math.stack(maps, batch('time'))
    return maps
33/13:
# generate the warped grid positions
grids_warped = gen_grids_warped(grid_nmlzd,v_trj_nmlzd,.5)
33/14:
# noise warping by the proposed method, no disclusion fix
noise_trj = [x]
x_in = x
for i in range(NUM_TIME_STEPS):
    # x_warped = noise_step(grids_warped.time[i+1], x_in, up_level, reshaped_mesh_idxs, vertices)

    x_warped = noise_step_torch(grids_warped.time[i+1], x_in.native(['b','vec','y','x']), up_level, reshaped_mesh_idxs, vertices)
    x_warped = math.tensor(x_warped, batch(b=batch_size),math.channel(vec=num_channel),spatial(x=RES, y=RES))
    noise_trj.append(x_warped)
    x_in = x_warped
noise_trj = math.stack(noise_trj, batch('time'))
33/15:
# noise warping by the proposed method, filling empty cell with warping from previous frame
noise_trj_prev = [x]
x_in = x
for i in range(NUM_TIME_STEPS):
    # x_warped = noise_step(grids_warped.time[i+1], x_in, up_level, reshaped_mesh_idxs, vertices)
    # x_warped_prev = noise_step(grids_warped.time[i], x_in, up_level, reshaped_mesh_idxs, vertices)

    x_warped = noise_step_torch(grids_warped.time[i+1], x_in.native(['b','vec','y','x']), up_level, reshaped_mesh_idxs, vertices)
    x_warped = math.tensor(x_warped, batch(b=batch_size),math.channel(vec=num_channel),spatial(x=RES, y=RES))
    x_warped_prev = noise_step_torch(grids_warped.time[i], x_in.native(['b','vec','y','x']), up_level, reshaped_mesh_idxs, vertices)
    x_warped_prev = math.tensor(x_warped_prev, batch(b=batch_size),math.channel(vec=num_channel),spatial(x=RES, y=RES))
    
    x_warped = math.where(math.is_nan(x_warped),x_warped_prev,x_warped)
    noise_trj_prev.append(x_warped)
    x_in = x_warped
noise_trj_prev = math.stack(noise_trj_prev, batch('time'))
33/16:
# noise warping by the proposed method, filling empty cell with warping from last frame + random noise
noise_trj_prev_rand = [x]
x_in = x
for i in range(NUM_TIME_STEPS):
    # x_warped = noise_step(grids_warped.time[i+1], x_in, up_level, reshaped_mesh_idxs, vertices)
    # x_warped_prev = noise_step(grids_warped.time[i], x_in, up_level, reshaped_mesh_idxs, vertices)

    x_warped = noise_step_torch(grids_warped.time[i+1], x_in.native(['b','vec','y','x']), up_level, reshaped_mesh_idxs, vertices)
    x_warped = math.tensor(x_warped, batch(b=batch_size),math.channel(vec=num_channel),spatial(x=RES, y=RES))
    x_warped_prev = noise_step_torch(grids_warped.time[i], x_in.native(['b','vec','y','x']), up_level, reshaped_mesh_idxs, vertices)
    x_warped_prev = math.tensor(x_warped_prev, batch(b=batch_size),math.channel(vec=num_channel),spatial(x=RES, y=RES))

    x_warped = math.where(math.is_nan(x_warped),x_warped_prev,x_warped)
    x_warped = math.where(math.is_nan(x_warped), math.random_normal(x_warped.shape), x_warped)
    noise_trj_prev_rand.append(x_warped)
    x_in = x_warped
noise_trj_prev_rand = math.stack(noise_trj_prev_rand, batch('time'))
33/17:
# noise warping comparison
row1 = math.stack([noise_trj.b[0].vec[0],noise_trj_prev.b[0].vec[0]],batch('row'))
row2 = math.stack([noise_trj_prev_rand.b[0].vec[0],s_trj.values / s_trj.values.max],batch('row'))
ani = math.stack([row1,row2],batch('col'))
t1 = math.stack(['original dubbed noise','with previous frame'],batch('row'))
t2 = math.stack(['with previous frame + random noise', 'density'],batch('row'))
ttl = math.stack([t1,t2],batch('col'))

vis.plot(ani,row_dims='row',col_dims='col', frame_time=40,animate='time',size=(10,6),title=ttl)
33/18:
# noise warping by the proposed method, no disclusion fix
noise_trj = [x]
x_in = x
for i in range(NUM_TIME_STEPS):
    # x_warped = noise_step(grids_warped.time[i+1], x_in, up_level, reshaped_mesh_idxs, vertices)

    x_warped = noise_step_torch(grids_warped.time[i+1], x_in.native(['b','vec','x','y']), up_level, reshaped_mesh_idxs, vertices)
    x_warped = math.tensor(x_warped, batch(b=batch_size),math.channel(vec=num_channel),spatial(x=RES, y=RES))
    noise_trj.append(x_warped)
    x_in = x_warped
noise_trj = math.stack(noise_trj, batch('time'))
33/19:
# noise warping by the proposed method, filling empty cell with warping from previous frame
noise_trj_prev = [x]
x_in = x
for i in range(NUM_TIME_STEPS):
    # x_warped = noise_step(grids_warped.time[i+1], x_in, up_level, reshaped_mesh_idxs, vertices)
    # x_warped_prev = noise_step(grids_warped.time[i], x_in, up_level, reshaped_mesh_idxs, vertices)

    x_warped = noise_step_torch(grids_warped.time[i+1], x_in.native(['b','vec','y','x']), up_level, reshaped_mesh_idxs, vertices)
    x_warped = math.tensor(x_warped, batch(b=batch_size),math.channel(vec=num_channel),spatial(x=RES, y=RES))
    x_warped_prev = noise_step_torch(grids_warped.time[i], x_in.native(['b','vec','y','x']), up_level, reshaped_mesh_idxs, vertices)
    x_warped_prev = math.tensor(x_warped_prev, batch(b=batch_size),math.channel(vec=num_channel),spatial(x=RES, y=RES))
    
    x_warped = math.where(math.is_nan(x_warped),x_warped_prev,x_warped)
    noise_trj_prev.append(x_warped)
    x_in = x_warped
noise_trj_prev = math.stack(noise_trj_prev, batch('time'))
33/20:
# noise warping by the proposed method, filling empty cell with warping from last frame + random noise
noise_trj_prev_rand = [x]
x_in = x
for i in range(NUM_TIME_STEPS):
    # x_warped = noise_step(grids_warped.time[i+1], x_in, up_level, reshaped_mesh_idxs, vertices)
    # x_warped_prev = noise_step(grids_warped.time[i], x_in, up_level, reshaped_mesh_idxs, vertices)

    x_warped = noise_step_torch(grids_warped.time[i+1], x_in.native(['b','vec','y','x']), up_level, reshaped_mesh_idxs, vertices)
    x_warped = math.tensor(x_warped, batch(b=batch_size),math.channel(vec=num_channel),spatial(x=RES, y=RES))
    x_warped_prev = noise_step_torch(grids_warped.time[i], x_in.native(['b','vec','y','x']), up_level, reshaped_mesh_idxs, vertices)
    x_warped_prev = math.tensor(x_warped_prev, batch(b=batch_size),math.channel(vec=num_channel),spatial(x=RES, y=RES))

    x_warped = math.where(math.is_nan(x_warped),x_warped_prev,x_warped)
    x_warped = math.where(math.is_nan(x_warped), math.random_normal(x_warped.shape), x_warped)
    noise_trj_prev_rand.append(x_warped)
    x_in = x_warped
noise_trj_prev_rand = math.stack(noise_trj_prev_rand, batch('time'))
33/21:
# noise warping comparison
row1 = math.stack([noise_trj.b[0].vec[0],noise_trj_prev.b[0].vec[0]],batch('row'))
row2 = math.stack([noise_trj_prev_rand.b[0].vec[0],s_trj.values / s_trj.values.max],batch('row'))
ani = math.stack([row1,row2],batch('col'))
t1 = math.stack(['original dubbed noise','with previous frame'],batch('row'))
t2 = math.stack(['with previous frame + random noise', 'density'],batch('row'))
ttl = math.stack([t1,t2],batch('col'))

vis.plot(ani,row_dims='row',col_dims='col', frame_time=40,animate='time',size=(10,6),title=ttl)
34/1:
from phi.torch.flow import *
from tqdm.notebook import trange
import torch
import matplotlib.pyplot as plt
34/2:
import warp
backend.default_backend().set_default_device('GPU')
torch.set_default_device('cuda')
34/3:
# fluid specification & initialization
RES = 128
BOUND = 100
NUM_TIME_STEPS = 200
DT = 0.5
domain = Box(x=BOUND, y=BOUND)
INFLOW_RATE = 0.5
BUOYANCY = 0.1
inflow = Sphere(x=50, y=9.5, radius=8)

v0 = StaggeredGrid(0, 0, domain, x=RES, y=RES)
smoke0 = CenteredGrid(0, math.extrapolation.BOUNDARY, domain, x=RES, y=RES)
34/4:
# noise specification & initialization
batch_size = 2
num_channel = 2
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
up_level = 2 # noise upsampling level
res_up = RES * (2 ** up_level)
34/5:
# conditional noise upsampling & visualization
x = math.random_normal(batch(b=batch_size),math.channel(vec=num_channel),spatial(x=RES, y=RES))
x_up = warp.upsample_noise_cond(x, up_level)
vis.plot({'noise':x.b[0].vec[0],'conditional upsampled noise':x_up.b[0].vec[0]})
34/6:
# fluid step function with smoke inflow
@jit_compile
def step(v, s, p, dt):
    s = advect.mac_cormack(s, v, dt) + INFLOW_RATE * resample(inflow, to=s, soft=True)
    buoyancy = resample(s * (0, BUOYANCY), to=v)
    v = advect.semi_lagrangian(v, v, dt) + buoyancy * dt
    v, p = fluid.make_incompressible(v, (), Solve('CG', 1e-3, x0=p))
    return v, s, p
34/7: v_trj, s_trj, p_trj = iterate(step, batch(time=NUM_TIME_STEPS), v0, smoke0, None, dt=DT, range=trange, substeps=3)
34/8:
# resampling the grid to a finer grid for noise transport
part_level = 2 # partition level for triangulation
tris_per_pix_dim = 2 ** (part_level-1) # triangles per pixel per dimension
tris_per_dim = tris_per_pix_dim * RES # triangles per dimension
vtx_per_dim = tris_per_pix_dim * RES + 1 # vertices per dimention
domain1=Box(x=(-BOUND/RES/tris_per_pix_dim/2, BOUND+BOUND/RES/tris_per_pix_dim/2),y=(-BOUND/RES/tris_per_pix_dim/2,BOUND+BOUND/RES/tris_per_pix_dim/2))
grid1 = CenteredGrid(0, math.extrapolation.BOUNDARY, domain1, x=vtx_per_dim, y=vtx_per_dim)
v_trj_rs = field.resample(value=v_trj, to=grid1)

vis.plot({'velocity': v_trj.time[-1], 'velocity resampled': v_trj_rs.time[-1]})
34/9:
# vertices & triangles (represented by vertex indices) generation
_, vertices = warp.vertices_gen(RES, RES, part_level)
reshaped_mesh_idxs = warp.mesh_idx_gen(RES, RES, part_level)
34/10:
# complete noise warping step function
def noise_step(vtx_pos, noise, up_level,mesh_idxs,vertices):
    res, _ = math.spatial(noise).sizes

    part_level = up_level
    resolution = res * (2 ** up_level)
    tris_per_row = 2 ** (part_level-1)

    noise_up = warp.upsample_noise_cond(noise, up_level)

    idx_y = mesh_idxs[:,0].int()
    idx_x = mesh_idxs[:,1].int()
    warped_coords = vtx_pos.native(['x','y','vector'])[idx_y, idx_x].fliplr()
    rast_out = warp.rasterize(warped_coords, vertices, res * tris_per_row, resolution, device)

    noise_warped = warp.transport_noise(noise_up, res, rast_out, part_level)

    return noise_warped

def noise_step_torch(vtx_pos, noise, up_level,mesh_idxs,vertices):
    batch_size, num_channel, res, _ = noise.shape

    part_level = up_level
    resolution = res * (2 ** up_level)
    tris_per_row = 2 ** (part_level-1)

    noise_up = warp.upsample_noise_cond_torch(noise, up_level)

    idx_y = mesh_idxs[:,0].int()
    idx_x = mesh_idxs[:,1].int()
    warped_coords = vtx_pos.native(['x','y','vector'])[idx_y, idx_x].fliplr()
    rast_out = warp.rasterize(warped_coords, vertices, res * tris_per_row, resolution, device)

    noise_warped = warp.transport_noise_torch(noise_up, res, rast_out, part_level)

    return noise_warped
34/11:
# normalize the grid and corresponding vertex velocities for warping
grid_nmlzd = grid1.center * tris_per_dim / BOUND
v_trj_nmlzd = v_trj_rs * tris_per_dim / BOUND
34/12:
def calc_grid_pos(grid, vel, dt):
    grid_warp = grid - vel.values*dt
    return grid_warp

def gen_grids_warped(grid, vels, dt):
    # maps = []
    maps = [grid]
    for i in range(vels.time.size-1):
        grid_warp = calc_grid_pos(grid,vels.time[i+1],dt)
        maps.append(grid_warp)
    maps = math.stack(maps, batch('time'))
    return maps
34/13:
# generate the warped grid positions
grids_warped = gen_grids_warped(grid_nmlzd,v_trj_nmlzd,.5)
34/14:
# noise warping by the proposed method, no disclusion fix
noise_trj = [x]
x_in = x
for i in range(NUM_TIME_STEPS):
    # x_warped = noise_step(grids_warped.time[i+1], x_in, up_level, reshaped_mesh_idxs, vertices)

    x_warped = noise_step_torch(grids_warped.time[i+1], x_in.native(['b','vec','x','y']), up_level, reshaped_mesh_idxs, vertices)
    x_warped = math.tensor(x_warped, batch(b=batch_size),math.channel(vec=num_channel),spatial(x=RES, y=RES))
    noise_trj.append(x_warped)
    x_in = x_warped
noise_trj = math.stack(noise_trj, batch('time'))
34/15:
# noise warping by the proposed method, filling empty cell with warping from previous frame
noise_trj_prev = [x]
x_in = x
for i in range(NUM_TIME_STEPS):
    # x_warped = noise_step(grids_warped.time[i+1], x_in, up_level, reshaped_mesh_idxs, vertices)
    # x_warped_prev = noise_step(grids_warped.time[i], x_in, up_level, reshaped_mesh_idxs, vertices)

    x_warped = noise_step_torch(grids_warped.time[i+1], x_in.native(['b','vec','x','y']), up_level, reshaped_mesh_idxs, vertices)
    x_warped = math.tensor(x_warped, batch(b=batch_size),math.channel(vec=num_channel),spatial(x=RES, y=RES))
    x_warped_prev = noise_step_torch(grids_warped.time[i], x_in.native(['b','vec','x','y']), up_level, reshaped_mesh_idxs, vertices)
    x_warped_prev = math.tensor(x_warped_prev, batch(b=batch_size),math.channel(vec=num_channel),spatial(x=RES, y=RES))
    
    x_warped = math.where(math.is_nan(x_warped),x_warped_prev,x_warped)
    noise_trj_prev.append(x_warped)
    x_in = x_warped
noise_trj_prev = math.stack(noise_trj_prev, batch('time'))
34/16:
# noise warping by the proposed method, filling empty cell with warping from last frame + random noise
noise_trj_prev_rand = [x]
x_in = x
for i in range(NUM_TIME_STEPS):
    # x_warped = noise_step(grids_warped.time[i+1], x_in, up_level, reshaped_mesh_idxs, vertices)
    # x_warped_prev = noise_step(grids_warped.time[i], x_in, up_level, reshaped_mesh_idxs, vertices)

    x_warped = noise_step_torch(grids_warped.time[i+1], x_in.native(['b','vec','x','y']), up_level, reshaped_mesh_idxs, vertices)
    x_warped = math.tensor(x_warped, batch(b=batch_size),math.channel(vec=num_channel),spatial(x=RES, y=RES))
    x_warped_prev = noise_step_torch(grids_warped.time[i], x_in.native(['b','vec','x','y']), up_level, reshaped_mesh_idxs, vertices)
    x_warped_prev = math.tensor(x_warped_prev, batch(b=batch_size),math.channel(vec=num_channel),spatial(x=RES, y=RES))

    x_warped = math.where(math.is_nan(x_warped),x_warped_prev,x_warped)
    x_warped = math.where(math.is_nan(x_warped), math.random_normal(x_warped.shape), x_warped)
    noise_trj_prev_rand.append(x_warped)
    x_in = x_warped
noise_trj_prev_rand = math.stack(noise_trj_prev_rand, batch('time'))
34/17:
# noise warping comparison
row1 = math.stack([noise_trj.b[0].vec[0],noise_trj_prev.b[0].vec[0]],batch('row'))
row2 = math.stack([noise_trj_prev_rand.b[0].vec[0],s_trj.values / s_trj.values.max],batch('row'))
ani = math.stack([row1,row2],batch('col'))
t1 = math.stack(['original dubbed noise','with previous frame'],batch('row'))
t2 = math.stack(['with previous frame + random noise', 'density'],batch('row'))
ttl = math.stack([t1,t2],batch('col'))

vis.plot(ani,row_dims='row',col_dims='col', frame_time=40,animate='time',size=(10,6),title=ttl)
19/42:
!wget -nc "https://dataserv.ub.tum.de/s/m1734798.001/download?path=/&files=128_tra_small.zip" -O data/128_tra_small.zip --no-check-certificate 
!unzip -nq data/128_tra_small.zip -d data
!wget -nc "https://dataserv.ub.tum.de/s/m1734798.001/download?path=/&files=checkpoints_acdm_tra.zip" -O models/checkpoints_acdm_tra.zip --no-check-certificate 
!unzip -nq models/checkpoints_acdm_tra.zip -d models
19/43:
try:
    import google.colab  # only to ensure that we are inside colab
    !pip install einops
except ImportError:
    print("This notebook is running locally, please follow the ACDM installation instructions first, then continue with the cell below.")
    pass
19/44:
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader, SequentialSampler, RandomSampler

from einops import rearrange
from functools import partial

import matplotlib.pyplot as plt
import numpy as np

import math
import os, json
from typing import List,Tuple,Dict
19/45:
class TurbulenceDataset(Dataset):
    """Data set for turbulence and wavelet noise data

    Args:
        name: name of the dataset
        dataDirs: list of paths to data directories
        filterTop: filter for top level folder names (e.g. different types of data)
        excludeFilterTop: mode for filterTop (exclude or include)
        filterSim: filter simulations by min and max (min inclusive, max exclusive)
        excludefilterSim: mode for filterSim (exclude or include)
        filterFrame: mandatory filter for simulation frames by min and max (min inclusive, max exclusive)
        sequenceLength: number of frames to group into a sequence and number of frames to omit in between
        randSeqOffset: randomizes the starting frame of each sequence
        simFields: list of simulation fields to include (vel is always included) ["dens", "pres"]
        simParams: list of simulation parameters to include ["rey", "mach"]
        printLevel: print mode for contents of the dataset ["none", "top", "sim", "full"]
    """

    def __init__(self, name:str, dataDirs:List[str], filterTop:List[str], excludeFilterTop:bool=False, filterSim:List[Tuple[int, int]]=[],
                excludefilterSim:bool=False, filterFrame:List[Tuple[int, int]]=[], sequenceLength:List[Tuple[int, int]]=[],
                randSeqOffset:bool=False, simFields:List[str]=[], simParams:List[str]=[], printLevel:str="none"):

        self.transform = None
        self.name = name
        self.dataDirs = dataDirs
        self.filterTop = filterTop
        self.excludeFilterTop = excludeFilterTop
        self.filterSim = filterSim
        self.excludefilterSim = excludefilterSim
        self.filterFrame = filterFrame
        self.sequenceLength = sequenceLength
        self.randSeqOffset = randSeqOffset
        self.simFields = ["velocity"]
        if "dens" in simFields:
            self.simFields += ["density"]
        if "pres" in simFields:
            self.simFields += ["pressure"]

        self.simParams = simParams
        self.printLevel = printLevel

        self.summaryPrint = []
        self.summaryPrint += ["Dataset " + name + " at " + str(dataDirs)]
        self.summaryPrint += [self.getFilterInfoString()]

        # BUILD FULL FILE LIST
        self.dataPaths = []
        self.dataPathModes = []

        for dataDir in dataDirs:
            topDirs = os.listdir(dataDir)
            topDirs.sort()

            # top level folders
            for topDir in topDirs:
                if filterTop:
                    # continue when excluding or including according to filter
                    if excludeFilterTop == any( item in topDir for item in filterTop ):
                        continue

                match = -1
                # compute matching top filter for according sim or frame filtering
                if len(filterSim) > 1 or len(filterFrame) > 1:
                    for i in range(len(filterTop)):
                        if filterTop[i] in topDir:
                            match = i
                            break
                    assert (match >= 0), "Match computation error"

                simDir = os.path.join(dataDir, topDir)
                sims = os.listdir(simDir)
                sims.sort()

                if printLevel == "top":
                    self.summaryPrint += ["Top folder loaded: " + simDir.replace(dataDir + "/", "")]

                # sim_000001 folders
                for sim in sims:
                    currentDir = os.path.join(simDir, sim)
                    if not os.path.isdir(currentDir):
                        continue

                    if len(filterSim) > 0:
                        simNum = int(sim.split("_")[1])
                        if len(filterSim) == 1:
                            if type(filterSim[0]) is tuple:
                                inside = simNum >= filterSim[0][0] and simNum < filterSim[0][1]
                            elif type(filterSim[0]) is list:
                                inside = simNum in filterSim[0]
                        else:
                            if type(filterSim[match]) is tuple:
                                inside = simNum >= filterSim[match][0] and simNum < filterSim[match][1]
                            elif type(filterSim[match]) is list:
                                inside = simNum in filterSim[match]
                        # continue when excluding or including according to filter
                        if inside == excludefilterSim:
                            continue

                    if printLevel == "sim":
                        self.summaryPrint += ["Sim loaded: " + currentDir.replace(dataDir + "/", "")]

                    # individual simulation frames
                    minFrame = filterFrame[0][0] if len(filterFrame) == 1 else filterFrame[match][0]
                    maxFrame = filterFrame[0][1] if len(filterFrame) == 1 else filterFrame[match][1]
                    seqLength = sequenceLength[0][0] if len(sequenceLength) == 1 else sequenceLength[match][0]
                    seqSkip   = sequenceLength[0][1] if len(sequenceLength) == 1 else sequenceLength[match][1]
                    for seqStart in range(minFrame, maxFrame, seqLength*seqSkip):
                        validSeq = True
                        for frame in range(seqStart, seqStart+seqLength*seqSkip, seqSkip):
                            # discard incomplete sequences at simulation end
                            if seqStart+seqLength*seqSkip > maxFrame:
                                validSeq = False
                                break

                            for field in self.simFields:
                                currentField = os.path.join(currentDir, "%s_%06d.npz" % (field, frame))
                                if not os.path.isfile(currentField):
                                    raise FileNotFoundError("Could not load %s file: %s" % (field, currentField))

                        # imcomplete sequence means there are no more frames left
                        if not validSeq:
                            break

                        if printLevel == "full":
                            self.summaryPrint += ["Frames %s loaded: %s/%s_%06d-%06d(%03d).npz" % ("-".join(self.simFields),
                                        currentDir.replace(dataDir + "/", ""), "-".join(self.simFields), seqStart, seqStart + seqLength*(seqSkip-1), seqSkip)]

                        self.dataPaths.append((currentDir, seqStart, seqStart + seqLength*seqSkip, seqSkip))

        self.summaryPrint += ["Dataset Length: %d\n" % len(self.dataPaths)]


    def __len__(self) -> int:
        return len(self.dataPaths)


    def __getitem__(self, idx:int) -> dict:
        # sequence indexing
        basePath, seqStart, seqEnd, seqSkip = self.dataPaths[idx]
        seqLen = int((seqEnd - seqStart) / seqSkip)
        if self.randSeqOffset:
            halfSeq = int((seqEnd-seqStart) / 2)
            offset = torch.randint(-halfSeq, halfSeq+1, (1,)).item()
            if seqStart + offset >= self.filterFrame[0][0] and seqEnd + offset < self.filterFrame[0][1]:
                seqStart = seqStart + offset
                seqEnd = seqEnd + offset

        # loading simulation parameters
        with open(os.path.join(basePath, "src", "description.json")) as f:
            loadedJSON = json.load(f)

            loadNames = ["Reynolds Number", "Mach Number", "Drag Coefficient", "Lift Coefficient", "Z Slice"]
            loadedParams = {}
            for loadName in loadNames:
                loadedParam = np.zeros(seqLen, dtype=np.float32)
                if loadName in loadedJSON:
                    temp = loadedJSON[loadName]
                    if isinstance(temp, int) or isinstance(temp, float):
                        temp = np.array(temp, dtype=np.float32)
                        loadedParam[0:] = np.repeat(temp, seqLen)
                    elif isinstance(temp, list):
                        loadedParam[0:] = temp[seqStart:seqEnd:seqSkip]
                    else:
                        raise ValueError("Invalid simulation parameter data type")
                loadedParams[loadName] = loadedParam

            if "rey" in self.simParams and "mach" in self.simParams:
                simParameters = np.stack([loadedParams["Reynolds Number"], loadedParams["Mach Number"]], axis=1)
            elif "rey" in self.simParams:
                simParameters = np.reshape(loadedParams["Reynolds Number"], (-1,1))
            elif "mach" in self.simParams:
                simParameters = np.reshape(loadedParams["Mach Number"], (-1,1))
            elif "zslice" in self.simParams:
                simParameters = np.reshape(loadedParams["Z Slice"], (-1,1))
            elif not self.simParams:
                simParameters ={}
            else:
                raise ValueError("Invalid specification of simulation parameters")

        # loading obstacle mask
        if os.path.isfile(os.path.join(basePath, "obstacle_mask.npz")):
            obsMask = np.load(os.path.join(basePath, "obstacle_mask.npz"))['arr_0']
        else:
            obsMask = None

        # loading fields and combining them with simulation parameters
        loaded = {}
        for field in self.simFields:
            loaded[field] = []

        for frame in range(seqStart, seqEnd, seqSkip):
            for field in self.simFields:
                loadedArr = np.load(os.path.join(basePath, "%s_%06d.npz" % (field,frame)))['arr_0']
                loaded[field] += [loadedArr.astype(np.float32)]

        loadedFields = []
        for field in self.simFields:
            loadedFields += [np.stack(loaded[field], axis=0)]

        if type(simParameters) is not dict:
            vel = loadedFields[0]
            if vel.ndim == 4:
                simParExpanded = simParameters[:,:,np.newaxis,np.newaxis]
                simParExpanded = np.repeat(np.repeat(simParExpanded, vel.shape[2], axis=2), vel.shape[3], axis=3)
            elif vel.ndim == 5:
                simParExpanded = simParameters[:,:,np.newaxis,np.newaxis,np.newaxis]
                simParExpanded = np.repeat(np.repeat(np.repeat(simParExpanded, vel.shape[2], axis=2), vel.shape[3], axis=3), vel.shape[4], axis=4)
            else:
                raise ValueError("Invalid input shape when loading samples!")
            loadedFields += [simParExpanded]

        data = np.concatenate(loadedFields, axis=1) # ORDER (fields): velocity (x,y), velocity z / density, pressure, ORDER (params): rey, mach, zslice

        # output
        dataPath = "%s/%s_%06d-%06d(%03d).npz" % (basePath, "-".join(self.simFields), seqStart, seqEnd - seqSkip, seqSkip)
        sample = {"data" : data, "simParameters" : simParameters, "allParameters" : loadedParams, "path" : dataPath}
        if obsMask is not None:
            sample["obsMask"] = obsMask

        if self.transform:
            sample = self.transform(sample)
        else:
            print("WARNING: no data transformations are employed!")

        return sample


    def printDatasetInfo(self):
        if self.transform:
            s  = "%s - Data Normalization Transformation: ACTIVE\n" % (self.name)
            self.summaryPrint += [s]
        print('\n'.join(self.summaryPrint))

    def getFilterInfoString(self) -> str:
        s  = "%s - Data Filter Setup: \n" % (self.name)
        s += "\tdataDirs: %s\n" % (str(self.dataDirs))
        s += "\tfilterTop: %s  exlude: %s\n" % (str(self.filterTop), self.excludeFilterTop)
        s += "\tfilterSim: %s  exlude: %s\n" % (str(self.filterSim), self.excludefilterSim)
        s += "\tfilterFrame: %s\n" % (str(self.filterFrame))
        s += "\tsequenceLength: %s\n" % (str(self.sequenceLength))
        return s
19/46:
!wget -nc "https://dataserv.ub.tum.de/s/m1734798.001/download?path=/&files=128_tra_small.zip" -O data/128_tra_small.zip --no-check-certificate 
!unzip -nq data/128_tra_small.zip -d data
!wget -nc "https://dataserv.ub.tum.de/s/m1734798.001/download?path=/&files=checkpoints_acdm_tra.zip" -O models/checkpoints_acdm_tra.zip --no-check-certificate 
!unzip -nq models/checkpoints_acdm_tra.zip -d models
19/47:
try:
    import google.colab  # only to ensure that we are inside colab
    !pip install einops
except ImportError:
    print("This notebook is running locally, please follow the ACDM installation instructions first, then continue with the cell below.")
    pass
19/48:
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader, SequentialSampler, RandomSampler

from einops import rearrange
from functools import partial

import matplotlib.pyplot as plt
import numpy as np

import math
import os, json
from typing import List,Tuple,Dict
19/49:
class TurbulenceDataset(Dataset):
    """Data set for turbulence and wavelet noise data

    Args:
        name: name of the dataset
        dataDirs: list of paths to data directories
        filterTop: filter for top level folder names (e.g. different types of data)
        excludeFilterTop: mode for filterTop (exclude or include)
        filterSim: filter simulations by min and max (min inclusive, max exclusive)
        excludefilterSim: mode for filterSim (exclude or include)
        filterFrame: mandatory filter for simulation frames by min and max (min inclusive, max exclusive)
        sequenceLength: number of frames to group into a sequence and number of frames to omit in between
        randSeqOffset: randomizes the starting frame of each sequence
        simFields: list of simulation fields to include (vel is always included) ["dens", "pres"]
        simParams: list of simulation parameters to include ["rey", "mach"]
        printLevel: print mode for contents of the dataset ["none", "top", "sim", "full"]
    """

    def __init__(self, name:str, dataDirs:List[str], filterTop:List[str], excludeFilterTop:bool=False, filterSim:List[Tuple[int, int]]=[],
                excludefilterSim:bool=False, filterFrame:List[Tuple[int, int]]=[], sequenceLength:List[Tuple[int, int]]=[],
                randSeqOffset:bool=False, simFields:List[str]=[], simParams:List[str]=[], printLevel:str="none"):

        self.transform = None
        self.name = name
        self.dataDirs = dataDirs
        self.filterTop = filterTop
        self.excludeFilterTop = excludeFilterTop
        self.filterSim = filterSim
        self.excludefilterSim = excludefilterSim
        self.filterFrame = filterFrame
        self.sequenceLength = sequenceLength
        self.randSeqOffset = randSeqOffset
        self.simFields = ["velocity"]
        if "dens" in simFields:
            self.simFields += ["density"]
        if "pres" in simFields:
            self.simFields += ["pressure"]

        self.simParams = simParams
        self.printLevel = printLevel

        self.summaryPrint = []
        self.summaryPrint += ["Dataset " + name + " at " + str(dataDirs)]
        self.summaryPrint += [self.getFilterInfoString()]

        # BUILD FULL FILE LIST
        self.dataPaths = []
        self.dataPathModes = []

        for dataDir in dataDirs:
            topDirs = os.listdir(dataDir)
            topDirs.sort()

            # top level folders
            for topDir in topDirs:
                if filterTop:
                    # continue when excluding or including according to filter
                    if excludeFilterTop == any( item in topDir for item in filterTop ):
                        continue

                match = -1
                # compute matching top filter for according sim or frame filtering
                if len(filterSim) > 1 or len(filterFrame) > 1:
                    for i in range(len(filterTop)):
                        if filterTop[i] in topDir:
                            match = i
                            break
                    assert (match >= 0), "Match computation error"

                simDir = os.path.join(dataDir, topDir)
                sims = os.listdir(simDir)
                sims.sort()

                if printLevel == "top":
                    self.summaryPrint += ["Top folder loaded: " + simDir.replace(dataDir + "/", "")]

                # sim_000001 folders
                for sim in sims:
                    currentDir = os.path.join(simDir, sim)
                    if not os.path.isdir(currentDir):
                        continue

                    if len(filterSim) > 0:
                        simNum = int(sim.split("_")[1])
                        if len(filterSim) == 1:
                            if type(filterSim[0]) is tuple:
                                inside = simNum >= filterSim[0][0] and simNum < filterSim[0][1]
                            elif type(filterSim[0]) is list:
                                inside = simNum in filterSim[0]
                        else:
                            if type(filterSim[match]) is tuple:
                                inside = simNum >= filterSim[match][0] and simNum < filterSim[match][1]
                            elif type(filterSim[match]) is list:
                                inside = simNum in filterSim[match]
                        # continue when excluding or including according to filter
                        if inside == excludefilterSim:
                            continue

                    if printLevel == "sim":
                        self.summaryPrint += ["Sim loaded: " + currentDir.replace(dataDir + "/", "")]

                    # individual simulation frames
                    minFrame = filterFrame[0][0] if len(filterFrame) == 1 else filterFrame[match][0]
                    maxFrame = filterFrame[0][1] if len(filterFrame) == 1 else filterFrame[match][1]
                    seqLength = sequenceLength[0][0] if len(sequenceLength) == 1 else sequenceLength[match][0]
                    seqSkip   = sequenceLength[0][1] if len(sequenceLength) == 1 else sequenceLength[match][1]
                    for seqStart in range(minFrame, maxFrame, seqLength*seqSkip):
                        validSeq = True
                        for frame in range(seqStart, seqStart+seqLength*seqSkip, seqSkip):
                            # discard incomplete sequences at simulation end
                            if seqStart+seqLength*seqSkip > maxFrame:
                                validSeq = False
                                break

                            for field in self.simFields:
                                currentField = os.path.join(currentDir, "%s_%06d.npz" % (field, frame))
                                if not os.path.isfile(currentField):
                                    raise FileNotFoundError("Could not load %s file: %s" % (field, currentField))

                        # imcomplete sequence means there are no more frames left
                        if not validSeq:
                            break

                        if printLevel == "full":
                            self.summaryPrint += ["Frames %s loaded: %s/%s_%06d-%06d(%03d).npz" % ("-".join(self.simFields),
                                        currentDir.replace(dataDir + "/", ""), "-".join(self.simFields), seqStart, seqStart + seqLength*(seqSkip-1), seqSkip)]

                        self.dataPaths.append((currentDir, seqStart, seqStart + seqLength*seqSkip, seqSkip))

        self.summaryPrint += ["Dataset Length: %d\n" % len(self.dataPaths)]


    def __len__(self) -> int:
        return len(self.dataPaths)


    def __getitem__(self, idx:int) -> dict:
        # sequence indexing
        basePath, seqStart, seqEnd, seqSkip = self.dataPaths[idx]
        seqLen = int((seqEnd - seqStart) / seqSkip)
        if self.randSeqOffset:
            halfSeq = int((seqEnd-seqStart) / 2)
            offset = torch.randint(-halfSeq, halfSeq+1, (1,)).item()
            if seqStart + offset >= self.filterFrame[0][0] and seqEnd + offset < self.filterFrame[0][1]:
                seqStart = seqStart + offset
                seqEnd = seqEnd + offset

        # loading simulation parameters
        with open(os.path.join(basePath, "src", "description.json")) as f:
            loadedJSON = json.load(f)

            loadNames = ["Reynolds Number", "Mach Number", "Drag Coefficient", "Lift Coefficient", "Z Slice"]
            loadedParams = {}
            for loadName in loadNames:
                loadedParam = np.zeros(seqLen, dtype=np.float32)
                if loadName in loadedJSON:
                    temp = loadedJSON[loadName]
                    if isinstance(temp, int) or isinstance(temp, float):
                        temp = np.array(temp, dtype=np.float32)
                        loadedParam[0:] = np.repeat(temp, seqLen)
                    elif isinstance(temp, list):
                        loadedParam[0:] = temp[seqStart:seqEnd:seqSkip]
                    else:
                        raise ValueError("Invalid simulation parameter data type")
                loadedParams[loadName] = loadedParam

            if "rey" in self.simParams and "mach" in self.simParams:
                simParameters = np.stack([loadedParams["Reynolds Number"], loadedParams["Mach Number"]], axis=1)
            elif "rey" in self.simParams:
                simParameters = np.reshape(loadedParams["Reynolds Number"], (-1,1))
            elif "mach" in self.simParams:
                simParameters = np.reshape(loadedParams["Mach Number"], (-1,1))
            elif "zslice" in self.simParams:
                simParameters = np.reshape(loadedParams["Z Slice"], (-1,1))
            elif not self.simParams:
                simParameters ={}
            else:
                raise ValueError("Invalid specification of simulation parameters")

        # loading obstacle mask
        if os.path.isfile(os.path.join(basePath, "obstacle_mask.npz")):
            obsMask = np.load(os.path.join(basePath, "obstacle_mask.npz"))['arr_0']
        else:
            obsMask = None

        # loading fields and combining them with simulation parameters
        loaded = {}
        for field in self.simFields:
            loaded[field] = []

        for frame in range(seqStart, seqEnd, seqSkip):
            for field in self.simFields:
                loadedArr = np.load(os.path.join(basePath, "%s_%06d.npz" % (field,frame)))['arr_0']
                loaded[field] += [loadedArr.astype(np.float32)]

        loadedFields = []
        for field in self.simFields:
            loadedFields += [np.stack(loaded[field], axis=0)]

        if type(simParameters) is not dict:
            vel = loadedFields[0]
            if vel.ndim == 4:
                simParExpanded = simParameters[:,:,np.newaxis,np.newaxis]
                simParExpanded = np.repeat(np.repeat(simParExpanded, vel.shape[2], axis=2), vel.shape[3], axis=3)
            elif vel.ndim == 5:
                simParExpanded = simParameters[:,:,np.newaxis,np.newaxis,np.newaxis]
                simParExpanded = np.repeat(np.repeat(np.repeat(simParExpanded, vel.shape[2], axis=2), vel.shape[3], axis=3), vel.shape[4], axis=4)
            else:
                raise ValueError("Invalid input shape when loading samples!")
            loadedFields += [simParExpanded]

        data = np.concatenate(loadedFields, axis=1) # ORDER (fields): velocity (x,y), velocity z / density, pressure, ORDER (params): rey, mach, zslice

        # output
        dataPath = "%s/%s_%06d-%06d(%03d).npz" % (basePath, "-".join(self.simFields), seqStart, seqEnd - seqSkip, seqSkip)
        sample = {"data" : data, "simParameters" : simParameters, "allParameters" : loadedParams, "path" : dataPath}
        if obsMask is not None:
            sample["obsMask"] = obsMask

        if self.transform:
            sample = self.transform(sample)
        else:
            print("WARNING: no data transformations are employed!")

        return sample


    def printDatasetInfo(self):
        if self.transform:
            s  = "%s - Data Normalization Transformation: ACTIVE\n" % (self.name)
            self.summaryPrint += [s]
        print('\n'.join(self.summaryPrint))

    def getFilterInfoString(self) -> str:
        s  = "%s - Data Filter Setup: \n" % (self.name)
        s += "\tdataDirs: %s\n" % (str(self.dataDirs))
        s += "\tfilterTop: %s  exlude: %s\n" % (str(self.filterTop), self.excludeFilterTop)
        s += "\tfilterSim: %s  exlude: %s\n" % (str(self.filterSim), self.excludefilterSim)
        s += "\tfilterFrame: %s\n" % (str(self.filterFrame))
        s += "\tsequenceLength: %s\n" % (str(self.sequenceLength))
        return s
19/50:
class DataTransforms(object):

    def __init__(self, normalizeMode="traMixed", simFields=["dens","pres"], simParams=["mach"]):
        self.simFields = simFields
        self.simParams = simParams

        # mean and std statistics from whole dataset for normalization
        if "tra" in normalizeMode.lower() and "mixed" in normalizeMode.lower():
            # ORDER (fields): velocity (x,y), density, pressure, ORDER (params): rey, mach
            self.normMean = np.array([0.560642, -0.000129, 0.903352, 0.637941, 10000.000000, 0.700000], dtype=np.float32)
            self.normStd =  np.array([0.216987, 0.216987, 0.145391, 0.119944, 1, 0.118322], dtype=np.float32)


    def __call__(self, sample:dict):
        data = sample["data"]
        simParameters = sample["simParameters"]
        allParameters = sample["allParameters"]
        obsMask = sample.get("obsMask", None)
        path = sample["path"]

        # normalization to std. normal distr. with zero mean and unit std via statistics from whole dataset
        # ORDER (fields): velocity (x,y), velocity z / density, pressure, ORDER (params): rey, mach
        filterList = [0, 1]
        if "dens" in self.simFields:
            filterList += [2]
        if "pres" in self.simFields:
            filterList += [3]
        if "rey" in self.simParams:
            filterList += [4]
        if "mach" in self.simParams:
            filterList += [5]
        filterArr = np.array(filterList)
        filterArrParam = filterArr[-len(self.simParams):]

        if self.simParams:
            meanParam = self.normMean[filterArrParam].reshape((1,-1))
            stdParam = self.normStd[filterArrParam].reshape((1,-1))
            simParameters = (simParameters - meanParam) / stdParam

        meanData = self.normMean[filterArr].reshape((1,-1,1,1))
        stdData = self.normStd[filterArr].reshape((1,-1,1,1))
        data = (data - meanData) / stdData

        # toTensor
        result = torch.from_numpy(data)
        if obsMask is not None:
            obsMask = torch.from_numpy(obsMask)

        outDict = {"data": result, "simParameters": simParameters, "allParameters": allParameters, "path": path}
        if obsMask is not None:
            outDict["obsMask"] = obsMask
        return outDict
19/51: data
19/52: data.shape
19/53:
device = "cuda" if torch.cuda.is_available() else "cpu"
print("Training device: %s" % device)

startFromCheckpoint = True

batch = 32 # training batch size
if startFromCheckpoint:
    epochs = 10 # finetune only for a small number of epochs
    lr = 0.00001 # since the model is already trained, a conservatively low learning rate
else:
    epochs = 10000 # train from scratch for large number of epochs
    lr = 0.0001 # larger learning rate for training from scratch

sequenceLength = [3,2] # three timesteps (two input steps and one target step) with a temporal stride of 2
simFields = ["dens", "pres"] # the provided data set contains velocity (implict), as well as density and pressure values
simParams = ["mach"] # scalar simulation parameters on which the model is conditioned only contain the Mach number here
diffusionSteps = 20 # the provided model checkpoint was pretrained on 20 diffusion steps

# data set and data loading
trainSet = TurbulenceDataset("Training", ["data"], filterTop=["128_small_tra"], filterSim=[[0]], excludefilterSim=False, filterFrame=[(250,1000)],
                sequenceLength=[sequenceLength], randSeqOffset=True, simFields=simFields, simParams=simParams, printLevel="sim")
trainSet.transform = DataTransforms(normalizeMode="traMixed", simFields=simFields, simParams=simParams)
trainSet.printDatasetInfo()
trainSampler = RandomSampler(trainSet)
#trainSampler = SequentialSampler(trainSet)
trainLoader = DataLoader(trainSet, sampler=trainSampler, batch_size=batch, drop_last=True, num_workers=2)
19/54: trainSet
19/55:
# model definition
condChannels = 2 * (2 + len(simFields) + len(simParams))
dataChannels = 2 + len(simFields) + len(simParams)
model = DiffusionModel(diffusionSteps, condChannels, dataChannels)

if startFromCheckpoint:
    # load weights from checkpoint
    # loaded = torch.load("models/models_tra/128_acdm-r20_02/Model.pth", map_location=torch.device('cpu'))
    # model.load_state_dict(loaded["stateDictDecoder"])
    loaded = torch.load("models/NEW.zip", map_location=torch.device('cpu'))
    model.load_state_dict(loaded)
    
model.train()
model.to(device)

# print model info and trainable weigths
paramsTrainable = sum([np.prod(p.size()) for p in filter(lambda p: p.requires_grad, model.parameters())])
params = sum([np.prod(p.size()) for p in model.parameters()])
#print(model)
print("Trainable Weights (All Weights): %d (%d)" % (paramsTrainable, params))

# training loop
print("\nStarting training...")
optimizer = torch.optim.Adam(model.parameters(), lr=lr)
for epoch in range(epochs):
    losses = []
    for s, sample in enumerate(trainLoader, 0):
        optimizer.zero_grad()

        d = sample["data"].to(device)

        inputSteps = 2
        cond = []
        for i in range(inputSteps):
            cond += [d[:,i:i+1]] # collect input steps
        conditioning = torch.concat(cond, dim=2) # combine along channel dimension
        data = d[:, inputSteps:inputSteps+1]

        noise, predictedNoise = model(conditioning=conditioning, data=data)

        loss = F.smooth_l1_loss(noise, predictedNoise)
        print("    [Epoch %2d, Batch %4d]: %1.7f" % (epoch, s, loss.detach().cpu().item()))
        loss.backward()

        losses += [loss.detach().cpu().item()]

        optimizer.step()
    print("[Epoch %2d, FULL]: %1.7f" % (epoch, sum(losses)/len(losses)))

print("Training complete!")
19/56:
!wget -nc "https://dataserv.ub.tum.de/s/m1734798.001/download?path=/&files=128_tra_small.zip" -O data/128_tra_small.zip --no-check-certificate 
!unzip -nq data/128_tra_small.zip -d data
!wget -nc "https://dataserv.ub.tum.de/s/m1734798.001/download?path=/&files=checkpoints_acdm_tra.zip" -O models/checkpoints_acdm_tra.zip --no-check-certificate 
!unzip -nq models/checkpoints_acdm_tra.zip -d models
35/1:
!wget -nc "https://dataserv.ub.tum.de/s/m1734798.001/download?path=/&files=128_tra_small.zip" -O data/128_tra_small.zip --no-check-certificate 
!unzip -nq data/128_tra_small.zip -d data
!wget -nc "https://dataserv.ub.tum.de/s/m1734798.001/download?path=/&files=checkpoints_acdm_tra.zip" -O models/checkpoints_acdm_tra.zip --no-check-certificate 
!unzip -nq models/checkpoints_acdm_tra.zip -d models
35/2:
!wget -nc "https://dataserv.ub.tum.de/s/m1734798.001/download?path=/&files=128_tra_small.zip" -O data/128_tra_small.zip --no-check-certificate 
!unzip -nq data/128_tra_small.zip -d data
!wget -nc "https://dataserv.ub.tum.de/s/m1734798.001/download?path=/&files=checkpoints_acdm_tra.zip" -O models/checkpoints_acdm_tra.zip --no-check-certificate 
!unzip -nq models/checkpoints_acdm_tra.zip -d models
35/3:
try:
    import google.colab  # only to ensure that we are inside colab
    !pip install einops
except ImportError:
    print("This notebook is running locally, please follow the ACDM installation instructions first, then continue with the cell below.")
    pass
35/4:
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader, SequentialSampler, RandomSampler

from einops import rearrange
from functools import partial

import matplotlib.pyplot as plt
import numpy as np

import math
import os, json
from typing import List,Tuple,Dict
35/5:
class TurbulenceDataset(Dataset):
    """Data set for turbulence and wavelet noise data

    Args:
        name: name of the dataset
        dataDirs: list of paths to data directories
        filterTop: filter for top level folder names (e.g. different types of data)
        excludeFilterTop: mode for filterTop (exclude or include)
        filterSim: filter simulations by min and max (min inclusive, max exclusive)
        excludefilterSim: mode for filterSim (exclude or include)
        filterFrame: mandatory filter for simulation frames by min and max (min inclusive, max exclusive)
        sequenceLength: number of frames to group into a sequence and number of frames to omit in between
        randSeqOffset: randomizes the starting frame of each sequence
        simFields: list of simulation fields to include (vel is always included) ["dens", "pres"]
        simParams: list of simulation parameters to include ["rey", "mach"]
        printLevel: print mode for contents of the dataset ["none", "top", "sim", "full"]
    """

    def __init__(self, name:str, dataDirs:List[str], filterTop:List[str], excludeFilterTop:bool=False, filterSim:List[Tuple[int, int]]=[],
                excludefilterSim:bool=False, filterFrame:List[Tuple[int, int]]=[], sequenceLength:List[Tuple[int, int]]=[],
                randSeqOffset:bool=False, simFields:List[str]=[], simParams:List[str]=[], printLevel:str="none"):

        self.transform = None
        self.name = name
        self.dataDirs = dataDirs
        self.filterTop = filterTop
        self.excludeFilterTop = excludeFilterTop
        self.filterSim = filterSim
        self.excludefilterSim = excludefilterSim
        self.filterFrame = filterFrame
        self.sequenceLength = sequenceLength
        self.randSeqOffset = randSeqOffset
        self.simFields = ["velocity"]
        if "dens" in simFields:
            self.simFields += ["density"]
        if "pres" in simFields:
            self.simFields += ["pressure"]

        self.simParams = simParams
        self.printLevel = printLevel

        self.summaryPrint = []
        self.summaryPrint += ["Dataset " + name + " at " + str(dataDirs)]
        self.summaryPrint += [self.getFilterInfoString()]

        # BUILD FULL FILE LIST
        self.dataPaths = []
        self.dataPathModes = []

        for dataDir in dataDirs:
            topDirs = os.listdir(dataDir)
            topDirs.sort()

            # top level folders
            for topDir in topDirs:
                if filterTop:
                    # continue when excluding or including according to filter
                    if excludeFilterTop == any( item in topDir for item in filterTop ):
                        continue

                match = -1
                # compute matching top filter for according sim or frame filtering
                if len(filterSim) > 1 or len(filterFrame) > 1:
                    for i in range(len(filterTop)):
                        if filterTop[i] in topDir:
                            match = i
                            break
                    assert (match >= 0), "Match computation error"

                simDir = os.path.join(dataDir, topDir)
                sims = os.listdir(simDir)
                sims.sort()

                if printLevel == "top":
                    self.summaryPrint += ["Top folder loaded: " + simDir.replace(dataDir + "/", "")]

                # sim_000001 folders
                for sim in sims:
                    currentDir = os.path.join(simDir, sim)
                    if not os.path.isdir(currentDir):
                        continue

                    if len(filterSim) > 0:
                        simNum = int(sim.split("_")[1])
                        if len(filterSim) == 1:
                            if type(filterSim[0]) is tuple:
                                inside = simNum >= filterSim[0][0] and simNum < filterSim[0][1]
                            elif type(filterSim[0]) is list:
                                inside = simNum in filterSim[0]
                        else:
                            if type(filterSim[match]) is tuple:
                                inside = simNum >= filterSim[match][0] and simNum < filterSim[match][1]
                            elif type(filterSim[match]) is list:
                                inside = simNum in filterSim[match]
                        # continue when excluding or including according to filter
                        if inside == excludefilterSim:
                            continue

                    if printLevel == "sim":
                        self.summaryPrint += ["Sim loaded: " + currentDir.replace(dataDir + "/", "")]

                    # individual simulation frames
                    minFrame = filterFrame[0][0] if len(filterFrame) == 1 else filterFrame[match][0]
                    maxFrame = filterFrame[0][1] if len(filterFrame) == 1 else filterFrame[match][1]
                    seqLength = sequenceLength[0][0] if len(sequenceLength) == 1 else sequenceLength[match][0]
                    seqSkip   = sequenceLength[0][1] if len(sequenceLength) == 1 else sequenceLength[match][1]
                    for seqStart in range(minFrame, maxFrame, seqLength*seqSkip):
                        validSeq = True
                        for frame in range(seqStart, seqStart+seqLength*seqSkip, seqSkip):
                            # discard incomplete sequences at simulation end
                            if seqStart+seqLength*seqSkip > maxFrame:
                                validSeq = False
                                break

                            for field in self.simFields:
                                currentField = os.path.join(currentDir, "%s_%06d.npz" % (field, frame))
                                if not os.path.isfile(currentField):
                                    raise FileNotFoundError("Could not load %s file: %s" % (field, currentField))

                        # imcomplete sequence means there are no more frames left
                        if not validSeq:
                            break

                        if printLevel == "full":
                            self.summaryPrint += ["Frames %s loaded: %s/%s_%06d-%06d(%03d).npz" % ("-".join(self.simFields),
                                        currentDir.replace(dataDir + "/", ""), "-".join(self.simFields), seqStart, seqStart + seqLength*(seqSkip-1), seqSkip)]

                        self.dataPaths.append((currentDir, seqStart, seqStart + seqLength*seqSkip, seqSkip))

        self.summaryPrint += ["Dataset Length: %d\n" % len(self.dataPaths)]


    def __len__(self) -> int:
        return len(self.dataPaths)


    def __getitem__(self, idx:int) -> dict:
        # sequence indexing
        basePath, seqStart, seqEnd, seqSkip = self.dataPaths[idx]
        seqLen = int((seqEnd - seqStart) / seqSkip)
        if self.randSeqOffset:
            halfSeq = int((seqEnd-seqStart) / 2)
            offset = torch.randint(-halfSeq, halfSeq+1, (1,)).item()
            if seqStart + offset >= self.filterFrame[0][0] and seqEnd + offset < self.filterFrame[0][1]:
                seqStart = seqStart + offset
                seqEnd = seqEnd + offset

        # loading simulation parameters
        with open(os.path.join(basePath, "src", "description.json")) as f:
            loadedJSON = json.load(f)

            loadNames = ["Reynolds Number", "Mach Number", "Drag Coefficient", "Lift Coefficient", "Z Slice"]
            loadedParams = {}
            for loadName in loadNames:
                loadedParam = np.zeros(seqLen, dtype=np.float32)
                if loadName in loadedJSON:
                    temp = loadedJSON[loadName]
                    if isinstance(temp, int) or isinstance(temp, float):
                        temp = np.array(temp, dtype=np.float32)
                        loadedParam[0:] = np.repeat(temp, seqLen)
                    elif isinstance(temp, list):
                        loadedParam[0:] = temp[seqStart:seqEnd:seqSkip]
                    else:
                        raise ValueError("Invalid simulation parameter data type")
                loadedParams[loadName] = loadedParam

            if "rey" in self.simParams and "mach" in self.simParams:
                simParameters = np.stack([loadedParams["Reynolds Number"], loadedParams["Mach Number"]], axis=1)
            elif "rey" in self.simParams:
                simParameters = np.reshape(loadedParams["Reynolds Number"], (-1,1))
            elif "mach" in self.simParams:
                simParameters = np.reshape(loadedParams["Mach Number"], (-1,1))
            elif "zslice" in self.simParams:
                simParameters = np.reshape(loadedParams["Z Slice"], (-1,1))
            elif not self.simParams:
                simParameters ={}
            else:
                raise ValueError("Invalid specification of simulation parameters")

        # loading obstacle mask
        if os.path.isfile(os.path.join(basePath, "obstacle_mask.npz")):
            obsMask = np.load(os.path.join(basePath, "obstacle_mask.npz"))['arr_0']
        else:
            obsMask = None

        # loading fields and combining them with simulation parameters
        loaded = {}
        for field in self.simFields:
            loaded[field] = []

        for frame in range(seqStart, seqEnd, seqSkip):
            for field in self.simFields:
                loadedArr = np.load(os.path.join(basePath, "%s_%06d.npz" % (field,frame)))['arr_0']
                loaded[field] += [loadedArr.astype(np.float32)]

        loadedFields = []
        for field in self.simFields:
            loadedFields += [np.stack(loaded[field], axis=0)]

        if type(simParameters) is not dict:
            vel = loadedFields[0]
            if vel.ndim == 4:
                simParExpanded = simParameters[:,:,np.newaxis,np.newaxis]
                simParExpanded = np.repeat(np.repeat(simParExpanded, vel.shape[2], axis=2), vel.shape[3], axis=3)
            elif vel.ndim == 5:
                simParExpanded = simParameters[:,:,np.newaxis,np.newaxis,np.newaxis]
                simParExpanded = np.repeat(np.repeat(np.repeat(simParExpanded, vel.shape[2], axis=2), vel.shape[3], axis=3), vel.shape[4], axis=4)
            else:
                raise ValueError("Invalid input shape when loading samples!")
            loadedFields += [simParExpanded]

        data = np.concatenate(loadedFields, axis=1) # ORDER (fields): velocity (x,y), velocity z / density, pressure, ORDER (params): rey, mach, zslice

        # output
        dataPath = "%s/%s_%06d-%06d(%03d).npz" % (basePath, "-".join(self.simFields), seqStart, seqEnd - seqSkip, seqSkip)
        sample = {"data" : data, "simParameters" : simParameters, "allParameters" : loadedParams, "path" : dataPath}
        if obsMask is not None:
            sample["obsMask"] = obsMask

        if self.transform:
            sample = self.transform(sample)
        else:
            print("WARNING: no data transformations are employed!")

        return sample


    def printDatasetInfo(self):
        if self.transform:
            s  = "%s - Data Normalization Transformation: ACTIVE\n" % (self.name)
            self.summaryPrint += [s]
        print('\n'.join(self.summaryPrint))

    def getFilterInfoString(self) -> str:
        s  = "%s - Data Filter Setup: \n" % (self.name)
        s += "\tdataDirs: %s\n" % (str(self.dataDirs))
        s += "\tfilterTop: %s  exlude: %s\n" % (str(self.filterTop), self.excludeFilterTop)
        s += "\tfilterSim: %s  exlude: %s\n" % (str(self.filterSim), self.excludefilterSim)
        s += "\tfilterFrame: %s\n" % (str(self.filterFrame))
        s += "\tsequenceLength: %s\n" % (str(self.sequenceLength))
        return s
35/6:
class DataTransforms(object):

    def __init__(self, normalizeMode="traMixed", simFields=["dens","pres"], simParams=["mach"]):
        self.simFields = simFields
        self.simParams = simParams

        # mean and std statistics from whole dataset for normalization
        if "tra" in normalizeMode.lower() and "mixed" in normalizeMode.lower():
            # ORDER (fields): velocity (x,y), density, pressure, ORDER (params): rey, mach
            self.normMean = np.array([0.560642, -0.000129, 0.903352, 0.637941, 10000.000000, 0.700000], dtype=np.float32)
            self.normStd =  np.array([0.216987, 0.216987, 0.145391, 0.119944, 1, 0.118322], dtype=np.float32)


    def __call__(self, sample:dict):
        data = sample["data"]
        simParameters = sample["simParameters"]
        allParameters = sample["allParameters"]
        obsMask = sample.get("obsMask", None)
        path = sample["path"]

        # normalization to std. normal distr. with zero mean and unit std via statistics from whole dataset
        # ORDER (fields): velocity (x,y), velocity z / density, pressure, ORDER (params): rey, mach
        filterList = [0, 1]
        if "dens" in self.simFields:
            filterList += [2]
        if "pres" in self.simFields:
            filterList += [3]
        if "rey" in self.simParams:
            filterList += [4]
        if "mach" in self.simParams:
            filterList += [5]
        filterArr = np.array(filterList)
        filterArrParam = filterArr[-len(self.simParams):]

        if self.simParams:
            meanParam = self.normMean[filterArrParam].reshape((1,-1))
            stdParam = self.normStd[filterArrParam].reshape((1,-1))
            simParameters = (simParameters - meanParam) / stdParam

        meanData = self.normMean[filterArr].reshape((1,-1,1,1))
        stdData = self.normStd[filterArr].reshape((1,-1,1,1))
        data = (data - meanData) / stdData

        # toTensor
        result = torch.from_numpy(data)
        if obsMask is not None:
            obsMask = torch.from_numpy(obsMask)

        outDict = {"data": result, "simParameters": simParameters, "allParameters": allParameters, "path": path}
        if obsMask is not None:
            outDict["obsMask"] = obsMask
        return outDict
35/7: data.shape
35/8:
!wget -nc "https://dataserv.ub.tum.de/s/m1734798.001/download?path=/&files=128_tra_small.zip" -O data/128_tra_small.zip --no-check-certificate 
!unzip -nq data/128_tra_small.zip -d data
!wget -nc "https://dataserv.ub.tum.de/s/m1734798.001/download?path=/&files=checkpoints_acdm_tra.zip" -O models/checkpoints_acdm_tra.zip --no-check-certificate 
!unzip -nq models/checkpoints_acdm_tra.zip -d models
35/9:
try:
    import google.colab  # only to ensure that we are inside colab
    !pip install einops
except ImportError:
    print("This notebook is running locally, please follow the ACDM installation instructions first, then continue with the cell below.")
    pass
35/10:
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader, SequentialSampler, RandomSampler

from einops import rearrange
from functools import partial

import matplotlib.pyplot as plt
import numpy as np

import math
import os, json
from typing import List,Tuple,Dict
35/11:
class TurbulenceDataset(Dataset):
    """Data set for turbulence and wavelet noise data

    Args:
        name: name of the dataset
        dataDirs: list of paths to data directories
        filterTop: filter for top level folder names (e.g. different types of data)
        excludeFilterTop: mode for filterTop (exclude or include)
        filterSim: filter simulations by min and max (min inclusive, max exclusive)
        excludefilterSim: mode for filterSim (exclude or include)
        filterFrame: mandatory filter for simulation frames by min and max (min inclusive, max exclusive)
        sequenceLength: number of frames to group into a sequence and number of frames to omit in between
        randSeqOffset: randomizes the starting frame of each sequence
        simFields: list of simulation fields to include (vel is always included) ["dens", "pres"]
        simParams: list of simulation parameters to include ["rey", "mach"]
        printLevel: print mode for contents of the dataset ["none", "top", "sim", "full"]
    """

    def __init__(self, name:str, dataDirs:List[str], filterTop:List[str], excludeFilterTop:bool=False, filterSim:List[Tuple[int, int]]=[],
                excludefilterSim:bool=False, filterFrame:List[Tuple[int, int]]=[], sequenceLength:List[Tuple[int, int]]=[],
                randSeqOffset:bool=False, simFields:List[str]=[], simParams:List[str]=[], printLevel:str="none"):

        self.transform = None
        self.name = name
        self.dataDirs = dataDirs
        self.filterTop = filterTop
        self.excludeFilterTop = excludeFilterTop
        self.filterSim = filterSim
        self.excludefilterSim = excludefilterSim
        self.filterFrame = filterFrame
        self.sequenceLength = sequenceLength
        self.randSeqOffset = randSeqOffset
        self.simFields = ["velocity"]
        if "dens" in simFields:
            self.simFields += ["density"]
        if "pres" in simFields:
            self.simFields += ["pressure"]

        self.simParams = simParams
        self.printLevel = printLevel

        self.summaryPrint = []
        self.summaryPrint += ["Dataset " + name + " at " + str(dataDirs)]
        self.summaryPrint += [self.getFilterInfoString()]

        # BUILD FULL FILE LIST
        self.dataPaths = []
        self.dataPathModes = []

        for dataDir in dataDirs:
            topDirs = os.listdir(dataDir)
            topDirs.sort()

            # top level folders
            for topDir in topDirs:
                if filterTop:
                    # continue when excluding or including according to filter
                    if excludeFilterTop == any( item in topDir for item in filterTop ):
                        continue

                match = -1
                # compute matching top filter for according sim or frame filtering
                if len(filterSim) > 1 or len(filterFrame) > 1:
                    for i in range(len(filterTop)):
                        if filterTop[i] in topDir:
                            match = i
                            break
                    assert (match >= 0), "Match computation error"

                simDir = os.path.join(dataDir, topDir)
                sims = os.listdir(simDir)
                sims.sort()

                if printLevel == "top":
                    self.summaryPrint += ["Top folder loaded: " + simDir.replace(dataDir + "/", "")]

                # sim_000001 folders
                for sim in sims:
                    currentDir = os.path.join(simDir, sim)
                    if not os.path.isdir(currentDir):
                        continue

                    if len(filterSim) > 0:
                        simNum = int(sim.split("_")[1])
                        if len(filterSim) == 1:
                            if type(filterSim[0]) is tuple:
                                inside = simNum >= filterSim[0][0] and simNum < filterSim[0][1]
                            elif type(filterSim[0]) is list:
                                inside = simNum in filterSim[0]
                        else:
                            if type(filterSim[match]) is tuple:
                                inside = simNum >= filterSim[match][0] and simNum < filterSim[match][1]
                            elif type(filterSim[match]) is list:
                                inside = simNum in filterSim[match]
                        # continue when excluding or including according to filter
                        if inside == excludefilterSim:
                            continue

                    if printLevel == "sim":
                        self.summaryPrint += ["Sim loaded: " + currentDir.replace(dataDir + "/", "")]

                    # individual simulation frames
                    minFrame = filterFrame[0][0] if len(filterFrame) == 1 else filterFrame[match][0]
                    maxFrame = filterFrame[0][1] if len(filterFrame) == 1 else filterFrame[match][1]
                    seqLength = sequenceLength[0][0] if len(sequenceLength) == 1 else sequenceLength[match][0]
                    seqSkip   = sequenceLength[0][1] if len(sequenceLength) == 1 else sequenceLength[match][1]
                    for seqStart in range(minFrame, maxFrame, seqLength*seqSkip):
                        validSeq = True
                        for frame in range(seqStart, seqStart+seqLength*seqSkip, seqSkip):
                            # discard incomplete sequences at simulation end
                            if seqStart+seqLength*seqSkip > maxFrame:
                                validSeq = False
                                break

                            for field in self.simFields:
                                currentField = os.path.join(currentDir, "%s_%06d.npz" % (field, frame))
                                if not os.path.isfile(currentField):
                                    raise FileNotFoundError("Could not load %s file: %s" % (field, currentField))

                        # imcomplete sequence means there are no more frames left
                        if not validSeq:
                            break

                        if printLevel == "full":
                            self.summaryPrint += ["Frames %s loaded: %s/%s_%06d-%06d(%03d).npz" % ("-".join(self.simFields),
                                        currentDir.replace(dataDir + "/", ""), "-".join(self.simFields), seqStart, seqStart + seqLength*(seqSkip-1), seqSkip)]

                        self.dataPaths.append((currentDir, seqStart, seqStart + seqLength*seqSkip, seqSkip))

        self.summaryPrint += ["Dataset Length: %d\n" % len(self.dataPaths)]


    def __len__(self) -> int:
        return len(self.dataPaths)


    def __getitem__(self, idx:int) -> dict:
        # sequence indexing
        basePath, seqStart, seqEnd, seqSkip = self.dataPaths[idx]
        seqLen = int((seqEnd - seqStart) / seqSkip)
        if self.randSeqOffset:
            halfSeq = int((seqEnd-seqStart) / 2)
            offset = torch.randint(-halfSeq, halfSeq+1, (1,)).item()
            if seqStart + offset >= self.filterFrame[0][0] and seqEnd + offset < self.filterFrame[0][1]:
                seqStart = seqStart + offset
                seqEnd = seqEnd + offset

        # loading simulation parameters
        with open(os.path.join(basePath, "src", "description.json")) as f:
            loadedJSON = json.load(f)

            loadNames = ["Reynolds Number", "Mach Number", "Drag Coefficient", "Lift Coefficient", "Z Slice"]
            loadedParams = {}
            for loadName in loadNames:
                loadedParam = np.zeros(seqLen, dtype=np.float32)
                if loadName in loadedJSON:
                    temp = loadedJSON[loadName]
                    if isinstance(temp, int) or isinstance(temp, float):
                        temp = np.array(temp, dtype=np.float32)
                        loadedParam[0:] = np.repeat(temp, seqLen)
                    elif isinstance(temp, list):
                        loadedParam[0:] = temp[seqStart:seqEnd:seqSkip]
                    else:
                        raise ValueError("Invalid simulation parameter data type")
                loadedParams[loadName] = loadedParam

            if "rey" in self.simParams and "mach" in self.simParams:
                simParameters = np.stack([loadedParams["Reynolds Number"], loadedParams["Mach Number"]], axis=1)
            elif "rey" in self.simParams:
                simParameters = np.reshape(loadedParams["Reynolds Number"], (-1,1))
            elif "mach" in self.simParams:
                simParameters = np.reshape(loadedParams["Mach Number"], (-1,1))
            elif "zslice" in self.simParams:
                simParameters = np.reshape(loadedParams["Z Slice"], (-1,1))
            elif not self.simParams:
                simParameters ={}
            else:
                raise ValueError("Invalid specification of simulation parameters")

        # loading obstacle mask
        if os.path.isfile(os.path.join(basePath, "obstacle_mask.npz")):
            obsMask = np.load(os.path.join(basePath, "obstacle_mask.npz"))['arr_0']
        else:
            obsMask = None

        # loading fields and combining them with simulation parameters
        loaded = {}
        for field in self.simFields:
            loaded[field] = []

        for frame in range(seqStart, seqEnd, seqSkip):
            for field in self.simFields:
                loadedArr = np.load(os.path.join(basePath, "%s_%06d.npz" % (field,frame)))['arr_0']
                loaded[field] += [loadedArr.astype(np.float32)]

        loadedFields = []
        for field in self.simFields:
            loadedFields += [np.stack(loaded[field], axis=0)]

        if type(simParameters) is not dict:
            vel = loadedFields[0]
            if vel.ndim == 4:
                simParExpanded = simParameters[:,:,np.newaxis,np.newaxis]
                simParExpanded = np.repeat(np.repeat(simParExpanded, vel.shape[2], axis=2), vel.shape[3], axis=3)
            elif vel.ndim == 5:
                simParExpanded = simParameters[:,:,np.newaxis,np.newaxis,np.newaxis]
                simParExpanded = np.repeat(np.repeat(np.repeat(simParExpanded, vel.shape[2], axis=2), vel.shape[3], axis=3), vel.shape[4], axis=4)
            else:
                raise ValueError("Invalid input shape when loading samples!")
            loadedFields += [simParExpanded]

        data = np.concatenate(loadedFields, axis=1) # ORDER (fields): velocity (x,y), velocity z / density, pressure, ORDER (params): rey, mach, zslice

        # output
        dataPath = "%s/%s_%06d-%06d(%03d).npz" % (basePath, "-".join(self.simFields), seqStart, seqEnd - seqSkip, seqSkip)
        sample = {"data" : data, "simParameters" : simParameters, "allParameters" : loadedParams, "path" : dataPath}
        if obsMask is not None:
            sample["obsMask"] = obsMask

        if self.transform:
            sample = self.transform(sample)
        else:
            print("WARNING: no data transformations are employed!")

        return sample


    def printDatasetInfo(self):
        if self.transform:
            s  = "%s - Data Normalization Transformation: ACTIVE\n" % (self.name)
            self.summaryPrint += [s]
        print('\n'.join(self.summaryPrint))

    def getFilterInfoString(self) -> str:
        s  = "%s - Data Filter Setup: \n" % (self.name)
        s += "\tdataDirs: %s\n" % (str(self.dataDirs))
        s += "\tfilterTop: %s  exlude: %s\n" % (str(self.filterTop), self.excludeFilterTop)
        s += "\tfilterSim: %s  exlude: %s\n" % (str(self.filterSim), self.excludefilterSim)
        s += "\tfilterFrame: %s\n" % (str(self.filterFrame))
        s += "\tsequenceLength: %s\n" % (str(self.sequenceLength))
        return s
35/12:
class DataTransforms(object):

    def __init__(self, normalizeMode="traMixed", simFields=["dens","pres"], simParams=["mach"]):
        self.simFields = simFields
        self.simParams = simParams

        # mean and std statistics from whole dataset for normalization
        if "tra" in normalizeMode.lower() and "mixed" in normalizeMode.lower():
            # ORDER (fields): velocity (x,y), density, pressure, ORDER (params): rey, mach
            self.normMean = np.array([0.560642, -0.000129, 0.903352, 0.637941, 10000.000000, 0.700000], dtype=np.float32)
            self.normStd =  np.array([0.216987, 0.216987, 0.145391, 0.119944, 1, 0.118322], dtype=np.float32)


    def __call__(self, sample:dict):
        data = sample["data"]
        simParameters = sample["simParameters"]
        allParameters = sample["allParameters"]
        obsMask = sample.get("obsMask", None)
        path = sample["path"]

        # normalization to std. normal distr. with zero mean and unit std via statistics from whole dataset
        # ORDER (fields): velocity (x,y), velocity z / density, pressure, ORDER (params): rey, mach
        filterList = [0, 1]
        if "dens" in self.simFields:
            filterList += [2]
        if "pres" in self.simFields:
            filterList += [3]
        if "rey" in self.simParams:
            filterList += [4]
        if "mach" in self.simParams:
            filterList += [5]
        filterArr = np.array(filterList)
        filterArrParam = filterArr[-len(self.simParams):]

        if self.simParams:
            meanParam = self.normMean[filterArrParam].reshape((1,-1))
            stdParam = self.normStd[filterArrParam].reshape((1,-1))
            simParameters = (simParameters - meanParam) / stdParam

        meanData = self.normMean[filterArr].reshape((1,-1,1,1))
        stdData = self.normStd[filterArr].reshape((1,-1,1,1))
        data = (data - meanData) / stdData

        # toTensor
        result = torch.from_numpy(data)
        if obsMask is not None:
            obsMask = torch.from_numpy(obsMask)

        outDict = {"data": result, "simParameters": simParameters, "allParameters": allParameters, "path": path}
        if obsMask is not None:
            outDict["obsMask"] = obsMask
        return outDict
35/13:
class Residual(nn.Module):
    def __init__(self, fn):
        super().__init__()
        self.fn = fn

    def forward(self, x, *args, **kwargs):
        return self.fn(x, *args, **kwargs) + x

def Upsample(dim):
    return nn.ConvTranspose2d(dim, dim, 4, 2, 1)

def Downsample(dim):
    return nn.Conv2d(dim, dim, 4, 2, 1)


class SinusoidalPositionEmbeddings(nn.Module):
    def __init__(self, dim):
        super().__init__()
        self.dim = dim

    def forward(self, time):
        device = time.device
        half_dim = self.dim // 2
        embeddings = math.log(10000) / (half_dim - 1)
        embeddings = torch.exp(torch.arange(half_dim, device=device) * -embeddings)
        embeddings = time[:, None] * embeddings[None, :]
        embeddings = torch.cat((embeddings.sin(), embeddings.cos()), dim=-1)
        return embeddings
35/14:
class ConvNextBlock(nn.Module):

    def __init__(self, dim, dim_out, *, time_emb_dim=None, mult=2, norm=True):
        super().__init__()
        self.mlp = (
            nn.Sequential(nn.GELU(), nn.Linear(time_emb_dim, dim))
            if time_emb_dim is not None else None
        )

        self.ds_conv = nn.Conv2d(dim, dim, 7, padding=3, groups=dim)

        self.net = nn.Sequential(
            nn.GroupNorm(1, dim) if norm else nn.Identity(),
            nn.Conv2d(dim, dim_out * mult, 3, padding=1),
            nn.GELU(),
            nn.GroupNorm(1, dim_out * mult),
            nn.Conv2d(dim_out * mult, dim_out, 3, padding=1),
        )

        self.res_conv = nn.Conv2d(dim, dim_out, 1) if dim != dim_out else nn.Identity()

    def forward(self, x, time_emb=None):
        h = self.ds_conv(x)

        if self.mlp is not None and time_emb is not None:
            assert time_emb is not None, "time embedding must be passed in"
            condition = self.mlp(time_emb)
            h = h + rearrange(condition, "b c -> b c 1 1")

        h = self.net(h)
        return h + self.res_conv(x)
35/15:
class Attention(nn.Module):
    def __init__(self, dim, heads=4, dim_head=32):
        super().__init__()
        self.scale = dim_head**-0.5
        self.heads = heads
        hidden_dim = dim_head * heads
        self.to_qkv = nn.Conv2d(dim, hidden_dim * 3, 1, bias=False)
        self.to_out = nn.Conv2d(hidden_dim, dim, 1)

    def forward(self, x):
        b, c, h, w = x.shape
        qkv = self.to_qkv(x).chunk(3, dim=1)
        q, k, v = map(
            lambda t: rearrange(t, "b (h c) x y -> b h c (x y)", h=self.heads), qkv
        )
        q = q * self.scale

        sim = torch.einsum("b h d i, b h d j -> b h i j", q, k)
        sim = sim - sim.amax(dim=-1, keepdim=True).detach()
        attn = sim.softmax(dim=-1)

        out = torch.einsum("b h i j, b h d j -> b h i d", attn, v)
        out = rearrange(out, "b h (x y) d -> b (h d) x y", x=h, y=w)
        return self.to_out(out)


class LinearAttention(nn.Module):
    def __init__(self, dim, heads=4, dim_head=32):
        super().__init__()
        self.scale = dim_head**-0.5
        self.heads = heads
        hidden_dim = dim_head * heads
        self.to_qkv = nn.Conv2d(dim, hidden_dim * 3, 1, bias=False)

        self.to_out = nn.Sequential(nn.Conv2d(hidden_dim, dim, 1),
                                    nn.GroupNorm(1, dim))

    def forward(self, x):
        b, c, h, w = x.shape
        qkv = self.to_qkv(x).chunk(3, dim=1)
        q, k, v = map(
            lambda t: rearrange(t, "b (h c) x y -> b h c (x y)", h=self.heads), qkv
        )

        q = q.softmax(dim=-2)
        k = k.softmax(dim=-1)

        q = q * self.scale
        context = torch.einsum("b h d n, b h e n -> b h d e", k, v)

        out = torch.einsum("b h d e, b h d n -> b h e n", context, q)
        out = rearrange(out, "b h c (x y) -> b (h c) x y", h=self.heads, x=h, y=w)
        return self.to_out(out)
35/16:
class PreNorm(nn.Module):
    def __init__(self, dim, fn):
        super().__init__()
        self.fn = fn
        self.norm = nn.GroupNorm(1, dim)

    def forward(self, x):
        x = self.norm(x)
        return self.fn(x)


class Unet(nn.Module):
    def __init__(
        self,
        dim,
        init_dim=None,
        out_dim=None,
        dim_mults=(1, 2, 4, 8),
        channels=3,
        with_time_emb=True,
        resnet_block_groups=8,
        use_convnext=True,
        convnext_mult=2,
    ):
        super().__init__()

        # determine dimensions
        self.channels = channels

        init_dim = init_dim if init_dim is not None else dim // 3 * 2
        self.init_conv = nn.Conv2d(channels, init_dim, 7, padding=3)

        dims = [init_dim, *map(lambda m: dim * m, dim_mults)]
        in_out = list(zip(dims[:-1], dims[1:]))

        if use_convnext:
            block_klass = partial(ConvNextBlock, mult=convnext_mult)
        else:
            raise NotImplementedError()

        # time embeddings
        if with_time_emb:
            time_dim = dim * 4
            self.time_mlp = nn.Sequential(
                SinusoidalPositionEmbeddings(dim),
                nn.Linear(dim, time_dim),
                nn.GELU(),
                nn.Linear(time_dim, time_dim),
            )

        else:
            time_dim = None
            self.time_mlp = None
            self.cond_mlp = None
            self.sim_mlp = None

        # layers
        self.downs = nn.ModuleList([])
        self.ups = nn.ModuleList([])
        num_resolutions = len(in_out)

        for ind, (dim_in, dim_out) in enumerate(in_out):
            is_last = ind >= (num_resolutions - 1)

            self.downs.append(
                nn.ModuleList(
                    [
                        block_klass(dim_in, dim_out, time_emb_dim=time_dim),
                        block_klass(dim_out, dim_out, time_emb_dim=time_dim),
                        Residual(PreNorm(dim_out, LinearAttention(dim_out))),
                        Downsample(dim_out) if not is_last else nn.Identity(),
                    ]
                )
            )

        mid_dim = dims[-1]
        self.mid_block1 = block_klass(mid_dim, mid_dim, time_emb_dim=time_dim)
        self.mid_attn = Residual(PreNorm(mid_dim, Attention(mid_dim)))
        self.mid_block2 = block_klass(mid_dim, mid_dim, time_emb_dim=time_dim)

        for ind, (dim_in, dim_out) in enumerate(reversed(in_out[1:])):
            is_last = ind >= (num_resolutions - 1)

            self.ups.append(
                nn.ModuleList(
                    [
                        block_klass(dim_out * 2, dim_in, time_emb_dim=time_dim),
                        block_klass(dim_in, dim_in, time_emb_dim=time_dim),
                        Residual(PreNorm(dim_in, LinearAttention(dim_in))),
                        Upsample(dim_in) if not is_last else nn.Identity(),
                    ]
                )
            )

        out_dim = out_dim if out_dim is not None else channels
        self.final_conv = nn.Sequential(
            block_klass(dim, dim), nn.Conv2d(dim, out_dim, 1)
        )

    def forward(self, x, time):
        x = self.init_conv(x)

        t = self.time_mlp(time) if self.time_mlp is not None else None

        h = []

        # downsample
        for block1, block2, attn, downsample in self.downs:
            x = block1(x, t)
            x = block2(x, t)
            x = attn(x)
            h.append(x)
            x = downsample(x)

        # bottleneck
        x = self.mid_block1(x, t)
        x = self.mid_attn(x)
        x = self.mid_block2(x, t)

        # upsample
        for block1, block2, attn, upsample in self.ups:
            x = torch.cat((x, h.pop()), dim=1)
            x = block1(x, t)
            x = block2(x, t)
            x = attn(x)
            x = upsample(x)

        return self.final_conv(x)
35/17:
def linear_beta_schedule(timesteps):
    if timesteps < 10:
        raise ValueError("Warning: Less than 10 timesteps require adjustments to this schedule!")

    beta_start = 0.0001 * (500/timesteps) # adjust reference values determined for 500 steps
    beta_end = 0.02 * (500/timesteps)
    betas = torch.linspace(beta_start, beta_end, timesteps)
    return torch.clip(betas, 0.0001, 0.9999)
35/18:
class DiffusionModel(nn.Module):
    def __init__(self, diffusionSteps:int, condChannels:int, dataChannels:int):
        super(DiffusionModel, self).__init__()

        self.timesteps = diffusionSteps
        betas = linear_beta_schedule(timesteps=self.timesteps)

        betas = betas.unsqueeze(1).unsqueeze(2).unsqueeze(3)
        alphas = 1.0 - betas
        alphasCumprod = torch.cumprod(alphas, axis=0)
        alphasCumprodPrev = F.pad(alphasCumprod[:-1], (0,0,0,0,0,0,1,0), value=1.0)
        sqrtRecipAlphas = torch.sqrt(1.0 / alphas)

        # calculations for diffusion q(x_t | x_{t-1}) and others
        sqrtAlphasCumprod = torch.sqrt(alphasCumprod)
        sqrtOneMinusAlphasCumprod = torch.sqrt(1. - alphasCumprod)

        # calculations for posterior q(x_{t-1} | x_t, x_0)
        posteriorVariance = betas * (1. - alphasCumprodPrev) / (1. - alphasCumprod)
        sqrtPosteriorVariance = torch.sqrt(posteriorVariance)

        self.register_buffer("betas", betas)
        self.register_buffer("sqrtRecipAlphas", sqrtRecipAlphas)
        self.register_buffer("sqrtAlphasCumprod", sqrtAlphasCumprod)
        self.register_buffer("sqrtOneMinusAlphasCumprod", sqrtOneMinusAlphasCumprod)
        self.register_buffer("sqrtPosteriorVariance", sqrtPosteriorVariance)

        # backbone model
        self.unet = Unet(
            dim=128,
            channels= condChannels + dataChannels,
            dim_mults=(1,1,1),
            use_convnext=True,
            convnext_mult=1,
        )


    # input shape (both inputs): B S C W H (D) -> output shape (both outputs): B S nC W H (D)
    def forward(self, conditioning:torch.Tensor, data:torch.Tensor) -> torch.Tensor:
        device = "cuda" if data.is_cuda else "cpu"
        seqLen = data.shape[1]

        # combine batch and sequence dimension for decoder processing
        d = torch.reshape(data, (-1, data.shape[2], data.shape[3], data.shape[4]))
        cond = torch.reshape(conditioning, (-1, conditioning.shape[2], conditioning.shape[3], conditioning.shape[4]))

        # TRAINING
        if self.training:

            # forward diffusion process that adds noise to data
            d = torch.concat((cond, d), dim=1)
            noise = torch.randn_like(d, device=device)
            t = torch.randint(0, self.timesteps, (d.shape[0],), device=device).long()
            dNoisy = self.sqrtAlphasCumprod[t] * d + self.sqrtOneMinusAlphasCumprod[t] * noise

            # noise prediction with network
            predictedNoise = self.unet(dNoisy, t)

            # unstack batch and sequence dimension again
            noise = torch.reshape(noise, (-1, seqLen, conditioning.shape[2] + data.shape[2], data.shape[3], data.shape[4]))
            predictedNoise = torch.reshape(predictedNoise, (-1, seqLen, conditioning.shape[2] + data.shape[2], data.shape[3], data.shape[4]))

            return noise, predictedNoise


        # INFERENCE
        else:
            # conditioned reverse diffusion process
            dNoise = torch.randn_like(d, device=device)
            cNoise = torch.randn_like(cond, device=device)

            for i in reversed(range(0, self.timesteps)):
                t = i * torch.ones(cond.shape[0], device=device).long()

                # compute conditioned part with normal forward diffusion
                condNoisy = self.sqrtAlphasCumprod[t] * cond + self.sqrtOneMinusAlphasCumprod[t] * cNoise

                dNoiseCond = torch.concat((condNoisy, dNoise), dim=1)

                # backward diffusion process that removes noise to create data
                predictedNoiseCond = self.unet(dNoiseCond, t)

                # use model (noise predictor) to predict mean
                modelMean = self.sqrtRecipAlphas[t] * (dNoiseCond - self.betas[t] * predictedNoiseCond / self.sqrtOneMinusAlphasCumprod[t])

                dNoise = modelMean[:, cond.shape[1]:modelMean.shape[1]] # discard prediction of conditioning
                if i != 0:
                    # sample randomly (only for non-final prediction), use mean directly for final prediction
                    dNoise = dNoise + self.sqrtPosteriorVariance[t] * torch.randn_like(dNoise)

            # unstack batch and sequence dimension again
            dNoise = torch.reshape(dNoise, (-1, seqLen, data.shape[2], data.shape[3], data.shape[4]))

            return dNoise
35/19:
device = "cuda" if torch.cuda.is_available() else "cpu"
print("Training device: %s" % device)

startFromCheckpoint = True

batch = 32 # training batch size
if startFromCheckpoint:
    epochs = 10 # finetune only for a small number of epochs
    lr = 0.00001 # since the model is already trained, a conservatively low learning rate
else:
    epochs = 10000 # train from scratch for large number of epochs
    lr = 0.0001 # larger learning rate for training from scratch

sequenceLength = [3,2] # three timesteps (two input steps and one target step) with a temporal stride of 2
simFields = ["dens", "pres"] # the provided data set contains velocity (implict), as well as density and pressure values
simParams = ["mach"] # scalar simulation parameters on which the model is conditioned only contain the Mach number here
diffusionSteps = 20 # the provided model checkpoint was pretrained on 20 diffusion steps

# data set and data loading
trainSet = TurbulenceDataset("Training", ["data"], filterTop=["128_small_tra"], filterSim=[[0]], excludefilterSim=False, filterFrame=[(250,1000)],
                sequenceLength=[sequenceLength], randSeqOffset=True, simFields=simFields, simParams=simParams, printLevel="sim")
trainSet.transform = DataTransforms(normalizeMode="traMixed", simFields=simFields, simParams=simParams)
trainSet.printDatasetInfo()
trainSampler = RandomSampler(trainSet)
#trainSampler = SequentialSampler(trainSet)
trainLoader = DataLoader(trainSet, sampler=trainSampler, batch_size=batch, drop_last=True, num_workers=2)
35/20:
# model definition
condChannels = 2 * (2 + len(simFields) + len(simParams))
dataChannels = 2 + len(simFields) + len(simParams)
model = DiffusionModel(diffusionSteps, condChannels, dataChannels)

if startFromCheckpoint:
    # load weights from checkpoint
    # loaded = torch.load("models/models_tra/128_acdm-r20_02/Model.pth", map_location=torch.device('cpu'))
    # model.load_state_dict(loaded["stateDictDecoder"])
    loaded = torch.load("models/NEW.zip", map_location=torch.device('cpu'))
    model.load_state_dict(loaded)
    
model.train()
model.to(device)

# print model info and trainable weigths
paramsTrainable = sum([np.prod(p.size()) for p in filter(lambda p: p.requires_grad, model.parameters())])
params = sum([np.prod(p.size()) for p in model.parameters()])
#print(model)
print("Trainable Weights (All Weights): %d (%d)" % (paramsTrainable, params))

# training loop
print("\nStarting training...")
optimizer = torch.optim.Adam(model.parameters(), lr=lr)
for epoch in range(epochs):
    losses = []
    for s, sample in enumerate(trainLoader, 0):
        optimizer.zero_grad()

        d = sample["data"].to(device)

        inputSteps = 2
        cond = []
        for i in range(inputSteps):
            cond += [d[:,i:i+1]] # collect input steps
        conditioning = torch.concat(cond, dim=2) # combine along channel dimension
        data = d[:, inputSteps:inputSteps+1]

        noise, predictedNoise = model(conditioning=conditioning, data=data)

        loss = F.smooth_l1_loss(noise, predictedNoise)
        print("    [Epoch %2d, Batch %4d]: %1.7f" % (epoch, s, loss.detach().cpu().item()))
        loss.backward()

        losses += [loss.detach().cpu().item()]

        optimizer.step()
    print("[Epoch %2d, FULL]: %1.7f" % (epoch, sum(losses)/len(losses)))

print("Training complete!")
35/21:
# model definition
condChannels = 2 * (2 + len(simFields) + len(simParams))
dataChannels = 2 + len(simFields) + len(simParams)
model = DiffusionModel(diffusionSteps, condChannels, dataChannels)

if startFromCheckpoint:
    # load weights from checkpoint
    # loaded = torch.load("models/models_tra/128_acdm-r20_02/Model.pth", map_location=torch.device('cpu'))
    # model.load_state_dict(loaded["stateDictDecoder"])
    loaded = torch.load("models/NEW.zip", map_location=torch.device('cpu'))
    model.load_state_dict(loaded)
    
model.train()
model.to(device)

# print model info and trainable weigths
paramsTrainable = sum([np.prod(p.size()) for p in filter(lambda p: p.requires_grad, model.parameters())])
params = sum([np.prod(p.size()) for p in model.parameters()])
#print(model)
print("Trainable Weights (All Weights): %d (%d)" % (paramsTrainable, params))

# training loop
print("\nStarting training...")
optimizer = torch.optim.Adam(model.parameters(), lr=lr)
for epoch in range(epochs):
    losses = []
    for s, sample in enumerate(trainLoader, 0):
        optimizer.zero_grad()

        d = sample["data"].to(device)

        inputSteps = 2
        cond = []
        for i in range(inputSteps):
            cond += [d[:,i:i+1]] # collect input steps
        conditioning = torch.concat(cond, dim=2) # combine along channel dimension
        data = d[:, inputSteps:inputSteps+1]

        noise, predictedNoise = model(conditioning=conditioning, data=data)

        loss = F.smooth_l1_loss(noise, predictedNoise)
        print("    [Epoch %2d, Batch %4d]: %1.7f" % (epoch, s, loss.detach().cpu().item()))
        loss.backward()

        losses += [loss.detach().cpu().item()]

        optimizer.step()
    print("[Epoch %2d, FULL]: %1.7f" % (epoch, sum(losses)/len(losses)))

print("Training complete!")
35/22:
# model definition
condChannels = 2 * (2 + len(simFields) + len(simParams))
dataChannels = 2 + len(simFields) + len(simParams)
model = DiffusionModel(diffusionSteps, condChannels, dataChannels)

if startFromCheckpoint:
    # load weights from checkpoint
    # loaded = torch.load("models/models_tra/128_acdm-r20_02/Model.pth", map_location=torch.device('cpu'))
    # model.load_state_dict(loaded["stateDictDecoder"])
    loaded = torch.load("models/NEW.zip", map_location=torch.device('cpu'))
    model.load_state_dict(loaded)
    
model.train()
model.to(device)

# print model info and trainable weigths
paramsTrainable = sum([np.prod(p.size()) for p in filter(lambda p: p.requires_grad, model.parameters())])
params = sum([np.prod(p.size()) for p in model.parameters()])
#print(model)
print("Trainable Weights (All Weights): %d (%d)" % (paramsTrainable, params))

# training loop
print("\nStarting training...")
optimizer = torch.optim.Adam(model.parameters(), lr=lr)
35/23: trainLoader
35/24: s1, sample1 = trainLoader[0]
35/25: s1, sample1 = trainLoader
35/26: trainLoader
35/27: trainSampler
35/28: trainSampler[0]
35/29: trainSampler\
35/30: trainSampler
35/31:
for s, sample in enumerate(trainLoader, 0):
    d = sample["data"].to(device)

    inputSteps = 2
    cond = []
    for i in range(inputSteps):
        cond += [d[:,i:i+1]] # collect input steps
    conditioning = torch.concat(cond, dim=2) # combine along channel dimension
    data = d[:, inputSteps:inputSteps+1]
35/32:
for s, sample in enumerate(trainLoader, 0):
    d = sample["data"].to(device)

    inputSteps = 2
    cond = []
    for i in range(inputSteps):
        cond += [d[:,i:i+1]] # collect input steps
    conditioning = torch.concat(cond, dim=2) # combine along channel dimension
    data = d[:, inputSteps:inputSteps+1]
36/1:
!wget -nc "https://dataserv.ub.tum.de/s/m1734798.001/download?path=/&files=128_tra_small.zip" -O data/128_tra_small.zip --no-check-certificate 
!unzip -nq data/128_tra_small.zip -d data
!wget -nc "https://dataserv.ub.tum.de/s/m1734798.001/download?path=/&files=checkpoints_acdm_tra.zip" -O models/checkpoints_acdm_tra.zip --no-check-certificate 
!unzip -nq models/checkpoints_acdm_tra.zip -d models
36/2:
try:
    import google.colab  # only to ensure that we are inside colab
    !pip install einops
except ImportError:
    print("This notebook is running locally, please follow the ACDM installation instructions first, then continue with the cell below.")
    pass
36/3:
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader, SequentialSampler, RandomSampler

from einops import rearrange
from functools import partial

import matplotlib.pyplot as plt
import numpy as np

import math
import os, json
from typing import List,Tuple,Dict
36/4:
class TurbulenceDataset(Dataset):
    """Data set for turbulence and wavelet noise data

    Args:
        name: name of the dataset
        dataDirs: list of paths to data directories
        filterTop: filter for top level folder names (e.g. different types of data)
        excludeFilterTop: mode for filterTop (exclude or include)
        filterSim: filter simulations by min and max (min inclusive, max exclusive)
        excludefilterSim: mode for filterSim (exclude or include)
        filterFrame: mandatory filter for simulation frames by min and max (min inclusive, max exclusive)
        sequenceLength: number of frames to group into a sequence and number of frames to omit in between
        randSeqOffset: randomizes the starting frame of each sequence
        simFields: list of simulation fields to include (vel is always included) ["dens", "pres"]
        simParams: list of simulation parameters to include ["rey", "mach"]
        printLevel: print mode for contents of the dataset ["none", "top", "sim", "full"]
    """

    def __init__(self, name:str, dataDirs:List[str], filterTop:List[str], excludeFilterTop:bool=False, filterSim:List[Tuple[int, int]]=[],
                excludefilterSim:bool=False, filterFrame:List[Tuple[int, int]]=[], sequenceLength:List[Tuple[int, int]]=[],
                randSeqOffset:bool=False, simFields:List[str]=[], simParams:List[str]=[], printLevel:str="none"):

        self.transform = None
        self.name = name
        self.dataDirs = dataDirs
        self.filterTop = filterTop
        self.excludeFilterTop = excludeFilterTop
        self.filterSim = filterSim
        self.excludefilterSim = excludefilterSim
        self.filterFrame = filterFrame
        self.sequenceLength = sequenceLength
        self.randSeqOffset = randSeqOffset
        self.simFields = ["velocity"]
        if "dens" in simFields:
            self.simFields += ["density"]
        if "pres" in simFields:
            self.simFields += ["pressure"]

        self.simParams = simParams
        self.printLevel = printLevel

        self.summaryPrint = []
        self.summaryPrint += ["Dataset " + name + " at " + str(dataDirs)]
        self.summaryPrint += [self.getFilterInfoString()]

        # BUILD FULL FILE LIST
        self.dataPaths = []
        self.dataPathModes = []

        for dataDir in dataDirs:
            topDirs = os.listdir(dataDir)
            topDirs.sort()

            # top level folders
            for topDir in topDirs:
                if filterTop:
                    # continue when excluding or including according to filter
                    if excludeFilterTop == any( item in topDir for item in filterTop ):
                        continue

                match = -1
                # compute matching top filter for according sim or frame filtering
                if len(filterSim) > 1 or len(filterFrame) > 1:
                    for i in range(len(filterTop)):
                        if filterTop[i] in topDir:
                            match = i
                            break
                    assert (match >= 0), "Match computation error"

                simDir = os.path.join(dataDir, topDir)
                sims = os.listdir(simDir)
                sims.sort()

                if printLevel == "top":
                    self.summaryPrint += ["Top folder loaded: " + simDir.replace(dataDir + "/", "")]

                # sim_000001 folders
                for sim in sims:
                    currentDir = os.path.join(simDir, sim)
                    if not os.path.isdir(currentDir):
                        continue

                    if len(filterSim) > 0:
                        simNum = int(sim.split("_")[1])
                        if len(filterSim) == 1:
                            if type(filterSim[0]) is tuple:
                                inside = simNum >= filterSim[0][0] and simNum < filterSim[0][1]
                            elif type(filterSim[0]) is list:
                                inside = simNum in filterSim[0]
                        else:
                            if type(filterSim[match]) is tuple:
                                inside = simNum >= filterSim[match][0] and simNum < filterSim[match][1]
                            elif type(filterSim[match]) is list:
                                inside = simNum in filterSim[match]
                        # continue when excluding or including according to filter
                        if inside == excludefilterSim:
                            continue

                    if printLevel == "sim":
                        self.summaryPrint += ["Sim loaded: " + currentDir.replace(dataDir + "/", "")]

                    # individual simulation frames
                    minFrame = filterFrame[0][0] if len(filterFrame) == 1 else filterFrame[match][0]
                    maxFrame = filterFrame[0][1] if len(filterFrame) == 1 else filterFrame[match][1]
                    seqLength = sequenceLength[0][0] if len(sequenceLength) == 1 else sequenceLength[match][0]
                    seqSkip   = sequenceLength[0][1] if len(sequenceLength) == 1 else sequenceLength[match][1]
                    for seqStart in range(minFrame, maxFrame, seqLength*seqSkip):
                        validSeq = True
                        for frame in range(seqStart, seqStart+seqLength*seqSkip, seqSkip):
                            # discard incomplete sequences at simulation end
                            if seqStart+seqLength*seqSkip > maxFrame:
                                validSeq = False
                                break

                            for field in self.simFields:
                                currentField = os.path.join(currentDir, "%s_%06d.npz" % (field, frame))
                                if not os.path.isfile(currentField):
                                    raise FileNotFoundError("Could not load %s file: %s" % (field, currentField))

                        # imcomplete sequence means there are no more frames left
                        if not validSeq:
                            break

                        if printLevel == "full":
                            self.summaryPrint += ["Frames %s loaded: %s/%s_%06d-%06d(%03d).npz" % ("-".join(self.simFields),
                                        currentDir.replace(dataDir + "/", ""), "-".join(self.simFields), seqStart, seqStart + seqLength*(seqSkip-1), seqSkip)]

                        self.dataPaths.append((currentDir, seqStart, seqStart + seqLength*seqSkip, seqSkip))

        self.summaryPrint += ["Dataset Length: %d\n" % len(self.dataPaths)]


    def __len__(self) -> int:
        return len(self.dataPaths)


    def __getitem__(self, idx:int) -> dict:
        # sequence indexing
        basePath, seqStart, seqEnd, seqSkip = self.dataPaths[idx]
        seqLen = int((seqEnd - seqStart) / seqSkip)
        if self.randSeqOffset:
            halfSeq = int((seqEnd-seqStart) / 2)
            offset = torch.randint(-halfSeq, halfSeq+1, (1,)).item()
            if seqStart + offset >= self.filterFrame[0][0] and seqEnd + offset < self.filterFrame[0][1]:
                seqStart = seqStart + offset
                seqEnd = seqEnd + offset

        # loading simulation parameters
        with open(os.path.join(basePath, "src", "description.json")) as f:
            loadedJSON = json.load(f)

            loadNames = ["Reynolds Number", "Mach Number", "Drag Coefficient", "Lift Coefficient", "Z Slice"]
            loadedParams = {}
            for loadName in loadNames:
                loadedParam = np.zeros(seqLen, dtype=np.float32)
                if loadName in loadedJSON:
                    temp = loadedJSON[loadName]
                    if isinstance(temp, int) or isinstance(temp, float):
                        temp = np.array(temp, dtype=np.float32)
                        loadedParam[0:] = np.repeat(temp, seqLen)
                    elif isinstance(temp, list):
                        loadedParam[0:] = temp[seqStart:seqEnd:seqSkip]
                    else:
                        raise ValueError("Invalid simulation parameter data type")
                loadedParams[loadName] = loadedParam

            if "rey" in self.simParams and "mach" in self.simParams:
                simParameters = np.stack([loadedParams["Reynolds Number"], loadedParams["Mach Number"]], axis=1)
            elif "rey" in self.simParams:
                simParameters = np.reshape(loadedParams["Reynolds Number"], (-1,1))
            elif "mach" in self.simParams:
                simParameters = np.reshape(loadedParams["Mach Number"], (-1,1))
            elif "zslice" in self.simParams:
                simParameters = np.reshape(loadedParams["Z Slice"], (-1,1))
            elif not self.simParams:
                simParameters ={}
            else:
                raise ValueError("Invalid specification of simulation parameters")

        # loading obstacle mask
        if os.path.isfile(os.path.join(basePath, "obstacle_mask.npz")):
            obsMask = np.load(os.path.join(basePath, "obstacle_mask.npz"))['arr_0']
        else:
            obsMask = None

        # loading fields and combining them with simulation parameters
        loaded = {}
        for field in self.simFields:
            loaded[field] = []

        for frame in range(seqStart, seqEnd, seqSkip):
            for field in self.simFields:
                loadedArr = np.load(os.path.join(basePath, "%s_%06d.npz" % (field,frame)))['arr_0']
                loaded[field] += [loadedArr.astype(np.float32)]

        loadedFields = []
        for field in self.simFields:
            loadedFields += [np.stack(loaded[field], axis=0)]

        if type(simParameters) is not dict:
            vel = loadedFields[0]
            if vel.ndim == 4:
                simParExpanded = simParameters[:,:,np.newaxis,np.newaxis]
                simParExpanded = np.repeat(np.repeat(simParExpanded, vel.shape[2], axis=2), vel.shape[3], axis=3)
            elif vel.ndim == 5:
                simParExpanded = simParameters[:,:,np.newaxis,np.newaxis,np.newaxis]
                simParExpanded = np.repeat(np.repeat(np.repeat(simParExpanded, vel.shape[2], axis=2), vel.shape[3], axis=3), vel.shape[4], axis=4)
            else:
                raise ValueError("Invalid input shape when loading samples!")
            loadedFields += [simParExpanded]

        data = np.concatenate(loadedFields, axis=1) # ORDER (fields): velocity (x,y), velocity z / density, pressure, ORDER (params): rey, mach, zslice

        # output
        dataPath = "%s/%s_%06d-%06d(%03d).npz" % (basePath, "-".join(self.simFields), seqStart, seqEnd - seqSkip, seqSkip)
        sample = {"data" : data, "simParameters" : simParameters, "allParameters" : loadedParams, "path" : dataPath}
        if obsMask is not None:
            sample["obsMask"] = obsMask

        if self.transform:
            sample = self.transform(sample)
        else:
            print("WARNING: no data transformations are employed!")

        return sample


    def printDatasetInfo(self):
        if self.transform:
            s  = "%s - Data Normalization Transformation: ACTIVE\n" % (self.name)
            self.summaryPrint += [s]
        print('\n'.join(self.summaryPrint))

    def getFilterInfoString(self) -> str:
        s  = "%s - Data Filter Setup: \n" % (self.name)
        s += "\tdataDirs: %s\n" % (str(self.dataDirs))
        s += "\tfilterTop: %s  exlude: %s\n" % (str(self.filterTop), self.excludeFilterTop)
        s += "\tfilterSim: %s  exlude: %s\n" % (str(self.filterSim), self.excludefilterSim)
        s += "\tfilterFrame: %s\n" % (str(self.filterFrame))
        s += "\tsequenceLength: %s\n" % (str(self.sequenceLength))
        return s
36/5:
class DataTransforms(object):

    def __init__(self, normalizeMode="traMixed", simFields=["dens","pres"], simParams=["mach"]):
        self.simFields = simFields
        self.simParams = simParams

        # mean and std statistics from whole dataset for normalization
        if "tra" in normalizeMode.lower() and "mixed" in normalizeMode.lower():
            # ORDER (fields): velocity (x,y), density, pressure, ORDER (params): rey, mach
            self.normMean = np.array([0.560642, -0.000129, 0.903352, 0.637941, 10000.000000, 0.700000], dtype=np.float32)
            self.normStd =  np.array([0.216987, 0.216987, 0.145391, 0.119944, 1, 0.118322], dtype=np.float32)


    def __call__(self, sample:dict):
        data = sample["data"]
        simParameters = sample["simParameters"]
        allParameters = sample["allParameters"]
        obsMask = sample.get("obsMask", None)
        path = sample["path"]

        # normalization to std. normal distr. with zero mean and unit std via statistics from whole dataset
        # ORDER (fields): velocity (x,y), velocity z / density, pressure, ORDER (params): rey, mach
        filterList = [0, 1]
        if "dens" in self.simFields:
            filterList += [2]
        if "pres" in self.simFields:
            filterList += [3]
        if "rey" in self.simParams:
            filterList += [4]
        if "mach" in self.simParams:
            filterList += [5]
        filterArr = np.array(filterList)
        filterArrParam = filterArr[-len(self.simParams):]

        if self.simParams:
            meanParam = self.normMean[filterArrParam].reshape((1,-1))
            stdParam = self.normStd[filterArrParam].reshape((1,-1))
            simParameters = (simParameters - meanParam) / stdParam

        meanData = self.normMean[filterArr].reshape((1,-1,1,1))
        stdData = self.normStd[filterArr].reshape((1,-1,1,1))
        data = (data - meanData) / stdData

        # toTensor
        result = torch.from_numpy(data)
        if obsMask is not None:
            obsMask = torch.from_numpy(obsMask)

        outDict = {"data": result, "simParameters": simParameters, "allParameters": allParameters, "path": path}
        if obsMask is not None:
            outDict["obsMask"] = obsMask
        return outDict
36/6:
class Residual(nn.Module):
    def __init__(self, fn):
        super().__init__()
        self.fn = fn

    def forward(self, x, *args, **kwargs):
        return self.fn(x, *args, **kwargs) + x

def Upsample(dim):
    return nn.ConvTranspose2d(dim, dim, 4, 2, 1)

def Downsample(dim):
    return nn.Conv2d(dim, dim, 4, 2, 1)


class SinusoidalPositionEmbeddings(nn.Module):
    def __init__(self, dim):
        super().__init__()
        self.dim = dim

    def forward(self, time):
        device = time.device
        half_dim = self.dim // 2
        embeddings = math.log(10000) / (half_dim - 1)
        embeddings = torch.exp(torch.arange(half_dim, device=device) * -embeddings)
        embeddings = time[:, None] * embeddings[None, :]
        embeddings = torch.cat((embeddings.sin(), embeddings.cos()), dim=-1)
        return embeddings
36/7:
class ConvNextBlock(nn.Module):

    def __init__(self, dim, dim_out, *, time_emb_dim=None, mult=2, norm=True):
        super().__init__()
        self.mlp = (
            nn.Sequential(nn.GELU(), nn.Linear(time_emb_dim, dim))
            if time_emb_dim is not None else None
        )

        self.ds_conv = nn.Conv2d(dim, dim, 7, padding=3, groups=dim)

        self.net = nn.Sequential(
            nn.GroupNorm(1, dim) if norm else nn.Identity(),
            nn.Conv2d(dim, dim_out * mult, 3, padding=1),
            nn.GELU(),
            nn.GroupNorm(1, dim_out * mult),
            nn.Conv2d(dim_out * mult, dim_out, 3, padding=1),
        )

        self.res_conv = nn.Conv2d(dim, dim_out, 1) if dim != dim_out else nn.Identity()

    def forward(self, x, time_emb=None):
        h = self.ds_conv(x)

        if self.mlp is not None and time_emb is not None:
            assert time_emb is not None, "time embedding must be passed in"
            condition = self.mlp(time_emb)
            h = h + rearrange(condition, "b c -> b c 1 1")

        h = self.net(h)
        return h + self.res_conv(x)
36/8:
class Attention(nn.Module):
    def __init__(self, dim, heads=4, dim_head=32):
        super().__init__()
        self.scale = dim_head**-0.5
        self.heads = heads
        hidden_dim = dim_head * heads
        self.to_qkv = nn.Conv2d(dim, hidden_dim * 3, 1, bias=False)
        self.to_out = nn.Conv2d(hidden_dim, dim, 1)

    def forward(self, x):
        b, c, h, w = x.shape
        qkv = self.to_qkv(x).chunk(3, dim=1)
        q, k, v = map(
            lambda t: rearrange(t, "b (h c) x y -> b h c (x y)", h=self.heads), qkv
        )
        q = q * self.scale

        sim = torch.einsum("b h d i, b h d j -> b h i j", q, k)
        sim = sim - sim.amax(dim=-1, keepdim=True).detach()
        attn = sim.softmax(dim=-1)

        out = torch.einsum("b h i j, b h d j -> b h i d", attn, v)
        out = rearrange(out, "b h (x y) d -> b (h d) x y", x=h, y=w)
        return self.to_out(out)


class LinearAttention(nn.Module):
    def __init__(self, dim, heads=4, dim_head=32):
        super().__init__()
        self.scale = dim_head**-0.5
        self.heads = heads
        hidden_dim = dim_head * heads
        self.to_qkv = nn.Conv2d(dim, hidden_dim * 3, 1, bias=False)

        self.to_out = nn.Sequential(nn.Conv2d(hidden_dim, dim, 1),
                                    nn.GroupNorm(1, dim))

    def forward(self, x):
        b, c, h, w = x.shape
        qkv = self.to_qkv(x).chunk(3, dim=1)
        q, k, v = map(
            lambda t: rearrange(t, "b (h c) x y -> b h c (x y)", h=self.heads), qkv
        )

        q = q.softmax(dim=-2)
        k = k.softmax(dim=-1)

        q = q * self.scale
        context = torch.einsum("b h d n, b h e n -> b h d e", k, v)

        out = torch.einsum("b h d e, b h d n -> b h e n", context, q)
        out = rearrange(out, "b h c (x y) -> b (h c) x y", h=self.heads, x=h, y=w)
        return self.to_out(out)
36/9:
class PreNorm(nn.Module):
    def __init__(self, dim, fn):
        super().__init__()
        self.fn = fn
        self.norm = nn.GroupNorm(1, dim)

    def forward(self, x):
        x = self.norm(x)
        return self.fn(x)


class Unet(nn.Module):
    def __init__(
        self,
        dim,
        init_dim=None,
        out_dim=None,
        dim_mults=(1, 2, 4, 8),
        channels=3,
        with_time_emb=True,
        resnet_block_groups=8,
        use_convnext=True,
        convnext_mult=2,
    ):
        super().__init__()

        # determine dimensions
        self.channels = channels

        init_dim = init_dim if init_dim is not None else dim // 3 * 2
        self.init_conv = nn.Conv2d(channels, init_dim, 7, padding=3)

        dims = [init_dim, *map(lambda m: dim * m, dim_mults)]
        in_out = list(zip(dims[:-1], dims[1:]))

        if use_convnext:
            block_klass = partial(ConvNextBlock, mult=convnext_mult)
        else:
            raise NotImplementedError()

        # time embeddings
        if with_time_emb:
            time_dim = dim * 4
            self.time_mlp = nn.Sequential(
                SinusoidalPositionEmbeddings(dim),
                nn.Linear(dim, time_dim),
                nn.GELU(),
                nn.Linear(time_dim, time_dim),
            )

        else:
            time_dim = None
            self.time_mlp = None
            self.cond_mlp = None
            self.sim_mlp = None

        # layers
        self.downs = nn.ModuleList([])
        self.ups = nn.ModuleList([])
        num_resolutions = len(in_out)

        for ind, (dim_in, dim_out) in enumerate(in_out):
            is_last = ind >= (num_resolutions - 1)

            self.downs.append(
                nn.ModuleList(
                    [
                        block_klass(dim_in, dim_out, time_emb_dim=time_dim),
                        block_klass(dim_out, dim_out, time_emb_dim=time_dim),
                        Residual(PreNorm(dim_out, LinearAttention(dim_out))),
                        Downsample(dim_out) if not is_last else nn.Identity(),
                    ]
                )
            )

        mid_dim = dims[-1]
        self.mid_block1 = block_klass(mid_dim, mid_dim, time_emb_dim=time_dim)
        self.mid_attn = Residual(PreNorm(mid_dim, Attention(mid_dim)))
        self.mid_block2 = block_klass(mid_dim, mid_dim, time_emb_dim=time_dim)

        for ind, (dim_in, dim_out) in enumerate(reversed(in_out[1:])):
            is_last = ind >= (num_resolutions - 1)

            self.ups.append(
                nn.ModuleList(
                    [
                        block_klass(dim_out * 2, dim_in, time_emb_dim=time_dim),
                        block_klass(dim_in, dim_in, time_emb_dim=time_dim),
                        Residual(PreNorm(dim_in, LinearAttention(dim_in))),
                        Upsample(dim_in) if not is_last else nn.Identity(),
                    ]
                )
            )

        out_dim = out_dim if out_dim is not None else channels
        self.final_conv = nn.Sequential(
            block_klass(dim, dim), nn.Conv2d(dim, out_dim, 1)
        )

    def forward(self, x, time):
        x = self.init_conv(x)

        t = self.time_mlp(time) if self.time_mlp is not None else None

        h = []

        # downsample
        for block1, block2, attn, downsample in self.downs:
            x = block1(x, t)
            x = block2(x, t)
            x = attn(x)
            h.append(x)
            x = downsample(x)

        # bottleneck
        x = self.mid_block1(x, t)
        x = self.mid_attn(x)
        x = self.mid_block2(x, t)

        # upsample
        for block1, block2, attn, upsample in self.ups:
            x = torch.cat((x, h.pop()), dim=1)
            x = block1(x, t)
            x = block2(x, t)
            x = attn(x)
            x = upsample(x)

        return self.final_conv(x)
36/10:
def linear_beta_schedule(timesteps):
    if timesteps < 10:
        raise ValueError("Warning: Less than 10 timesteps require adjustments to this schedule!")

    beta_start = 0.0001 * (500/timesteps) # adjust reference values determined for 500 steps
    beta_end = 0.02 * (500/timesteps)
    betas = torch.linspace(beta_start, beta_end, timesteps)
    return torch.clip(betas, 0.0001, 0.9999)
36/11:
class DiffusionModel(nn.Module):
    def __init__(self, diffusionSteps:int, condChannels:int, dataChannels:int):
        super(DiffusionModel, self).__init__()

        self.timesteps = diffusionSteps
        betas = linear_beta_schedule(timesteps=self.timesteps)

        betas = betas.unsqueeze(1).unsqueeze(2).unsqueeze(3)
        alphas = 1.0 - betas
        alphasCumprod = torch.cumprod(alphas, axis=0)
        alphasCumprodPrev = F.pad(alphasCumprod[:-1], (0,0,0,0,0,0,1,0), value=1.0)
        sqrtRecipAlphas = torch.sqrt(1.0 / alphas)

        # calculations for diffusion q(x_t | x_{t-1}) and others
        sqrtAlphasCumprod = torch.sqrt(alphasCumprod)
        sqrtOneMinusAlphasCumprod = torch.sqrt(1. - alphasCumprod)

        # calculations for posterior q(x_{t-1} | x_t, x_0)
        posteriorVariance = betas * (1. - alphasCumprodPrev) / (1. - alphasCumprod)
        sqrtPosteriorVariance = torch.sqrt(posteriorVariance)

        self.register_buffer("betas", betas)
        self.register_buffer("sqrtRecipAlphas", sqrtRecipAlphas)
        self.register_buffer("sqrtAlphasCumprod", sqrtAlphasCumprod)
        self.register_buffer("sqrtOneMinusAlphasCumprod", sqrtOneMinusAlphasCumprod)
        self.register_buffer("sqrtPosteriorVariance", sqrtPosteriorVariance)

        # backbone model
        self.unet = Unet(
            dim=128,
            channels= condChannels + dataChannels,
            dim_mults=(1,1,1),
            use_convnext=True,
            convnext_mult=1,
        )


    # input shape (both inputs): B S C W H (D) -> output shape (both outputs): B S nC W H (D)
    def forward(self, conditioning:torch.Tensor, data:torch.Tensor) -> torch.Tensor:
        device = "cuda" if data.is_cuda else "cpu"
        seqLen = data.shape[1]

        # combine batch and sequence dimension for decoder processing
        d = torch.reshape(data, (-1, data.shape[2], data.shape[3], data.shape[4]))
        cond = torch.reshape(conditioning, (-1, conditioning.shape[2], conditioning.shape[3], conditioning.shape[4]))

        # TRAINING
        if self.training:

            # forward diffusion process that adds noise to data
            d = torch.concat((cond, d), dim=1)
            noise = torch.randn_like(d, device=device)
            t = torch.randint(0, self.timesteps, (d.shape[0],), device=device).long()
            dNoisy = self.sqrtAlphasCumprod[t] * d + self.sqrtOneMinusAlphasCumprod[t] * noise

            # noise prediction with network
            predictedNoise = self.unet(dNoisy, t)

            # unstack batch and sequence dimension again
            noise = torch.reshape(noise, (-1, seqLen, conditioning.shape[2] + data.shape[2], data.shape[3], data.shape[4]))
            predictedNoise = torch.reshape(predictedNoise, (-1, seqLen, conditioning.shape[2] + data.shape[2], data.shape[3], data.shape[4]))

            return noise, predictedNoise


        # INFERENCE
        else:
            # conditioned reverse diffusion process
            dNoise = torch.randn_like(d, device=device)
            cNoise = torch.randn_like(cond, device=device)

            for i in reversed(range(0, self.timesteps)):
                t = i * torch.ones(cond.shape[0], device=device).long()

                # compute conditioned part with normal forward diffusion
                condNoisy = self.sqrtAlphasCumprod[t] * cond + self.sqrtOneMinusAlphasCumprod[t] * cNoise

                dNoiseCond = torch.concat((condNoisy, dNoise), dim=1)

                # backward diffusion process that removes noise to create data
                predictedNoiseCond = self.unet(dNoiseCond, t)

                # use model (noise predictor) to predict mean
                modelMean = self.sqrtRecipAlphas[t] * (dNoiseCond - self.betas[t] * predictedNoiseCond / self.sqrtOneMinusAlphasCumprod[t])

                dNoise = modelMean[:, cond.shape[1]:modelMean.shape[1]] # discard prediction of conditioning
                if i != 0:
                    # sample randomly (only for non-final prediction), use mean directly for final prediction
                    dNoise = dNoise + self.sqrtPosteriorVariance[t] * torch.randn_like(dNoise)

            # unstack batch and sequence dimension again
            dNoise = torch.reshape(dNoise, (-1, seqLen, data.shape[2], data.shape[3], data.shape[4]))

            return dNoise
36/12:
device = "cuda" if torch.cuda.is_available() else "cpu"
print("Training device: %s" % device)

startFromCheckpoint = True

batch = 32 # training batch size
if startFromCheckpoint:
    epochs = 10 # finetune only for a small number of epochs
    lr = 0.00001 # since the model is already trained, a conservatively low learning rate
else:
    epochs = 10000 # train from scratch for large number of epochs
    lr = 0.0001 # larger learning rate for training from scratch

sequenceLength = [3,2] # three timesteps (two input steps and one target step) with a temporal stride of 2
simFields = ["dens", "pres"] # the provided data set contains velocity (implict), as well as density and pressure values
simParams = ["mach"] # scalar simulation parameters on which the model is conditioned only contain the Mach number here
diffusionSteps = 20 # the provided model checkpoint was pretrained on 20 diffusion steps

# data set and data loading
trainSet = TurbulenceDataset("Training", ["data"], filterTop=["128_small_tra"], filterSim=[[0]], excludefilterSim=False, filterFrame=[(250,1000)],
                sequenceLength=[sequenceLength], randSeqOffset=True, simFields=simFields, simParams=simParams, printLevel="sim")
trainSet.transform = DataTransforms(normalizeMode="traMixed", simFields=simFields, simParams=simParams)
trainSet.printDatasetInfo()
trainSampler = RandomSampler(trainSet)
#trainSampler = SequentialSampler(trainSet)
trainLoader = DataLoader(trainSet, sampler=trainSampler, batch_size=batch, drop_last=True, num_workers=2)
36/13:
# model definition
condChannels = 2 * (2 + len(simFields) + len(simParams))
dataChannels = 2 + len(simFields) + len(simParams)
model = DiffusionModel(diffusionSteps, condChannels, dataChannels)

if startFromCheckpoint:
    # load weights from checkpoint
    # loaded = torch.load("models/models_tra/128_acdm-r20_02/Model.pth", map_location=torch.device('cpu'))
    # model.load_state_dict(loaded["stateDictDecoder"])
    loaded = torch.load("models/NEW.zip", map_location=torch.device('cpu'))
    model.load_state_dict(loaded)
    
model.train()
model.to(device)

# print model info and trainable weigths
paramsTrainable = sum([np.prod(p.size()) for p in filter(lambda p: p.requires_grad, model.parameters())])
params = sum([np.prod(p.size()) for p in model.parameters()])
#print(model)
print("Trainable Weights (All Weights): %d (%d)" % (paramsTrainable, params))

# training loop
print("\nStarting training...")
optimizer = torch.optim.Adam(model.parameters(), lr=lr)
38/1:
!wget -nc "https://dataserv.ub.tum.de/s/m1734798.001/download?path=/&files=128_tra_small.zip" -O data/128_tra_small.zip --no-check-certificate 
!unzip -nq data/128_tra_small.zip -d data
!wget -nc "https://dataserv.ub.tum.de/s/m1734798.001/download?path=/&files=checkpoints_acdm_tra.zip" -O models/checkpoints_acdm_tra.zip --no-check-certificate 
!unzip -nq models/checkpoints_acdm_tra.zip -d models
38/2:
try:
    import google.colab  # only to ensure that we are inside colab
    !pip install einops
except ImportError:
    print("This notebook is running locally, please follow the ACDM installation instructions first, then continue with the cell below.")
    pass
38/3:
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader, SequentialSampler, RandomSampler

from einops import rearrange
from functools import partial

import matplotlib.pyplot as plt
import numpy as np

import math
import os, json
from typing import List,Tuple,Dict
38/4:
class TurbulenceDataset(Dataset):
    """Data set for turbulence and wavelet noise data

    Args:
        name: name of the dataset
        dataDirs: list of paths to data directories
        filterTop: filter for top level folder names (e.g. different types of data)
        excludeFilterTop: mode for filterTop (exclude or include)
        filterSim: filter simulations by min and max (min inclusive, max exclusive)
        excludefilterSim: mode for filterSim (exclude or include)
        filterFrame: mandatory filter for simulation frames by min and max (min inclusive, max exclusive)
        sequenceLength: number of frames to group into a sequence and number of frames to omit in between
        randSeqOffset: randomizes the starting frame of each sequence
        simFields: list of simulation fields to include (vel is always included) ["dens", "pres"]
        simParams: list of simulation parameters to include ["rey", "mach"]
        printLevel: print mode for contents of the dataset ["none", "top", "sim", "full"]
    """

    def __init__(self, name:str, dataDirs:List[str], filterTop:List[str], excludeFilterTop:bool=False, filterSim:List[Tuple[int, int]]=[],
                excludefilterSim:bool=False, filterFrame:List[Tuple[int, int]]=[], sequenceLength:List[Tuple[int, int]]=[],
                randSeqOffset:bool=False, simFields:List[str]=[], simParams:List[str]=[], printLevel:str="none"):

        self.transform = None
        self.name = name
        self.dataDirs = dataDirs
        self.filterTop = filterTop
        self.excludeFilterTop = excludeFilterTop
        self.filterSim = filterSim
        self.excludefilterSim = excludefilterSim
        self.filterFrame = filterFrame
        self.sequenceLength = sequenceLength
        self.randSeqOffset = randSeqOffset
        self.simFields = ["velocity"]
        if "dens" in simFields:
            self.simFields += ["density"]
        if "pres" in simFields:
            self.simFields += ["pressure"]

        self.simParams = simParams
        self.printLevel = printLevel

        self.summaryPrint = []
        self.summaryPrint += ["Dataset " + name + " at " + str(dataDirs)]
        self.summaryPrint += [self.getFilterInfoString()]

        # BUILD FULL FILE LIST
        self.dataPaths = []
        self.dataPathModes = []

        for dataDir in dataDirs:
            topDirs = os.listdir(dataDir)
            topDirs.sort()

            # top level folders
            for topDir in topDirs:
                if filterTop:
                    # continue when excluding or including according to filter
                    if excludeFilterTop == any( item in topDir for item in filterTop ):
                        continue

                match = -1
                # compute matching top filter for according sim or frame filtering
                if len(filterSim) > 1 or len(filterFrame) > 1:
                    for i in range(len(filterTop)):
                        if filterTop[i] in topDir:
                            match = i
                            break
                    assert (match >= 0), "Match computation error"

                simDir = os.path.join(dataDir, topDir)
                sims = os.listdir(simDir)
                sims.sort()

                if printLevel == "top":
                    self.summaryPrint += ["Top folder loaded: " + simDir.replace(dataDir + "/", "")]

                # sim_000001 folders
                for sim in sims:
                    currentDir = os.path.join(simDir, sim)
                    if not os.path.isdir(currentDir):
                        continue

                    if len(filterSim) > 0:
                        simNum = int(sim.split("_")[1])
                        if len(filterSim) == 1:
                            if type(filterSim[0]) is tuple:
                                inside = simNum >= filterSim[0][0] and simNum < filterSim[0][1]
                            elif type(filterSim[0]) is list:
                                inside = simNum in filterSim[0]
                        else:
                            if type(filterSim[match]) is tuple:
                                inside = simNum >= filterSim[match][0] and simNum < filterSim[match][1]
                            elif type(filterSim[match]) is list:
                                inside = simNum in filterSim[match]
                        # continue when excluding or including according to filter
                        if inside == excludefilterSim:
                            continue

                    if printLevel == "sim":
                        self.summaryPrint += ["Sim loaded: " + currentDir.replace(dataDir + "/", "")]

                    # individual simulation frames
                    minFrame = filterFrame[0][0] if len(filterFrame) == 1 else filterFrame[match][0]
                    maxFrame = filterFrame[0][1] if len(filterFrame) == 1 else filterFrame[match][1]
                    seqLength = sequenceLength[0][0] if len(sequenceLength) == 1 else sequenceLength[match][0]
                    seqSkip   = sequenceLength[0][1] if len(sequenceLength) == 1 else sequenceLength[match][1]
                    for seqStart in range(minFrame, maxFrame, seqLength*seqSkip):
                        validSeq = True
                        for frame in range(seqStart, seqStart+seqLength*seqSkip, seqSkip):
                            # discard incomplete sequences at simulation end
                            if seqStart+seqLength*seqSkip > maxFrame:
                                validSeq = False
                                break

                            for field in self.simFields:
                                currentField = os.path.join(currentDir, "%s_%06d.npz" % (field, frame))
                                if not os.path.isfile(currentField):
                                    raise FileNotFoundError("Could not load %s file: %s" % (field, currentField))

                        # imcomplete sequence means there are no more frames left
                        if not validSeq:
                            break

                        if printLevel == "full":
                            self.summaryPrint += ["Frames %s loaded: %s/%s_%06d-%06d(%03d).npz" % ("-".join(self.simFields),
                                        currentDir.replace(dataDir + "/", ""), "-".join(self.simFields), seqStart, seqStart + seqLength*(seqSkip-1), seqSkip)]

                        self.dataPaths.append((currentDir, seqStart, seqStart + seqLength*seqSkip, seqSkip))

        self.summaryPrint += ["Dataset Length: %d\n" % len(self.dataPaths)]


    def __len__(self) -> int:
        return len(self.dataPaths)


    def __getitem__(self, idx:int) -> dict:
        # sequence indexing
        basePath, seqStart, seqEnd, seqSkip = self.dataPaths[idx]
        seqLen = int((seqEnd - seqStart) / seqSkip)
        if self.randSeqOffset:
            halfSeq = int((seqEnd-seqStart) / 2)
            offset = torch.randint(-halfSeq, halfSeq+1, (1,)).item()
            if seqStart + offset >= self.filterFrame[0][0] and seqEnd + offset < self.filterFrame[0][1]:
                seqStart = seqStart + offset
                seqEnd = seqEnd + offset

        # loading simulation parameters
        with open(os.path.join(basePath, "src", "description.json")) as f:
            loadedJSON = json.load(f)

            loadNames = ["Reynolds Number", "Mach Number", "Drag Coefficient", "Lift Coefficient", "Z Slice"]
            loadedParams = {}
            for loadName in loadNames:
                loadedParam = np.zeros(seqLen, dtype=np.float32)
                if loadName in loadedJSON:
                    temp = loadedJSON[loadName]
                    if isinstance(temp, int) or isinstance(temp, float):
                        temp = np.array(temp, dtype=np.float32)
                        loadedParam[0:] = np.repeat(temp, seqLen)
                    elif isinstance(temp, list):
                        loadedParam[0:] = temp[seqStart:seqEnd:seqSkip]
                    else:
                        raise ValueError("Invalid simulation parameter data type")
                loadedParams[loadName] = loadedParam

            if "rey" in self.simParams and "mach" in self.simParams:
                simParameters = np.stack([loadedParams["Reynolds Number"], loadedParams["Mach Number"]], axis=1)
            elif "rey" in self.simParams:
                simParameters = np.reshape(loadedParams["Reynolds Number"], (-1,1))
            elif "mach" in self.simParams:
                simParameters = np.reshape(loadedParams["Mach Number"], (-1,1))
            elif "zslice" in self.simParams:
                simParameters = np.reshape(loadedParams["Z Slice"], (-1,1))
            elif not self.simParams:
                simParameters ={}
            else:
                raise ValueError("Invalid specification of simulation parameters")

        # loading obstacle mask
        if os.path.isfile(os.path.join(basePath, "obstacle_mask.npz")):
            obsMask = np.load(os.path.join(basePath, "obstacle_mask.npz"))['arr_0']
        else:
            obsMask = None

        # loading fields and combining them with simulation parameters
        loaded = {}
        for field in self.simFields:
            loaded[field] = []

        for frame in range(seqStart, seqEnd, seqSkip):
            for field in self.simFields:
                loadedArr = np.load(os.path.join(basePath, "%s_%06d.npz" % (field,frame)))['arr_0']
                loaded[field] += [loadedArr.astype(np.float32)]

        loadedFields = []
        for field in self.simFields:
            loadedFields += [np.stack(loaded[field], axis=0)]

        if type(simParameters) is not dict:
            vel = loadedFields[0]
            if vel.ndim == 4:
                simParExpanded = simParameters[:,:,np.newaxis,np.newaxis]
                simParExpanded = np.repeat(np.repeat(simParExpanded, vel.shape[2], axis=2), vel.shape[3], axis=3)
            elif vel.ndim == 5:
                simParExpanded = simParameters[:,:,np.newaxis,np.newaxis,np.newaxis]
                simParExpanded = np.repeat(np.repeat(np.repeat(simParExpanded, vel.shape[2], axis=2), vel.shape[3], axis=3), vel.shape[4], axis=4)
            else:
                raise ValueError("Invalid input shape when loading samples!")
            loadedFields += [simParExpanded]

        data = np.concatenate(loadedFields, axis=1) # ORDER (fields): velocity (x,y), velocity z / density, pressure, ORDER (params): rey, mach, zslice

        # output
        dataPath = "%s/%s_%06d-%06d(%03d).npz" % (basePath, "-".join(self.simFields), seqStart, seqEnd - seqSkip, seqSkip)
        sample = {"data" : data, "simParameters" : simParameters, "allParameters" : loadedParams, "path" : dataPath}
        if obsMask is not None:
            sample["obsMask"] = obsMask

        if self.transform:
            sample = self.transform(sample)
        else:
            print("WARNING: no data transformations are employed!")

        return sample


    def printDatasetInfo(self):
        if self.transform:
            s  = "%s - Data Normalization Transformation: ACTIVE\n" % (self.name)
            self.summaryPrint += [s]
        print('\n'.join(self.summaryPrint))

    def getFilterInfoString(self) -> str:
        s  = "%s - Data Filter Setup: \n" % (self.name)
        s += "\tdataDirs: %s\n" % (str(self.dataDirs))
        s += "\tfilterTop: %s  exlude: %s\n" % (str(self.filterTop), self.excludeFilterTop)
        s += "\tfilterSim: %s  exlude: %s\n" % (str(self.filterSim), self.excludefilterSim)
        s += "\tfilterFrame: %s\n" % (str(self.filterFrame))
        s += "\tsequenceLength: %s\n" % (str(self.sequenceLength))
        return s
38/5:
class DataTransforms(object):

    def __init__(self, normalizeMode="traMixed", simFields=["dens","pres"], simParams=["mach"]):
        self.simFields = simFields
        self.simParams = simParams

        # mean and std statistics from whole dataset for normalization
        if "tra" in normalizeMode.lower() and "mixed" in normalizeMode.lower():
            # ORDER (fields): velocity (x,y), density, pressure, ORDER (params): rey, mach
            self.normMean = np.array([0.560642, -0.000129, 0.903352, 0.637941, 10000.000000, 0.700000], dtype=np.float32)
            self.normStd =  np.array([0.216987, 0.216987, 0.145391, 0.119944, 1, 0.118322], dtype=np.float32)


    def __call__(self, sample:dict):
        data = sample["data"]
        simParameters = sample["simParameters"]
        allParameters = sample["allParameters"]
        obsMask = sample.get("obsMask", None)
        path = sample["path"]

        # normalization to std. normal distr. with zero mean and unit std via statistics from whole dataset
        # ORDER (fields): velocity (x,y), velocity z / density, pressure, ORDER (params): rey, mach
        filterList = [0, 1]
        if "dens" in self.simFields:
            filterList += [2]
        if "pres" in self.simFields:
            filterList += [3]
        if "rey" in self.simParams:
            filterList += [4]
        if "mach" in self.simParams:
            filterList += [5]
        filterArr = np.array(filterList)
        filterArrParam = filterArr[-len(self.simParams):]

        if self.simParams:
            meanParam = self.normMean[filterArrParam].reshape((1,-1))
            stdParam = self.normStd[filterArrParam].reshape((1,-1))
            simParameters = (simParameters - meanParam) / stdParam

        meanData = self.normMean[filterArr].reshape((1,-1,1,1))
        stdData = self.normStd[filterArr].reshape((1,-1,1,1))
        data = (data - meanData) / stdData

        # toTensor
        result = torch.from_numpy(data)
        if obsMask is not None:
            obsMask = torch.from_numpy(obsMask)

        outDict = {"data": result, "simParameters": simParameters, "allParameters": allParameters, "path": path}
        if obsMask is not None:
            outDict["obsMask"] = obsMask
        return outDict
38/6:
class Residual(nn.Module):
    def __init__(self, fn):
        super().__init__()
        self.fn = fn

    def forward(self, x, *args, **kwargs):
        return self.fn(x, *args, **kwargs) + x

def Upsample(dim):
    return nn.ConvTranspose2d(dim, dim, 4, 2, 1)

def Downsample(dim):
    return nn.Conv2d(dim, dim, 4, 2, 1)


class SinusoidalPositionEmbeddings(nn.Module):
    def __init__(self, dim):
        super().__init__()
        self.dim = dim

    def forward(self, time):
        device = time.device
        half_dim = self.dim // 2
        embeddings = math.log(10000) / (half_dim - 1)
        embeddings = torch.exp(torch.arange(half_dim, device=device) * -embeddings)
        embeddings = time[:, None] * embeddings[None, :]
        embeddings = torch.cat((embeddings.sin(), embeddings.cos()), dim=-1)
        return embeddings
38/7:
class ConvNextBlock(nn.Module):

    def __init__(self, dim, dim_out, *, time_emb_dim=None, mult=2, norm=True):
        super().__init__()
        self.mlp = (
            nn.Sequential(nn.GELU(), nn.Linear(time_emb_dim, dim))
            if time_emb_dim is not None else None
        )

        self.ds_conv = nn.Conv2d(dim, dim, 7, padding=3, groups=dim)

        self.net = nn.Sequential(
            nn.GroupNorm(1, dim) if norm else nn.Identity(),
            nn.Conv2d(dim, dim_out * mult, 3, padding=1),
            nn.GELU(),
            nn.GroupNorm(1, dim_out * mult),
            nn.Conv2d(dim_out * mult, dim_out, 3, padding=1),
        )

        self.res_conv = nn.Conv2d(dim, dim_out, 1) if dim != dim_out else nn.Identity()

    def forward(self, x, time_emb=None):
        h = self.ds_conv(x)

        if self.mlp is not None and time_emb is not None:
            assert time_emb is not None, "time embedding must be passed in"
            condition = self.mlp(time_emb)
            h = h + rearrange(condition, "b c -> b c 1 1")

        h = self.net(h)
        return h + self.res_conv(x)
38/8:
class Attention(nn.Module):
    def __init__(self, dim, heads=4, dim_head=32):
        super().__init__()
        self.scale = dim_head**-0.5
        self.heads = heads
        hidden_dim = dim_head * heads
        self.to_qkv = nn.Conv2d(dim, hidden_dim * 3, 1, bias=False)
        self.to_out = nn.Conv2d(hidden_dim, dim, 1)

    def forward(self, x):
        b, c, h, w = x.shape
        qkv = self.to_qkv(x).chunk(3, dim=1)
        q, k, v = map(
            lambda t: rearrange(t, "b (h c) x y -> b h c (x y)", h=self.heads), qkv
        )
        q = q * self.scale

        sim = torch.einsum("b h d i, b h d j -> b h i j", q, k)
        sim = sim - sim.amax(dim=-1, keepdim=True).detach()
        attn = sim.softmax(dim=-1)

        out = torch.einsum("b h i j, b h d j -> b h i d", attn, v)
        out = rearrange(out, "b h (x y) d -> b (h d) x y", x=h, y=w)
        return self.to_out(out)


class LinearAttention(nn.Module):
    def __init__(self, dim, heads=4, dim_head=32):
        super().__init__()
        self.scale = dim_head**-0.5
        self.heads = heads
        hidden_dim = dim_head * heads
        self.to_qkv = nn.Conv2d(dim, hidden_dim * 3, 1, bias=False)

        self.to_out = nn.Sequential(nn.Conv2d(hidden_dim, dim, 1),
                                    nn.GroupNorm(1, dim))

    def forward(self, x):
        b, c, h, w = x.shape
        qkv = self.to_qkv(x).chunk(3, dim=1)
        q, k, v = map(
            lambda t: rearrange(t, "b (h c) x y -> b h c (x y)", h=self.heads), qkv
        )

        q = q.softmax(dim=-2)
        k = k.softmax(dim=-1)

        q = q * self.scale
        context = torch.einsum("b h d n, b h e n -> b h d e", k, v)

        out = torch.einsum("b h d e, b h d n -> b h e n", context, q)
        out = rearrange(out, "b h c (x y) -> b (h c) x y", h=self.heads, x=h, y=w)
        return self.to_out(out)
38/9:
class PreNorm(nn.Module):
    def __init__(self, dim, fn):
        super().__init__()
        self.fn = fn
        self.norm = nn.GroupNorm(1, dim)

    def forward(self, x):
        x = self.norm(x)
        return self.fn(x)


class Unet(nn.Module):
    def __init__(
        self,
        dim,
        init_dim=None,
        out_dim=None,
        dim_mults=(1, 2, 4, 8),
        channels=3,
        with_time_emb=True,
        resnet_block_groups=8,
        use_convnext=True,
        convnext_mult=2,
    ):
        super().__init__()

        # determine dimensions
        self.channels = channels

        init_dim = init_dim if init_dim is not None else dim // 3 * 2
        self.init_conv = nn.Conv2d(channels, init_dim, 7, padding=3)

        dims = [init_dim, *map(lambda m: dim * m, dim_mults)]
        in_out = list(zip(dims[:-1], dims[1:]))

        if use_convnext:
            block_klass = partial(ConvNextBlock, mult=convnext_mult)
        else:
            raise NotImplementedError()

        # time embeddings
        if with_time_emb:
            time_dim = dim * 4
            self.time_mlp = nn.Sequential(
                SinusoidalPositionEmbeddings(dim),
                nn.Linear(dim, time_dim),
                nn.GELU(),
                nn.Linear(time_dim, time_dim),
            )

        else:
            time_dim = None
            self.time_mlp = None
            self.cond_mlp = None
            self.sim_mlp = None

        # layers
        self.downs = nn.ModuleList([])
        self.ups = nn.ModuleList([])
        num_resolutions = len(in_out)

        for ind, (dim_in, dim_out) in enumerate(in_out):
            is_last = ind >= (num_resolutions - 1)

            self.downs.append(
                nn.ModuleList(
                    [
                        block_klass(dim_in, dim_out, time_emb_dim=time_dim),
                        block_klass(dim_out, dim_out, time_emb_dim=time_dim),
                        Residual(PreNorm(dim_out, LinearAttention(dim_out))),
                        Downsample(dim_out) if not is_last else nn.Identity(),
                    ]
                )
            )

        mid_dim = dims[-1]
        self.mid_block1 = block_klass(mid_dim, mid_dim, time_emb_dim=time_dim)
        self.mid_attn = Residual(PreNorm(mid_dim, Attention(mid_dim)))
        self.mid_block2 = block_klass(mid_dim, mid_dim, time_emb_dim=time_dim)

        for ind, (dim_in, dim_out) in enumerate(reversed(in_out[1:])):
            is_last = ind >= (num_resolutions - 1)

            self.ups.append(
                nn.ModuleList(
                    [
                        block_klass(dim_out * 2, dim_in, time_emb_dim=time_dim),
                        block_klass(dim_in, dim_in, time_emb_dim=time_dim),
                        Residual(PreNorm(dim_in, LinearAttention(dim_in))),
                        Upsample(dim_in) if not is_last else nn.Identity(),
                    ]
                )
            )

        out_dim = out_dim if out_dim is not None else channels
        self.final_conv = nn.Sequential(
            block_klass(dim, dim), nn.Conv2d(dim, out_dim, 1)
        )

    def forward(self, x, time):
        x = self.init_conv(x)

        t = self.time_mlp(time) if self.time_mlp is not None else None

        h = []

        # downsample
        for block1, block2, attn, downsample in self.downs:
            x = block1(x, t)
            x = block2(x, t)
            x = attn(x)
            h.append(x)
            x = downsample(x)

        # bottleneck
        x = self.mid_block1(x, t)
        x = self.mid_attn(x)
        x = self.mid_block2(x, t)

        # upsample
        for block1, block2, attn, upsample in self.ups:
            x = torch.cat((x, h.pop()), dim=1)
            x = block1(x, t)
            x = block2(x, t)
            x = attn(x)
            x = upsample(x)

        return self.final_conv(x)
38/10:
def linear_beta_schedule(timesteps):
    if timesteps < 10:
        raise ValueError("Warning: Less than 10 timesteps require adjustments to this schedule!")

    beta_start = 0.0001 * (500/timesteps) # adjust reference values determined for 500 steps
    beta_end = 0.02 * (500/timesteps)
    betas = torch.linspace(beta_start, beta_end, timesteps)
    return torch.clip(betas, 0.0001, 0.9999)
38/11:
class DiffusionModel(nn.Module):
    def __init__(self, diffusionSteps:int, condChannels:int, dataChannels:int):
        super(DiffusionModel, self).__init__()

        self.timesteps = diffusionSteps
        betas = linear_beta_schedule(timesteps=self.timesteps)

        betas = betas.unsqueeze(1).unsqueeze(2).unsqueeze(3)
        alphas = 1.0 - betas
        alphasCumprod = torch.cumprod(alphas, axis=0)
        alphasCumprodPrev = F.pad(alphasCumprod[:-1], (0,0,0,0,0,0,1,0), value=1.0)
        sqrtRecipAlphas = torch.sqrt(1.0 / alphas)

        # calculations for diffusion q(x_t | x_{t-1}) and others
        sqrtAlphasCumprod = torch.sqrt(alphasCumprod)
        sqrtOneMinusAlphasCumprod = torch.sqrt(1. - alphasCumprod)

        # calculations for posterior q(x_{t-1} | x_t, x_0)
        posteriorVariance = betas * (1. - alphasCumprodPrev) / (1. - alphasCumprod)
        sqrtPosteriorVariance = torch.sqrt(posteriorVariance)

        self.register_buffer("betas", betas)
        self.register_buffer("sqrtRecipAlphas", sqrtRecipAlphas)
        self.register_buffer("sqrtAlphasCumprod", sqrtAlphasCumprod)
        self.register_buffer("sqrtOneMinusAlphasCumprod", sqrtOneMinusAlphasCumprod)
        self.register_buffer("sqrtPosteriorVariance", sqrtPosteriorVariance)

        # backbone model
        self.unet = Unet(
            dim=128,
            channels= condChannels + dataChannels,
            dim_mults=(1,1,1),
            use_convnext=True,
            convnext_mult=1,
        )


    # input shape (both inputs): B S C W H (D) -> output shape (both outputs): B S nC W H (D)
    def forward(self, conditioning:torch.Tensor, data:torch.Tensor) -> torch.Tensor:
        device = "cuda" if data.is_cuda else "cpu"
        seqLen = data.shape[1]

        # combine batch and sequence dimension for decoder processing
        d = torch.reshape(data, (-1, data.shape[2], data.shape[3], data.shape[4]))
        cond = torch.reshape(conditioning, (-1, conditioning.shape[2], conditioning.shape[3], conditioning.shape[4]))

        # TRAINING
        if self.training:

            # forward diffusion process that adds noise to data
            d = torch.concat((cond, d), dim=1)
            noise = torch.randn_like(d, device=device)
            t = torch.randint(0, self.timesteps, (d.shape[0],), device=device).long()
            dNoisy = self.sqrtAlphasCumprod[t] * d + self.sqrtOneMinusAlphasCumprod[t] * noise

            # noise prediction with network
            predictedNoise = self.unet(dNoisy, t)

            # unstack batch and sequence dimension again
            noise = torch.reshape(noise, (-1, seqLen, conditioning.shape[2] + data.shape[2], data.shape[3], data.shape[4]))
            predictedNoise = torch.reshape(predictedNoise, (-1, seqLen, conditioning.shape[2] + data.shape[2], data.shape[3], data.shape[4]))

            return noise, predictedNoise


        # INFERENCE
        else:
            # conditioned reverse diffusion process
            dNoise = torch.randn_like(d, device=device)
            cNoise = torch.randn_like(cond, device=device)

            for i in reversed(range(0, self.timesteps)):
                t = i * torch.ones(cond.shape[0], device=device).long()

                # compute conditioned part with normal forward diffusion
                condNoisy = self.sqrtAlphasCumprod[t] * cond + self.sqrtOneMinusAlphasCumprod[t] * cNoise

                dNoiseCond = torch.concat((condNoisy, dNoise), dim=1)

                # backward diffusion process that removes noise to create data
                predictedNoiseCond = self.unet(dNoiseCond, t)

                # use model (noise predictor) to predict mean
                modelMean = self.sqrtRecipAlphas[t] * (dNoiseCond - self.betas[t] * predictedNoiseCond / self.sqrtOneMinusAlphasCumprod[t])

                dNoise = modelMean[:, cond.shape[1]:modelMean.shape[1]] # discard prediction of conditioning
                if i != 0:
                    # sample randomly (only for non-final prediction), use mean directly for final prediction
                    dNoise = dNoise + self.sqrtPosteriorVariance[t] * torch.randn_like(dNoise)

            # unstack batch and sequence dimension again
            dNoise = torch.reshape(dNoise, (-1, seqLen, data.shape[2], data.shape[3], data.shape[4]))

            return dNoise
38/12:
device = "cuda" if torch.cuda.is_available() else "cpu"
print("Training device: %s" % device)

startFromCheckpoint = True

batch = 32 # training batch size
if startFromCheckpoint:
    epochs = 10 # finetune only for a small number of epochs
    lr = 0.00001 # since the model is already trained, a conservatively low learning rate
else:
    epochs = 10000 # train from scratch for large number of epochs
    lr = 0.0001 # larger learning rate for training from scratch

sequenceLength = [3,2] # three timesteps (two input steps and one target step) with a temporal stride of 2
simFields = ["dens", "pres"] # the provided data set contains velocity (implict), as well as density and pressure values
simParams = ["mach"] # scalar simulation parameters on which the model is conditioned only contain the Mach number here
diffusionSteps = 20 # the provided model checkpoint was pretrained on 20 diffusion steps

# data set and data loading
trainSet = TurbulenceDataset("Training", ["data"], filterTop=["128_small_tra"], filterSim=[[0]], excludefilterSim=False, filterFrame=[(250,1000)],
                sequenceLength=[sequenceLength], randSeqOffset=True, simFields=simFields, simParams=simParams, printLevel="sim")
trainSet.transform = DataTransforms(normalizeMode="traMixed", simFields=simFields, simParams=simParams)
trainSet.printDatasetInfo()
trainSampler = RandomSampler(trainSet)
#trainSampler = SequentialSampler(trainSet)
trainLoader = DataLoader(trainSet, sampler=trainSampler, batch_size=batch, drop_last=True, num_workers=2)
38/13:
# model definition
condChannels = 2 * (2 + len(simFields) + len(simParams))
dataChannels = 2 + len(simFields) + len(simParams)
model = DiffusionModel(diffusionSteps, condChannels, dataChannels)

if startFromCheckpoint:
    # load weights from checkpoint
    # loaded = torch.load("models/models_tra/128_acdm-r20_02/Model.pth", map_location=torch.device('cpu'))
    # model.load_state_dict(loaded["stateDictDecoder"])
    loaded = torch.load("models/NEW.zip", map_location=torch.device('cpu'))
    model.load_state_dict(loaded)
    
model.train()
model.to(device)

# print model info and trainable weigths
paramsTrainable = sum([np.prod(p.size()) for p in filter(lambda p: p.requires_grad, model.parameters())])
params = sum([np.prod(p.size()) for p in model.parameters()])
#print(model)
print("Trainable Weights (All Weights): %d (%d)" % (paramsTrainable, params))

# training loop
print("\nStarting training...")
optimizer = torch.optim.Adam(model.parameters(), lr=lr)
38/14:
for s, sample in enumerate(trainLoader, 0):
    d = sample["data"].to(device)

    inputSteps = 2
    cond = []
    for i in range(inputSteps):
        cond += [d[:,i:i+1]] # collect input steps
    conditioning = torch.concat(cond, dim=2) # combine along channel dimension
    data = d[:, inputSteps:inputSteps+1]
38/15: trainLoader.batch_sampler
38/16: trainLoader.batch_sampler()
38/17: trainSet[0]
38/18: trainSet
38/19: trainSet[0].shape
38/20: trainSet[0]
38/21: trainSet[0][0]
38/22: trainSet[0]['data']
38/23: trainSet[0]['data'].shape
38/24: trainSet[]'data'].shape
38/25: trainSet['data'].shape
38/26: trainSet
38/27: trainSet[20]
38/28: trainSet[0['data'].shape
38/29: trainSet.shape
38/30: trainSet
38/31: trainSet[0]['data'].shape
38/32: trainSet[0]['data'][:, 2:3]
38/33: trainSet[0]['data'][:, 2:3].shape
38/34: trainSet[0]['data'][0]
38/35: trainSet[0]['data'][1]
38/36: trainSet[0]['data'][2]
38/37: trainSet[0]['data'][3]
38/38: trainSet[0]['data'][0]
38/39: trainSet[0]['data'][0][1]
38/40: trainSet[0]['data'][0][2]
38/41: trainSet[0]['data'][0][3]
38/42: trainSet[0]['data'][0][4]
38/43: trainSet[0]['data'][0][3]
38/44: trainSet[0]['data'][0][4]
38/45: trainSet[0]['data'][0][0]
38/46: trainSet[0]['data'][0][1]
38/47: trainSet[0]['data'][0][2]
38/48: trainSet[0]['data'][0][3]
38/49: trainSet[0]['data'][0][2\]
38/50: trainSet[0]['data'][0][2]
38/51: trainSet[0]['data'][0][3]
38/52: trainSet[0]['data'][0][4]
38/53: trainSet[1]['data'][0][4]
38/54: trainSet[10]['data'][0][4]
38/55: trainSet[100]['data'][0][4]
38/56: trainSet[100]['data'][0][4] == 0.0
38/57: trainSet[100]['data'][0][4]
38/58: trainSet[:]
38/59: trainSet[:-1]
38/60: trainSet[0]
38/61: trainSet[0:]
38/62: trainSet[0:-1]
38/63: trainSet[0:124]
38/64: trainSet[0]
38/65: trainSet[1]
38/66: trainSet[2]
38/67: trainSet[3]
38/68: trainSet[4]
38/69: trainSet[5]
38/70: trainSet[6]
38/71: trainSet[7]
38/72: trainSet[0]
38/73: trainSet[10]
38/74: trainSet[100]
38/75: trainSet[110]
38/76: trainSet[123]
38/77: trainSet[124]
38/78: trainSet[125]
38/79: trainSet[124]
38/80: trainSet[0:124]
38/81: trainSet['data']
38/82: trainSet[0]
38/83: trainSet[0:1]
38/84: trainSet[0]
38/85: trainSet[124]
38/86: trainSet[124].shape
38/87: trainSet[124]['data']
38/88: trainSet[124]['simFields']
38/89: trainSet[124]['simParams']
38/90: trainSet[124]['data']
38/91: trainSet[124]['data'].shape
38/92: trainSet[124]['data'][0]
38/93: trainSet[124]['data'][0][0]
38/94:
from phi.torch.flow import *
import warp
38/95:
from phi.torch.flow import *
# import warp
38/96:
from phi.torch.flow import *
import .warp
38/97:
from phi.torch.flow import *
# import warp
38/98: math.tensor(trainSet[124]['data'][0][0],spatial(x=128,y=64))
38/99: backend.default_backend().set_default_device('GPU')
38/100: math.tensor(trainSet[124]['data'][0][0],spatial(x=128,y=64))
38/101:
backend.default_backend().set_default_device('GPU')
torch.set_default_device('cuda')
38/102: math.tensor(trainSet[124]['data'][0][0],spatial(x=128,y=64))
38/103: trainSet[124]['data'][0][0].device
38/104: trainSet[124]['data'][0][0].to('cuda')
38/105: math.tensor(trainSet[124]['data'][0][0].to('cuda'),spatial(x=128,y=64))
38/106: sample1 = math.tensor(trainSet[124]['data'][0][0].to('cuda'),spatial(x=128,y=64))
38/107:
sample1 = math.tensor(trainSet[124]['data'][0][0].to('cuda'),spatial(x=128,y=64))
vis.plot(sample1)
38/108: trainSet[124]['data'][0][0]
38/109: trainSet[124]['data'][0][0].shape
38/110: trainSet[124]['data'].shape
38/111: trainSet[124]['data'][0][0:2]
38/112: trainSet[124]['data'][0][0:2].shape
38/113:
sample1 = math.tensor(trainSet[124]['data'][0][0:2].to('cuda'),channel(vec='x,y'), spatial(x=128,y=64))
vis.plot(sample1)
38/114: math.tensor(trainSet[124]['data'][0][0:2].to('cuda'), channel(vec='x,y'), spatial(x=128,y=64))
38/115: math.tensor(trainSet[124]['data'][0][0:2].to('cuda'), channel(vec='x,y'), spatial(x=128,y=64)).vec[x]
38/116: math.tensor(trainSet[124]['data'][0][0:2].to('cuda'), math.channel(vec='x,y'), math.spatial(x=128,y=64))
38/117:
sample1 = math.tensor(trainSet[124]['data'][0][0:2].to('cuda'), math.channel(vec='x,y'), math.spatial(x=128,y=64))
vis.plot(sample1)
38/118:
sample1 = math.tensor(trainSet[124]['data'][0][0:2].to('cuda'), math.channel(vec=2), math.spatial(x=128,y=64))
vis.plot(sample1)
38/119:
sample1 = math.tensor(trainSet[124]['data'][0][0:2].to('cuda'), math.spatial(x=128,y=64), math.channel(vec='x,y'))
vis.plot(sample1)
38/120:
sample1 = math.tensor(trainSet[124]['data'][0][0:2].to('cuda'), math.channel(vec='x,y'), math.spatial(x=128,y=64))
vis.plot(sample1)
39/1: v_trj.time[-1]
39/2:
from phi.torch.flow import *
from tqdm.notebook import trange
import torch
import matplotlib.pyplot as plt
39/3:
import warp
backend.default_backend().set_default_device('GPU')
torch.set_default_device('cuda')
39/4:
# fluid specification & initialization
RES = 128
BOUND = 100
NUM_TIME_STEPS = 200
DT = 0.5
domain = Box(x=BOUND, y=BOUND)
INFLOW_RATE = 0.5
BUOYANCY = 0.1
inflow = Sphere(x=50, y=9.5, radius=8)

v0 = StaggeredGrid(0, 0, domain, x=RES, y=RES)
smoke0 = CenteredGrid(0, math.extrapolation.BOUNDARY, domain, x=RES, y=RES)
39/5:
# noise specification & initialization
batch_size = 2
num_channel = 2
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
up_level = 2 # noise upsampling level
res_up = RES * (2 ** up_level)
39/6:
# conditional noise upsampling & visualization
x = math.random_normal(batch(b=batch_size),math.channel(vec=num_channel),spatial(x=RES, y=RES))
x_up = warp.upsample_noise_cond(x, up_level)
vis.plot({'noise':x.b[0].vec[0],'conditional upsampled noise':x_up.b[0].vec[0]})
39/7:
# fluid step function with smoke inflow
@jit_compile
def step(v, s, p, dt):
    s = advect.mac_cormack(s, v, dt) + INFLOW_RATE * resample(inflow, to=s, soft=True)
    buoyancy = resample(s * (0, BUOYANCY), to=v)
    v = advect.semi_lagrangian(v, v, dt) + buoyancy * dt
    v, p = fluid.make_incompressible(v, (), Solve('CG', 1e-3, x0=p))
    return v, s, p
39/8: v_trj, s_trj, p_trj = iterate(step, batch(time=NUM_TIME_STEPS), v0, smoke0, None, dt=DT, range=trange, substeps=3)
38/121:
sample1 = math.tensor(trainSet[124]['data'][0][0:2].to('cuda'), math.channel(vector='x,y'), math.spatial(x=128,y=64))
vis.plot(sample1)
39/9:
# resampling the grid to a finer grid for noise transport
part_level = 2 # partition level for triangulation
tris_per_pix_dim = 2 ** (part_level-1) # triangles per pixel per dimension
tris_per_dim = tris_per_pix_dim * RES # triangles per dimension
vtx_per_dim = tris_per_pix_dim * RES + 1 # vertices per dimention
domain1=Box(x=(-BOUND/RES/tris_per_pix_dim/2, BOUND+BOUND/RES/tris_per_pix_dim/2),y=(-BOUND/RES/tris_per_pix_dim/2,BOUND+BOUND/RES/tris_per_pix_dim/2))
grid1 = CenteredGrid(0, math.extrapolation.BOUNDARY, domain1, x=vtx_per_dim, y=vtx_per_dim)
v_trj_rs = field.resample(value=v_trj, to=grid1)

vis.plot({'velocity': v_trj.time[-1], 'velocity resampled': v_trj_rs.time[-1]})
38/122:
sample1 = math.tensor(trainSet[124]['data'][0][2].to('cuda'), math.spatial(x=128,y=64))
vis.plot(sample1)
38/123:
sample1 = math.tensor(trainSet[124]['data'][0][3].to('cuda'), math.spatial(x=128,y=64))
vis.plot(sample1)
38/124:
sample1 = math.tensor(trainSet[124]['data'][0][4].to('cuda'), math.spatial(x=128,y=64))
vis.plot(sample1)
38/125: trainSet.size
38/126: trainSet.sizes
38/127:
vel_trj = []
for timeStep in range(125):
    vel = math.tensor(trainSet[timeStep]['data'][0][0:2].to('cuda'), math.channel(vector='x,y'), math.spatial(x=128,y=64))
    vel_trj.append(vel)
38/128: vel_trj
38/129: math.stack(vel_trj, math.batch(time=125))
38/130:
vel_trj = []
for timeStep in range(125):
    vel = math.tensor(trainSet[timeStep]['data'][0][0:2].to('cuda'), math.channel(vector='x,y'), math.spatial(x=128,y=64))
    vel_trj.append(vel)
math.stack(vel_trj, math.batch(time=125))
38/131:
vel_trj = []
for timeStep in range(125):
    vel = math.tensor(trainSet[timeStep]['data'][0][0:2].to('cuda'), math.channel(vector='x,y'), math.spatial(x=128,y=64))
    vel_trj.append(vel)
vel_trj = math.stack(vel_trj, math.batch(time=125))
38/132: vis.plot(vel_trj, animate='time')
38/133:
vel_trj = []
dens_trj = []
for timeStep in range(125):
    vel = math.tensor(trainSet[timeStep]['data'][0][0:2].to('cuda'), math.channel(vector='x,y'), math.spatial(x=128,y=64))
    dens = math.tensor(trainSet[timeStep]['data'][0][2].to('cuda'), math.channel(vector='x,y'), math.spatial(x=128,y=64))
    vel_trj.append(vel)
    dens_trj.append(dens)
vel_trj = math.stack(vel_trj, math.batch(time=125))
dens_trj = math.stack(dens_trj, math.batch(time=125))
38/134:
vel_trj = []
dens_trj = []
for timeStep in range(125):
    vel = math.tensor(trainSet[timeStep]['data'][0][0:2].to('cuda'), math.channel(vector='x,y'), math.spatial(x=128,y=64))
    dens = math.tensor(trainSet[timeStep]['data'][0][2].to('cuda'), math.spatial(x=128,y=64))
    vel_trj.append(vel)
    dens_trj.append(dens)
vel_trj = math.stack(vel_trj, math.batch(time=125))
dens_trj = math.stack(dens_trj, math.batch(time=125))
38/135: vis.plot(dens_trj, animate='time')
38/136: trainSet[timeStep]['data']
38/137: trainSet[timeStep]['Resolution']
38/138: trainSet[timeStep]
38/139: trainSet[timeStep]
38/140: trainSet[0]
38/141: trainSet[0].keys
38/142: trainSet[0].values
38/143: trainSet[0]
38/144: trainSet[0].keys
38/145: trainSet[0]
38/146: print(trainSet[0].keys)
38/147: trainSet[0].keys()
38/148: trainSet[0]['simParameters']
38/149: trainSet[0]['allParameters']
38/150: trainSet[0]['path']
38/151: trainSet[0]['obsMask']
38/152: trainSet[0]['data']
38/153: trainSet[0]['data'].shape
38/154: trainSet[0]['simParameters']
38/155: trainSet[0]['allParameters']
38/156:
device = "cuda" if torch.cuda.is_available() else "cpu"
print("Training device: %s" % device)

startFromCheckpoint = True

batch = 32 # training batch size
if startFromCheckpoint:
    epochs = 10 # finetune only for a small number of epochs
    lr = 0.00001 # since the model is already trained, a conservatively low learning rate
else:
    epochs = 10000 # train from scratch for large number of epochs
    lr = 0.0001 # larger learning rate for training from scratch

sequenceLength = [3,2] # three timesteps (two input steps and one target step) with a temporal stride of 2
simFields = ["dens", "pres"] # the provided data set contains velocity (implict), as well as density and pressure values
simParams = ["mach"] # scalar simulation parameters on which the model is conditioned only contain the Mach number here
diffusionSteps = 20 # the provided model checkpoint was pretrained on 20 diffusion steps

# data set and data loading
trainSet = TurbulenceDataset("Training", ["data"], filterTop=["128_small_tra"], filterSim=[[0]], excludefilterSim=False, filterFrame=[(250,1000)],
                sequenceLength=[sequenceLength], randSeqOffset=True, simFields=simFields, simParams=simParams, printLevel="full")
trainSet.transform = DataTransforms(normalizeMode="traMixed", simFields=simFields, simParams=simParams)
trainSet.printDatasetInfo()
trainSampler = RandomSampler(trainSet)
#trainSampler = SequentialSampler(trainSet)
trainLoader = DataLoader(trainSet, sampler=trainSampler, batch_size=batch, drop_last=True, num_workers=2)
38/157: len(trainSet.dataPaths)
38/158: trainSet[0].shape[-1]
38/159: trainSet[0]['data']
38/160: trainSet[0]['data'].shape[-1]
38/161: trainSet[0]['data'].shape[-2]
38/162:
num_time_steps = len(trainSet.dataPaths)
res_x = trainSet[0]['data'].shape[-2]
res_y = trainSet[0]['data'].shape[-1]
BOUND = res_y
38/163:
# resampling the grid to a finer grid for noise transport
part_level = 2 # partition level for triangulation
tris_per_pix_dim = 2 ** (part_level-1) # triangles per pixel per dimension
tris_per_dim = tris_per_pix_dim * res_x # triangles per dimension
vtx_per_dim = tris_per_pix_dim * res_x + 1 # vertices per dimention
domain=Box(x=(-BOUND/res_x/tris_per_pix_dim/2, BOUND+BOUND/res_x/tris_per_pix_dim/2),y=(-BOUND/res_y/tris_per_pix_dim/2,BOUND+BOUND/res_y/tris_per_pix_dim/2))
grid_to_warp = CenteredGrid(0, math.extrapolation.BOUNDARY, domain, x=vtx_per_dim, y=vtx_per_dim)
v_trj_rs = field.resample(value=vel_trj, to=grid_to_warp)

vis.plot({'velocity': vel_trj.time[-1], 'velocity resampled': vel_trj_rs.time[-1]})
38/164:
# resampling the grid to a finer grid for noise transport
part_level = 2 # partition level for triangulation
tris_per_pix_dim = 2 ** (part_level-1) # triangles per pixel per dimension
tris_per_dim = tris_per_pix_dim * res_x # triangles per dimension
vtx_per_dim = tris_per_pix_dim * res_x + 1 # vertices per dimention
domain=Box(x=(-BOUND/res_x/tris_per_pix_dim/2, BOUND+BOUND/res_x/tris_per_pix_dim/2),y=(-BOUND/res_y/tris_per_pix_dim/2,BOUND+BOUND/res_y/tris_per_pix_dim/2))
grid_to_warp = CenteredGrid(0, math.extrapolation.BOUNDARY, domain, x=vtx_per_dim, y=vtx_per_dim)
vel_trj_rs = field.resample(value=vel_trj, to=grid_to_warp)

vis.plot({'velocity': vel_trj.time[-1], 'velocity resampled': vel_trj_rs.time[-1]})
38/165:
num_time_steps = len(trainSet.dataPaths)
res_x = trainSet[0]['data'].shape[-2]
res_y = trainSet[0]['data'].shape[-1]
BOUND_X = res_x
BOUND_Y = res_y
38/166:
# resampling the grid to a finer grid for noise transport
part_level = 2 # partition level for triangulation
tris_per_pix_dim = 2 ** (part_level-1) # triangles per pixel per dimension
tris_per_dim = tris_per_pix_dim * res_x # triangles per dimension
vtx_per_dim = tris_per_pix_dim * res_x + 1 # vertices per dimention
domain=Box(x=(-BOUND_X/res_x/tris_per_pix_dim/2, BOUND_X+BOUND_X/res_x/tris_per_pix_dim/2),y=(-BOUND_Y/res_y/tris_per_pix_dim/2,BOUND_Y+BOUND_Y/res_y/tris_per_pix_dim/2))
grid_to_warp = CenteredGrid(0, math.extrapolation.BOUNDARY, domain, x=vtx_per_dim, y=vtx_per_dim)
vel_trj_rs = field.resample(value=vel_trj, to=grid_to_warp)

vis.plot({'velocity': vel_trj.time[-1], 'velocity resampled': vel_trj_rs.time[-1]})
38/167:
# resampling the grid to a finer grid for noise transport
part_level = 2 # partition level for triangulation
tris_per_pix_dim = 2 ** (part_level-1) # triangles per pixel per dimension
tris_per_dim = tris_per_pix_dim * res_x # triangles per dimension
vtx_per_dim_x = tris_per_pix_dim * res_x + 1 # vertices per dimention
vtx_per_dim_y = tris_per_pix_dim * res_y + 1 # vertices per dimention
domain=Box(x=(-BOUND_X/res_x/tris_per_pix_dim/2, BOUND_X+BOUND_X/res_x/tris_per_pix_dim/2),y=(-BOUND_Y/res_y/tris_per_pix_dim/2,BOUND_Y+BOUND_Y/res_y/tris_per_pix_dim/2))
grid_to_warp = CenteredGrid(0, math.extrapolation.BOUNDARY, domain, x=vtx_per_dim_x, y=vtx_per_dim_y)
vel_trj_rs = field.resample(value=vel_trj, to=grid_to_warp)

vis.plot({'velocity': vel_trj.time[-1], 'velocity resampled': vel_trj_rs.time[-1]})
39/10: grid1
39/11: v_trj
39/12: v_trj_rs
39/13: grid1
39/14: v_trj
39/15: v_trj.shape
38/168: CenteredGrid(vel_trj, math.extrapolation.BOUNDARY, domain, x=vtx_per_dim_x, y=vtx_per_dim_y)
38/169: CenteredGrid(vel_trj, math.extrapolation.BOUNDARY, domain, x=res_x, y=res_y)
38/170:
# resampling the grid to a finer grid for noise transport
part_level = 2 # partition level for triangulation
tris_per_pix_dim = 2 ** (part_level-1) # triangles per pixel per dimension
tris_per_dim = tris_per_pix_dim * res_x # triangles per dimension
vtx_per_dim_x = tris_per_pix_dim * res_x + 1 # vertices per dimention
vtx_per_dim_y = tris_per_pix_dim * res_y + 1 # vertices per dimention
domain=Box(x=(-BOUND_X/res_x/tris_per_pix_dim/2, BOUND_X+BOUND_X/res_x/tris_per_pix_dim/2),y=(-BOUND_Y/res_y/tris_per_pix_dim/2,BOUND_Y+BOUND_Y/res_y/tris_per_pix_dim/2))
grid_to_warp = CenteredGrid(0, math.extrapolation.BOUNDARY, domain, x=vtx_per_dim_x, y=vtx_per_dim_y)
vel_trj_rs = field.resample(value=CenteredGrid(vel_trj, math.extrapolation.BOUNDARY, domain, x=res_x, y=res_y), to=grid_to_warp)

vis.plot({'velocity': vel_trj.time[-1], 'velocity resampled': vel_trj_rs.time[-1]})
38/171:
# resampling the grid to a finer grid for noise transport
part_level = 2 # partition level for triangulation
tris_per_pix_dim = 2 ** (part_level-1) # triangles per pixel per dimension
tris_per_dim = tris_per_pix_dim * res_x # triangles per dimension
vtx_per_dim_x = tris_per_pix_dim * res_x + 1 # vertices per dimention
vtx_per_dim_y = tris_per_pix_dim * res_y + 1 # vertices per dimention
domain=Box(x=(-BOUND_X/res_x/tris_per_pix_dim/2, BOUND_X+BOUND_X/res_x/tris_per_pix_dim/2),y=(-BOUND_Y/res_y/tris_per_pix_dim/2,BOUND_Y+BOUND_Y/res_y/tris_per_pix_dim/2))
vel_trj = CenteredGrid(vel_trj, math.extrapolation.BOUNDARY, domain, x=res_x, y=res_y)
grid_to_warp = CenteredGrid(0, math.extrapolation.BOUNDARY, domain, x=vtx_per_dim_x, y=vtx_per_dim_y)
vel_trj_rs = field.resample(value=CenteredGrid(vel_trj, math.extrapolation.BOUNDARY, domain, x=res_x, y=res_y), to=grid_to_warp)

vis.plot({'velocity': vel_trj.time[-1], 'velocity resampled': vel_trj_rs.time[-1]})
38/172: vel_trj
38/173: vel_trj_Rs
38/174: vel_trj_rs
38/175: impot ..warp
38/176: import ..warp
38/177: from .. import warp
38/178: from ... import warp
38/179: from .. import warp
38/180: from . import warp
38/181: from .. import warp
38/182: from .warp. import warp
38/183: from .warp import warp
38/184: from ..warp import warp
38/185: from .. import warp
38/186: from ..warp import warp
38/187: from ../warp import warp
38/188: from .. import warp
38/189: import warp
38/190: from .. import warp
38/191: from ..ACDM_noise_warp import warp
38/192: from .ACDM_noise_warp import warp
38/193: from ...ACDM_noise_warp import warp
38/194: from ..ACDM_noise_warp import warp
38/195: from ..warp import warp
38/196: from ..warp import *
38/197: from .. import warp
38/198: from . import warp
38/199: import sys
38/200:
here = os.path.dirname(__file__)

sys.path.append(os.path.join(here, '..'))
import warp
38/201:
# here = os.path.dirname(__file__)

# sys.path.append(os.path.join(here, '..'))
import warp
38/202:
import sys

sys.path.append('..')
38/203:
# here = os.path.dirname(__file__)

# sys.path.append(os.path.join(here, '..'))
import warp
38/204:
_, vertices = warp.vertices_gen(res_x, res_y, part_level)
reshaped_mesh_idxs = warp.mesh_idx_gen(res_x, res_y, part_level)
38/205: grid_to_warp.center
   1: history -g -f filename
